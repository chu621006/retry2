import streamlit as st
import pandas as pd
import io
import pdfplumber
import re # <-- ç¢ºä¿æœ‰é€™ä¸€è¡Œ

# ... (å…¶ä»–å‡½æ•¸ä¿æŒä¸è®Šï¼Œä¾‹å¦‚ parse_gpa_to_numeric, analyze_student_grades, normalize_text) ...

# --- 4. è™•ç†åˆ†è¡ŒGPA/å­¸åˆ†å•é¡Œçš„å‡½æ•¸ (åœ¨æå–åŸå§‹è¡¨æ ¼å¾Œç«‹å³æ‡‰ç”¨) ---
def parse_gpa_credit_from_combined_cell(gpa_cell_content, credit_cell_content):
    """
    Handles cases where GPA and credit are combined in one cell, or extracted incorrectly.
    Returns cleaned GPA and credit values.
    """
    original_gpa = str(gpa_cell_content).strip()
    original_credit = str(credit_cell_content).strip()

    # Normalize both inputs first to handle problematic characters
    gpa = normalize_text(original_gpa)
    credit = normalize_text(original_credit)

    # Regex to find a potential grade and a potential number (credit)
    # Allows for optional whitespace between grade and number
    # Group 1: Grade (A-F, +, -, æŠµå…, é€šé, or empty)
    # Group 2: Numeric part (digits and dot)
    grade_credit_pattern = re.compile(r'^\s*([A-Z\+\-æŠµå…é€šé]*)\s*([0-9\.]*)\s*$')

    parsed_gpa = gpa
    parsed_credit = credit

    # Try to parse from GPA cell if credit cell is empty or looks like a grade
    if not credit or (parse_gpa_to_numeric(credit) != 0.0 and not credit.replace('.', '').isdigit()):
        match = grade_credit_pattern.match(gpa)
        if match:
            grade_part = match.group(1).strip()
            num_part = match.group(2).strip()

            # If a grade part is found and it's valid, use it for GPA
            if grade_part and (parse_gpa_to_numeric(grade_part) != 0.0 or grade_part in ['æŠµå…', 'é€šé']):
                parsed_gpa = grade_part
            # If a numeric part is found and it's valid, use it for credit
            if num_part and num_part.replace('.', '').isdigit():
                parsed_credit = num_part
            # If GPA cell contained "Grade Number", and credit cell was truly empty
            elif not credit and parsed_gpa != gpa and parsed_credit != credit:
                 # This means we successfully split 'gpa' cell into grade and credit
                 pass
            # Handle cases where original gpa was just "3" (a credit) and original credit was "A" (a grade) - swap them
            elif gpa.replace('.', '').isdigit() and (parse_gpa_to_numeric(credit) != 0.0 and not credit.replace('.', '').isdigit()):
                parsed_gpa = credit
                parsed_credit = gpa

    # Try to parse from Credit cell if GPA cell is empty or looks like a credit number
    if not gpa or (gpa.replace('.', '').isdigit() and parse_gpa_to_numeric(gpa) == 0.0): # gpa looks like a credit number
        match = grade_credit_pattern.match(credit)
        if match:
            grade_part = match.group(1).strip()
            num_part = match.group(2).strip()

            if grade_part and (parse_gpa_to_numeric(grade_part) != 0.0 or grade_part in ['æŠµå…', 'é€šé']):
                parsed_gpa = grade_part
            if num_part and num_part.replace('.', '').isdigit():
                parsed_credit = num_part
            # Handle cases where original credit was just "A" (a grade) and original gpa was "3" (a credit) - swap them
            elif credit.replace('.', '').isdigit() and (parse_gpa_to_numeric(gpa) != 0.0 and not gpa.replace('.', '').isdigit()):
                parsed_gpa = gpa
                parsed_credit = credit

    # Final check for common scenarios if one is clearly a grade and the other a number, and they were swapped
    # E.g., if gpa is "3.0" and credit is "A", swap them
    if parsed_gpa and parsed_credit:
        is_gpa_like_grade = (parse_gpa_to_numeric(parsed_gpa) != 0.0 or parsed_gpa in ['æŠµå…', 'é€šé']) and not parsed_gpa.replace('.', '').isdigit()
        is_credit_like_number = parsed_credit.replace('.', '').isdigit()

        if not is_gpa_like_grade and is_credit_like_number: # GPA looks like a number, Credit looks like a number
            # This is ambiguous, keep original assignment unless a swap is obvious
            pass
        elif is_gpa_like_grade and not is_credit_like_number: # GPA looks like a grade, Credit looks like a grade
            # This means both are grades, which is probably wrong, return as is and let downstream handle
            pass
        elif not is_gpa_like_grade and not is_credit_like_number: # Both not grade and not number, keep as is
            pass
        elif is_gpa_like_grade and is_credit_like_number: # Correct scenario, grade in GPA, number in credit
            pass
        else: # Unlikely, but covers other combinations
            pass
    
    # One last swap check: If one cell got "æŠµå…" or "é€šé" and the other got a number, assign them correctly
    if parsed_gpa in ['æŠµå…', 'é€šé'] and parsed_credit.replace('.', '').isdigit():
        pass # Correctly assigned
    elif parsed_credit in ['æŠµå…', 'é€šé'] and parsed_gpa.replace('.', '').isdigit():
        temp_gpa = parsed_credit
        temp_credit = parsed_gpa
        parsed_gpa = temp_gpa
        parsed_credit = temp_credit

    return parsed_gpa, parsed_credit

# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é«” ---
def main():
    st.title("ç¸½å­¸åˆ†æŸ¥è©¢ç³»çµ± ğŸ“")
    st.write("è«‹ä¸Šå‚³æ‚¨çš„æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆï¼Œç³»çµ±å°‡æœƒç‚ºæ‚¨æŸ¥è©¢ç›®å‰ç¸½å­¸åˆ†èˆ‡è·é›¢ç•¢æ¥­æ‰€éœ€çš„å­¸åˆ†ã€‚")
    st.info("ğŸ’¡ ç¢ºä¿æ‚¨çš„æˆç¸¾å–® PDF æ˜¯æ¸…æ™°çš„è¡¨æ ¼æ ¼å¼ï¼Œä»¥ç²å¾—æœ€ä½³è§£ææ•ˆæœã€‚")

    uploaded_file = st.file_uploader("ä¸Šå‚³æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆ", type=["pdf"])

    all_grades_data = []
    full_grades_df = pd.DataFrame() 

    if uploaded_file is not None:
        st.success("æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼æ­£åœ¨åˆ†æä¸­...")

        try:
            expected_header_keywords = ["å­¸å¹´åº¦", "å­¸æœŸ", "é¸èª²ä»£è™Ÿ", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]
            
            with pdfplumber.open(io.BytesIO(uploaded_file.getvalue())) as pdf:
                total_pages = len(pdf.pages)

                for page_num, page in enumerate(pdf.pages):
                    top_y_crop = 0
                    bottom_y_crop = page.height

                    if "è¬äº‘ç‘„æˆç¸¾ç¸½è¡¨.pdf" in uploaded_file.name:
                        top_y_crop = 170 if page_num == 0 else 50
                        bottom_y_crop = page.height - 30
                    elif "é‚±æ—­å»·æˆç¸¾ç¸½è¡¨.pdf" in uploaded_file.name:
                        top_y_crop = 250 if page_num == 0 else 50
                        bottom_y_crop = page.height - 30
                    else:
                        top_y_crop = 100 if page_num == 0 else 50
                        bottom_y_crop = page.height - 30

                    cropped_page = page.crop((0, top_y_crop, page.width, bottom_y_crop))
                    
                    # å˜—è©¦æ›´ç´°ç·»çš„ table_settings
                    table_settings = {
                        "vertical_strategy": "lines",
                        "horizontal_strategy": "lines",
                        "snap_tolerance": 2, # å¾®èª¿ï¼šå¾ 3 èª¿æ•´ç‚º 2
                        "text_tolerance": 2, # å¾®èª¿ï¼šå¾ 3 èª¿æ•´ç‚º 2
                        "join_tolerance": 2, # å¾®èª¿ï¼šå¾ 3 èª¿æ•´ç‚º 2
                        "edge_min_length": 3,
                        "min_words_horizontal": 1,
                        "min_words_vertical": 1
                    }
                    
                    tables = cropped_page.extract_tables(table_settings)
                    
                    if not tables:
                        continue

                    for table_idx, table in enumerate(tables):
                        if not table or len(table) < 1:
                            continue

                        filtered_table = []
                        for row in table:
                            normalized_row = [normalize_text(cell) for cell in row]
                            if any(cell.strip() for cell in normalized_row):
                                filtered_table.append(normalized_row)
                        
                        if not filtered_table:
                            continue
                        
                        header_row_found = False
                        header = []
                        header_row_start_idx = -1

                        potential_header_search_range = min(len(filtered_table), 5)
                        for h_idx in range(potential_header_search_range):
                            h_row_cells = [cell.strip() for cell in filtered_table[h_idx]]
                            
                            header_match_criteria = [
                                any("å­¸å¹´" in cell for cell in h_row_cells),
                                any("ç§‘ç›®åç¨±" in cell for cell in h_row_cells),
                                any("å­¸åˆ†" in cell for cell in h_row_cells),
                                any("GPA" in cell for cell in h_row_cells)
                            ]

                            if all(header_match_criteria):
                                header = h_row_cells
                                header_row_found = True
                                header_row_start_idx = h_idx
                                break
                        
                        if not header_row_found:
                            if len(filtered_table[0]) > 0 and filtered_table[0][0].isdigit() and len(filtered_table[0][0]) == 3:
                                header = expected_header_keywords
                                header_row_start_idx = -1
                                header_row_found = True
                            else:
                                continue

                        col_to_index = {}
                        for i, h_text in enumerate(header):
                            if "å­¸å¹´" in h_text: col_to_index["å­¸å¹´åº¦"] = i
                            elif "å­¸æœŸ" in h_text: col_to_index["å­¸æœŸ"] = i
                            elif "é¸èª²ä»£è™Ÿ" in h_text: col_to_index["é¸èª²ä»£è™Ÿ"] = i
                            elif "ç§‘ç›®åç¨±" in h_text: col_to_index["ç§‘ç›®åç¨±"] = i
                            elif "å­¸åˆ†" in h_text: col_to_index["å­¸åˆ†"] = i
                            elif "GPA" in h_text: col_to_index["GPA"] = i

                        critical_cols = ["å­¸å¹´åº¦", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]
                        if not all(col in col_to_index for col in critical_cols):
                            st.warning(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} ç¼ºå°‘é—œéµåˆ—ã€‚è·³éæ­¤è¡¨æ ¼ã€‚")
                            continue

                        å­¸å¹´åº¦_idx = col_to_index.get("å­¸å¹´åº¦")
                        å­¸æœŸ_idx = col_to_index.get("å­¸æœŸ")
                        é¸èª²ä»£è™Ÿ_idx = col_to_index.get("é¸èª²ä»£è™Ÿ")
                        ç§‘ç›®åç¨±_idx = col_to_index.get("ç§‘ç›®åç¨±")
                        å­¸åˆ†_idx = col_to_index.get("å­¸åˆ†")
                        GPA_idx = col_to_index.get("GPA")

                        processed_rows = []
                        current_row_data_temp = [""] * len(expected_header_keywords)

                        data_rows_to_process = filtered_table[header_row_start_idx + 1:] if header_row_start_idx != -1 else filtered_table[:]

                        for row_num_in_table, row_cells in enumerate(data_rows_to_process):
                            if not any(str(cell).strip() for cell in row_cells):
                                continue

                            max_idx = max(col_to_index.values()) if col_to_index else 0
                            row_cells_padded = row_cells + [''] * (max_idx + 1 - len(row_cells))

                            å­¸å¹´åº¦_val = row_cells_padded[å­¸å¹´åº¦_idx] if å­¸å¹´åº¦_idx is not None and å­¸å¹´åº¦_idx < len(row_cells_padded) else ''
                            é¸èª²ä»£è™Ÿ_val = row_cells_padded[é¸èª²ä»£è™Ÿ_idx] if é¸èª²ä»£è™Ÿ_idx is not None and é¸èª²ä»£è™Ÿ_idx < len(row_cells_padded) else ''
                            ç§‘ç›®åç¨±_val = row_cells_padded[ç§‘ç›®åç¨±_idx] if ç§‘ç›®åç¨±_idx is not None and ç§‘ç›®åç¨±_idx < len(row_cells_padded) else ''
                            å­¸åˆ†_val = row_cells_padded[å­¸åˆ†_idx] if å­¸åˆ†_idx is not None and å­¸åˆ†_idx < len(row_cells_padded) else ''
                            GPA_val = row_cells_padded[GPA_idx] if GPA_idx is not None and GPA_idx < len(row_cells_padded) else ''

                            is_new_grade_row = False
                            if å­¸å¹´åº¦_val.isdigit() and len(å­¸å¹´åº¦_val) == 3 and \
                               (é¸èª²ä»£è™Ÿ_val.strip() != '' or ç§‘ç›®åç¨±_val.strip() != ''):
                                is_new_grade_row = True
                            
                            if is_new_grade_row:
                                if current_row_data_temp and any(x is not None and str(x).strip() for x in current_row_data_temp):
                                    processed_rows.append(current_row_data_temp[:])
                                
                                current_row_data_temp = [""] * len(expected_header_keywords)

                                if å­¸å¹´åº¦_idx is not None: current_row_data_temp[expected_header_keywords.index("å­¸å¹´åº¦")] = å­¸å¹´åº¦_val
                                if å­¸æœŸ_idx is not None: current_row_data_temp[expected_header_keywords.index("å­¸æœŸ")] = (row_cells_padded[å­¸æœŸ_idx] if å­¸æœŸ_idx is not None and å­¸æœŸ_idx < len(row_cells_padded) else '')
                                if é¸èª²ä»£è™Ÿ_idx is not None: current_row_data_temp[expected_header_keywords.index("é¸èª²ä»£è™Ÿ")] = é¸èª²ä»£è™Ÿ_val
                                if ç§‘ç›®åç¨±_idx is not None: current_row_data_temp[expected_header_keywords.index("ç§‘ç›®åç¨±")] = ç§‘ç›®åç¨±_val
                                
                                # Apply parsing for GPA and Credit immediately
                                current_gpa, current_credit = parse_gpa_credit_from_combined_cell(GPA_val, å­¸åˆ†_val)
                                current_row_data_temp[expected_header_keywords.index("GPA")] = current_gpa
                                current_row_data_temp[expected_header_keywords.index("å­¸åˆ†")] = current_credit

                            elif current_row_data_temp:
                                is_continuation_candidate = (å­¸å¹´åº¦_val.strip() == '' and é¸èª²ä»£è™Ÿ_val.strip() == '')

                                if is_continuation_candidate and ç§‘ç›®åç¨±_val.strip() != '':
                                    current_subject_name_index = expected_header_keywords.index("ç§‘ç›®åç¨±")
                                    current_subject_name = current_row_data_temp[current_subject_name_index]
                                    if current_subject_name.strip() == "":
                                        current_row_data_temp[current_subject_name_index] = ç§‘ç›®åç¨±_val
                                    else:
                                        current_row_data_temp[current_subject_name_index] += " " + ç§‘ç›®åç¨±_val
                                
                                # For continuation rows, try to update GPA/Credit if they are found in this row
                                if is_continuation_candidate and (å­¸åˆ†_val.strip() != '' or GPA_val.strip() != ''):
                                    merged_gpa, merged_credit = parse_gpa_credit_from_combined_cell(GPA_val, å­¸åˆ†_val)
                                    
                                    credit_index = expected_header_keywords.index("å­¸åˆ†")
                                    gpa_index = expected_header_keywords.index("GPA")

                                    # Only update if current temp is empty or new value is more complete
                                    if current_row_data_temp[credit_index].strip() == "" and merged_credit.strip() != "":
                                        current_row_data_temp[credit_index] = merged_credit
                                    if current_row_data_temp[gpa_index].strip() == "" and merged_gpa.strip() != "":
                                        current_row_data_temp[gpa_index] = merged_gpa


                        if current_row_data_temp and any(x is not None and str(x).strip() for x in current_row_data_temp):
                            processed_rows.append(current_row_data_temp[:])
                        
                        if processed_rows:
                            df_table = pd.DataFrame(processed_rows, columns=expected_header_keywords)
                            
                            for col in df_table.columns:
                                df_table[col] = df_table[col].astype(str).str.strip().replace('None', '').replace('nan', '')

                            all_grades_data.append(df_table)
                        else:
                            pass

            if not all_grades_data:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼æˆ–èª¿æ•´è¡¨æ ¼æå–è¨­å®šã€‚")
                full_grades_df = pd.DataFrame(columns=expected_header_keywords)
            else:
                full_grades_df = pd.concat(all_grades_data, ignore_index=True)

                full_grades_df.dropna(how='all', inplace=True)
                
                if 'å­¸å¹´åº¦' in full_grades_df.columns and 'é¸èª²ä»£è™Ÿ' in full_grades_df.columns:
                    full_grades_df = full_grades_df[
                        full_grades_df['å­¸å¹´åº¦'].astype(str).str.match(r'^\d{3}$') &
                        (full_grades_df['é¸èª²ä»£è™Ÿ'].astype(str).str.strip() != '')
                    ]

                if 'ç§‘ç›®åç¨±' in full_grades_df.columns:
                    full_grades_df = full_grades_df[~full_grades_df['ç§‘ç›®åç¨±'].astype(str).str.contains('å‹ä½œæˆç¸¾', na=False)]
                
                if 'GPA' in full_grades_df.columns:
                    full_grades_df['GPA'] = full_grades_df['GPA'].astype(str).str.strip()
                
                if 'å­¸åˆ†' in full_grades_df.columns:
                    full_grades_df['å­¸åˆ†'] = pd.to_numeric(full_grades_df['å­¸åˆ†'], errors='coerce').fillna(0)


            if not full_grades_df.empty:
                total_credits, remaining_credits, passed_courses_df = analyze_student_grades(full_grades_df)

                st.subheader("æŸ¥è©¢çµæœ âœ…")
                st.metric("ç›®å‰ç¸½å­¸åˆ†", total_credits)
                st.metric("è·é›¢ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±128å­¸åˆ†)", remaining_credits)

                st.subheader("é€šéçš„èª²ç¨‹åˆ—è¡¨ ğŸ“–")
                st.dataframe(passed_courses_df[['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']])

                with st.expander("æŸ¥çœ‹åŸå§‹æå–çš„æ•¸æ“š (ç”¨æ–¼é™¤éŒ¯)"):
                    st.dataframe(full_grades_df)
            else:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼ã€‚")

        except Exception as e:
            st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            st.info("è«‹ç¢ºèªæ‚¨çš„ PDF æ ¼å¼æ˜¯å¦ç‚ºæ¸…æ™°çš„è¡¨æ ¼ã€‚è‹¥å•é¡ŒæŒçºŒï¼Œå¯èƒ½æ˜¯ PDF çµæ§‹è¼ƒç‚ºè¤‡é›œï¼Œéœ€è¦èª¿æ•´ `pdfplumber` çš„è¡¨æ ¼æå–è¨­å®šã€‚")
            st.exception(e)

if __name__ == "__main__":
    main()
