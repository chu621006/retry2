import streamlit as st
import pandas as pd
import io
import pdfplumber

# --- 1. GPA è½‰æ›å‡½æ•¸ ---
def parse_gpa_to_numeric(gpa_str):
    """
    Converts GPA string to a numeric value for comparison.
    This mapping can be adjusted based on specific grading scales.
    For this example, we define C- and above as passing.
    """
    gpa_map = {
        'A+': 4.3, 'A': 4.0, 'A-': 3.7,
        'B+': 3.3, 'B': 3.0, 'B-': 2.7,
        'C+': 2.3, 'C': 2.0, 'C-': 1.7,
        'D+': 1.3, 'D': 1.0, 'D-': 0.7,
        'E': 0.0, 'F': 0.0,
        'æŠµå…': 999.0,
        'é€šé': 999.0
    }
    return gpa_map.get(str(gpa_str).strip(), 0.0)

# --- 2. æˆç¸¾åˆ†æå‡½æ•¸ ---
def analyze_student_grades(df):
    """
    Analyzes a DataFrame of student grades to calculate total earned credits
    and remaining credits for graduation.
    """
    GRADUATION_REQUIREMENT = 128

    df['å­¸åˆ†'] = pd.to_numeric(df['å­¸åˆ†'], errors='coerce').fillna(0)
    df['GPA_Numeric'] = df['GPA'].apply(parse_gpa_to_numeric)
    df['æ˜¯å¦é€šé'] = df['GPA_Numeric'].apply(lambda x: x >= 1.7)
    passed_courses_df = df[df['æ˜¯å¦é€šé'] & (df['å­¸åˆ†'] > 0)].copy()

    total_earned_credits = passed_courses_df['å­¸åˆ†'].sum()
    remaining_credits_to_graduate = max(0, GRADUATION_REQUIREMENT - total_earned_credits)

    return total_earned_credits, remaining_credits_to_graduate, passed_courses_df

# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é«” ---
def main():
    st.title("ç¸½å­¸åˆ†æŸ¥è©¢ç³»çµ± ğŸ“")
    st.write("è«‹ä¸Šå‚³æ‚¨çš„æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆï¼Œç³»çµ±å°‡æœƒç‚ºæ‚¨æŸ¥è©¢ç›®å‰ç¸½å­¸åˆ†èˆ‡è·é›¢ç•¢æ¥­æ‰€éœ€çš„å­¸åˆ†ã€‚")
    st.info("ğŸ’¡ ç¢ºä¿æ‚¨çš„æˆç¸¾å–® PDF æ˜¯æ¸…æ™°çš„è¡¨æ ¼æ ¼å¼ï¼Œä»¥ç²å¾—æœ€ä½³è§£ææ•ˆæœã€‚")

    uploaded_file = st.file_uploader("ä¸Šå‚³æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆ", type=["pdf"])

    if uploaded_file is not None:
        st.success("æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼æ­£åœ¨åˆ†æä¸­...")

        try:
            all_grades_data = [] # ç¢ºä¿åœ¨ try å€å¡Šé–‹å§‹æ™‚å®šç¾©
            expected_columns_order = ["å­¸å¹´åº¦", "å­¸æœŸ", "é¸èª²ä»£è™Ÿ", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]

            with pdfplumber.open(io.BytesIO(uploaded_file.getvalue())) as pdf:
                for page_num, page in enumerate(pdf.pages): # åŠ å…¥ page_num ä»¥ä¾¿é™¤éŒ¯
                    # é€™äº›æ˜¯åŸºæ–¼ã€Œé‚±æ—­å»·æˆç¸¾ç¸½è¡¨.pdfã€çš„è§€å¯Ÿå€¼ï¼Œå¯èƒ½éœ€è¦å¾®èª¿
                    # å»ºè­°åœ¨æœ¬åœ°ä½¿ç”¨ pdfplumber çš„ debug æ¨¡å¼ä¾†è¦–è¦ºåŒ–é€™äº›ç·šæ¢
                    explicit_vertical_lines = [
                        45,   90,  135,    210,         460,    500,  550 # ç²—ç•¥ä¼°è¨ˆçš„Xåæ¨™
                    ]
                    
                    # è£åˆ‡é é¢ä»¥å°ˆæ³¨æ–¼è¡¨æ ¼å€åŸŸï¼Œé¿å…é é¢é ‚éƒ¨å’Œåº•éƒ¨çš„éè¡¨æ ¼æ–‡å­—
                    # å°æ–¼æˆç¸¾ç¸½è¡¨ï¼Œè¡¨æ ¼å…§å®¹å¤§è‡´å¾ Y=180 å·¦å³é–‹å§‹
                    # page.height - 50 æ˜¯ç‚ºäº†é¿å…è£åˆ‡åˆ°é è…³è³‡è¨Šï¼Œå¦‚æœè¡¨æ ¼å»¶ä¼¸åˆ°é åº•ï¼Œå¯èƒ½éœ€è¦èª¿æ•´ç‚º page.height
                    cropped_page = page.crop((0, 180, page.width, page.height - 50)) 

                    table_settings = {
                        "vertical_strategy": "explicit", # æ˜ç¢ºæŒ‡å®šå‚ç›´ç·š
                        "horizontal_strategy": "lines", # ä¾è³´æ°´å¹³ç·šä¾†å€åˆ†è¡Œ
                        "explicit_vertical_lines": explicit_vertical_lines,
                        "snap_tolerance": 5, # å¢åŠ å°é½Šå®¹å¿åº¦
                    }
                    
                    tables = cropped_page.extract_tables(table_settings)

                    for table_idx, table in enumerate(tables):
                        if not table or len(table) < 2: # è‡³å°‘éœ€è¦é ­éƒ¨å’Œä¸€è¡Œæ•¸æ“š
                            continue

                        # æ¸…ç†è¡¨é ­ï¼Œä¸¦è™•ç† None å€¼
                        header = [col.replace('\n', ' ').strip() if col is not None else "" for col in table[0]]
                        
                        # å»ºç«‹ä¸€å€‹æ˜ å°„ï¼Œå¾æå–åˆ°çš„åˆ—ååˆ°æ¨™æº–åˆ—åï¼Œä¸¦è¨˜éŒ„ç´¢å¼•
                        # é€™ä½¿å¾—ç¨‹å¼ç¢¼å°åˆ—é †åºå’Œåç¨±è®ŠåŒ–æ›´å¥å£¯
                        col_to_index = {} # å­˜æ”¾æ¨™æº–åˆ—å -> æå–è¡¨æ ¼ä¸­çš„ç´¢å¼•
                        index_to_col = {} # å­˜æ”¾æå–è¡¨æ ¼ä¸­çš„ç´¢å¼• -> æ¨™æº–åˆ—å

                        for i, h_ext in enumerate(header):
                            if "å­¸å¹´åº¦" in h_ext: col_to_index["å­¸å¹´åº¦"] = i; index_to_col[i] = "å­¸å¹´åº¦"
                            elif "å­¸æœŸ" in h_ext: col_to_index["å­¸æœŸ"] = i; index_to_col[i] = "å­¸æœŸ"
                            elif "é¸èª²ä»£è™Ÿ" in h_ext: col_to_index["é¸èª²ä»£è™Ÿ"] = i; index_to_col[i] = "é¸èª²ä»£è™Ÿ"
                            elif "ç§‘ç›®åç¨±" in h_ext: col_to_index["ç§‘ç›®åç¨±"] = i; index_to_col[i] = "ç§‘ç›®åç¨±"
                            elif "å­¸åˆ†" in h_ext: col_to_index["å­¸åˆ†"] = i; index_to_col[i] = "å­¸åˆ†"
                            elif "GPA" in h_ext: col_to_index["GPA"] = i; index_to_col[i] = "GPA"
                            # å°æ–¼å…¶ä»–æœªè­˜åˆ¥çš„åˆ—ï¼Œå¦‚æœéœ€è¦ï¼Œå¯ä»¥çµ¦å®ƒå€‘ä¸€å€‹è‡¨æ™‚åç¨±
                            # else: index_to_col[i] = f"Unknown_Col_{i}"

                        # æª¢æŸ¥æ‰€æœ‰é—œéµåˆ—æ˜¯å¦éƒ½è¢«è­˜åˆ¥
                        critical_cols_found = all(col in col_to_index for col in ["å­¸å¹´åº¦", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"])
                        if not critical_cols_found:
                            continue # å¦‚æœé—œéµåˆ—ç¼ºå¤±ï¼Œè·³éæ­¤è¡¨æ ¼

                        # å‹•æ…‹ç²å–é—œéµåˆ—çš„ç´¢å¼•
                        å­¸å¹´åº¦_idx = col_to_index.get("å­¸å¹´åº¦")
                        ç§‘ç›®åç¨±_idx = col_to_index.get("ç§‘ç›®åç¨±")
                        å­¸åˆ†_idx = col_to_index.get("å­¸åˆ†")
                        GPA_idx = col_to_index.get("GPA")

                        processed_rows = []
                        current_row_data = None # ç”¨æ–¼çµ„åˆè·¨è¡Œæ•¸æ“š

                        for row in table[1:]: # å¾æ•¸æ“šè¡Œé–‹å§‹
                            # æ¸…ç†ç•¶å‰è¡Œçš„æ‰€æœ‰å–®å…ƒæ ¼
                            cleaned_row = [c.replace('\n', ' ').strip() if c is not None else "" for c in row]
                            
                            # åˆ¤æ–·æ˜¯å¦ç‚ºæ–°çš„ä¸€è¡Œæˆç¸¾è¨˜éŒ„ï¼šæª¢æŸ¥ã€Œå­¸å¹´åº¦ã€åˆ—æ˜¯å¦æœ‰ä¸‰ä½æ•¸å­—
                            if å­¸å¹´åº¦_idx is not None and cleaned_row[å­¸å¹´åº¦_idx].isdigit() and len(cleaned_row[å­¸å¹´åº¦_idx]) == 3:
                                if current_row_data:
                                    # å¦‚æœæœ‰ä¹‹å‰æœªå®Œæˆçš„è¡Œï¼Œå…ˆå°‡å…¶ä¿å­˜
                                    processed_rows.append(current_row_data)
                                # é–‹å§‹æ–°çš„è¡Œæ•¸æ“š
                                current_row_data = cleaned_row
                            elif current_row_data and å­¸å¹´åº¦_idx is not None and cleaned_row[å­¸å¹´åº¦_idx] == '':
                                # åˆ¤æ–·æ˜¯å¦ç‚ºã€Œç§‘ç›®åç¨±ã€çš„çºŒè¡Œ (å­¸å¹´åº¦ç‚ºç©ºï¼Œä¸”ç§‘ç›®åç¨±æœ‰å…§å®¹)
                                if ç§‘ç›®åç¨±_idx is not None and cleaned_row[ç§‘ç›®åç¨±_idx] != '':
                                    # å°‡ç•¶å‰è¡Œçš„ç§‘ç›®åç¨±å…§å®¹åˆä½µåˆ°å‰ä¸€è¡Œ
                                    current_row_data[ç§‘ç›®åç¨±_idx] += " " + cleaned_row[ç§‘ç›®åç¨±_idx]
                                    # æ³¨æ„ï¼šé€™è£¡å‡è¨­åªæœ‰ç§‘ç›®åç¨±æœƒè·¨è¡Œï¼Œå¦‚æœå…¶ä»–åˆ—ä¹Ÿæœƒè·¨è¡Œï¼Œå‰‡éœ€è¦æ›´è¤‡é›œçš„åˆä½µé‚è¼¯
                                else:
                                    # å¦‚æœæ˜¯ç©ºè¡Œæˆ–å…¶ä»–ä¸ç¬¦åˆæ¨¡å¼çš„è¡Œï¼Œå‰‡çµæŸå‰ä¸€è¡Œä¸¦é–‹å§‹æ–°çš„è™•ç† (é€™è£¡æˆ‘å€‘ç›´æ¥å¿½ç•¥)
                                    # é€™é˜²æ­¢äº†ç©ºè¡Œè¢«éŒ¯èª¤åœ°åˆä½µ
                                    if current_row_data:
                                        processed_rows.append(current_row_data)
                                    current_row_data = None
                            else: # ä¸ç¬¦åˆæ–°è¡Œæˆ–çºŒè¡Œçš„æ¨¡å¼ï¼Œå¯èƒ½æ˜¯è¡¨æ ¼å¤–çš„æ–‡å­—æˆ–é›œé …ï¼Œç›´æ¥å¿½ç•¥
                                if current_row_data: # å¦‚æœæœ‰æ•¸æ“šæ­£åœ¨è™•ç†ï¼Œå‰‡çµæŸä¸¦ä¿å­˜
                                    processed_rows.append(current_row_data)
                                current_row_data = None


                        if current_row_data: # æ·»åŠ æœ€å¾Œè™•ç†å®Œçš„è¡Œ
                            processed_rows.append(current_row_data)

                        if processed_rows:
                            # ä½¿ç”¨è™•ç†å¾Œçš„è¡Œæ•¸æ“šå‰µå»º DataFrame
                            df_table = pd.DataFrame(processed_rows)
                            
                            # ä½¿ç”¨ index_to_col å­—å…¸é€²è¡Œåˆ—é‡å‘½åï¼Œç¢ºä¿æ­£ç¢ºçš„æ¨™æº–åˆ—å
                            df_table.rename(columns=index_to_col, inplace=True)
                            
                            # ç¢ºä¿æ‰€æœ‰é æœŸåˆ—éƒ½å­˜åœ¨ï¼Œå¦‚æœç¼ºå¤±å‰‡æ·»åŠ ä¸¦å¡«å…… NaN
                            for col_name in expected_columns_order:
                                if col_name not in df_table.columns:
                                    df_table[col_name] = pd.NA
                            
                            # åªä¿ç•™é æœŸåˆ—ï¼Œä¸¦æŒ‰æ­£ç¢ºé †åºæ’åˆ—
                            df_table = df_table[expected_columns_order].copy() # ä½¿ç”¨ .copy() é¿å… SettingWithCopyWarning
                            
                            # æœ€çµ‚æ¸…ç†æ•¸æ“šè¡Œä¸­çš„ 'None' å’Œ 'nan' å­—ä¸²
                            for col in df_table.columns:
                                df_table[col] = df_table[col].astype(str).str.strip().str.replace('None', '').replace('nan', '')

                            all_grades_data.append(df_table)
                
            if not all_grades_data:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼æˆ–èª¿æ•´è¡¨æ ¼æå–è¨­å®šã€‚")
                # å¦‚æœæ²’æœ‰æå–åˆ°ä»»ä½•æ•¸æ“šï¼Œåˆå§‹åŒ–ä¸€å€‹ç©ºçš„ DataFrameï¼Œé¿å…å¾ŒçºŒéŒ¯èª¤
                full_grades_df = pd.DataFrame(columns=expected_columns_order)
                return

            full_grades_df = pd.concat(all_grades_data, ignore_index=True)

            # æ•¸æ“šæ¸…æ´— (é‡å°å…§å®¹æ•¸æ“š)
            full_grades_df.dropna(how='all', inplace=True) # ç§»é™¤æ‰€æœ‰åˆ—éƒ½æ˜¯ NaN çš„è¡Œ

            # éæ¿¾æ‰é‚£äº›æ˜é¡¯ä¸æ˜¯æˆç¸¾è¡Œçš„è³‡æ–™
            # ç¢ºä¿ 'å­¸å¹´åº¦' æ˜¯ä¸‰ä½æ•¸çš„æ•¸å­—
            full_grades_df = full_grades_df[
                full_grades_df['å­¸å¹´åº¦'].astype(str).str.match(r'^\d{3}$')
            ]
            
            # éæ¿¾æ‰å‹ä½œæˆç¸¾
            if 'ç§‘ç›®åç¨±' in full_grades_df.columns:
                full_grades_df = full_grades_df[~full_grades_df['ç§‘ç›®åç¨±'].astype(str).str.contains('å‹ä½œæˆç¸¾', na=False)]
            
            # GPA åˆ—æ¸…ç†
            full_grades_df['GPA'] = full_grades_df['GPA'].astype(str).str.strip()


            if not full_grades_df.empty:
                total_credits, remaining_credits, passed_courses_df = analyze_student_grades(full_grades_df)

                st.subheader("æŸ¥è©¢çµæœ âœ…")
                st.metric("ç›®å‰ç¸½å­¸åˆ†", total_credits)
                st.metric("è·é›¢ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±128å­¸åˆ†)", remaining_credits)

                st.subheader("é€šéçš„èª²ç¨‹åˆ—è¡¨ ğŸ“–")
                st.dataframe(passed_courses_df[['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']])

                with st.expander("æŸ¥çœ‹åŸå§‹æå–çš„æ•¸æ“š (ç”¨æ–¼é™¤éŒ¯)"):
                    st.dataframe(full_grades_df)
            else:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼ã€‚")

        except Exception as e:
            st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            st.info("è«‹ç¢ºèªæ‚¨çš„ PDF æ ¼å¼æ˜¯å¦ç‚ºæ¸…æ™°çš„è¡¨æ ¼ã€‚è‹¥å•é¡ŒæŒçºŒï¼Œå¯èƒ½æ˜¯ PDF çµæ§‹è¼ƒç‚ºè¤‡é›œï¼Œéœ€è¦èª¿æ•´ `pdfplumber` çš„è¡¨æ ¼æå–è¨­å®šã€‚")
            st.exception(e)

if __name__ == "__main__":
    main()
