import streamlit as st
import pandas as pd
import io
import pdfplumber

# --- 1. GPA è½‰æ›å‡½æ•¸ ---
def parse_gpa_to_numeric(gpa_str):
    """
    Converts GPA string to a numeric value for comparison.
    This mapping can be adjusted based on specific grading scales.
    For this example, we define C- and above as passing.
    """
    gpa_map = {
        'A+': 4.3, 'A': 4.0, 'A-': 3.7,
        'B+': 3.3, 'B': 3.0, 'B-': 2.7,
        'C+': 2.3, 'C': 2.0, 'C-': 1.7,
        'D+': 1.3, 'D': 1.0, 'D-': 0.7,
        'E': 0.0, 'F': 0.0,
        'æŠµå…': 999.0, # Special value for 'æŠµå…' - treated as passed for credit count
        'é€šé': 999.0  # Special value for 'é€šé' - treated as passed for credit count
    }
    # Ensure gpa_str is treated as string, then strip, then get from map
    return gpa_map.get(str(gpa_str).strip(), 0.0)

# --- 2. æˆç¸¾åˆ†æå‡½æ•¸ ---
def analyze_student_grades(df):
    """
    Analyzes a DataFrame of student grades to calculate total earned credits
    and remaining credits for graduation.
    """
    GRADUATION_REQUIREMENT = 128 # Set the total graduation requirement

    df['å­¸åˆ†'] = pd.to_numeric(df['å­¸åˆ†'], errors='coerce').fillna(0)
    
    # Ensure GPA column is string before applying parse_gpa_to_numeric
    df['GPA_Numeric'] = df['GPA'].astype(str).apply(parse_gpa_to_numeric)
    
    # Define "passed" condition: GPA_Numeric >= 1.7 OR GPA is 'æŠµå…' OR GPA is 'é€šé'
    # Use original 'GPA' column for 'æŠµå…'/'é€šé' check to avoid relying on 999.0 for actual GPA calculation
    # Also ensure å­¸åˆ† is greater than 0 for credit counting
    df['æ˜¯å¦é€šé'] = (df['GPA_Numeric'] >= 1.7) | \
                   (df['GPA'].astype(str).str.strip() == 'æŠµå…') | \
                   (df['GPA'].astype(str).str.strip() == 'é€šé')
    
    # Filter for courses that passed and have credits > 0
    passed_courses_df = df[df['æ˜¯å¦é€šé'] & (df['å­¸åˆ†'] > 0)].copy()

    # Calculate total earned credits by summing 'å­¸åˆ†' for passed courses
    total_earned_credits = passed_courses_df['å­¸åˆ†'].sum()
    
    # Calculate remaining credits: Graduation requirement minus total earned credits
    # Ensure it's not negative
    remaining_credits_to_graduate = max(0, GRADUATION_REQUIREMENT - total_earned_credits)

    return total_earned_credits, remaining_credits_to_graduate, passed_courses_df

# --- 3. å­—å…ƒæ­£è¦åŒ–å‡½æ•¸ ---
def normalize_text(text):
    """
    Normalizes specific problematic Unicode characters often found in PDF extraction
    to their standard Traditional Chinese/ASCII counterparts. Handles None input.
    """
    if text is None:
        return ""
    text = str(text).replace('\n', ' ').strip()
    # Normalize common full-width or variant characters
    text = text.replace('â½¬', 'ç›®') # CJK UNIFIED IDEOGRAPH-2F4D -> CJK UNIFIED IDEOGRAPH-76EE (ç›®)
    text = text.replace('â½‡', 'æ—¥') # CJK UNIFIED IDEOGRAPH-2F31 -> CJK UNIFIED IDEOGRAPH-65E5 (æ—¥)
    text = text.replace('ï¼ˆ', '(') # FULLWIDTH LEFT PARENTHESIS -> LEFT PARENTHESIS
    text = text.replace('ï¼‰', ')') # FULLWIDTH RIGHT PARENTHESIS -> RIGHT PARENTHESIS
    text = text.replace('â¼€', 'ä¸€') # CJK RADICAL ONE -> CJK UNIFIED IDEOGRAPH-4E00 (ä¸€)
    text = text.replace('ï¼£', 'C') # FULLWIDTH LATIN CAPITAL LETTER C -> LATIN CAPITAL LETTER C
    text = text.replace('ï¼¡', 'A') # FULLWIDTH LATIN CAPITAL LETTER A -> LATIN CAPITAL LETTER A
    text = text.replace('ï¼¢', 'B') # FULLWIDTH LATIN CAPITAL LETTER B -> LATIN CAPITAL LETTER B
    text = text.text.replace('ï¼¤', 'D') # FULLWIDTH LATIN CAPITAL LETTER D -> LATIN CAPITAL LETTER D
    text = text.replace('ï¼¥', 'E') # FULLWIDTH LATIN CAPITAL LETTER E -> LATIN CAPITAL LETTER E
    text = text.replace('ï¼¦', 'F') # FULLWIDTH LATIN CAPITAL LETTER F -> LATIN CAPITAL LETTER F
    text = text.replace('ï¼§', 'G') # FULLWIDTH LATIN CAPITAL LETTER G -> LATIN CAPITAL LETTER G
    return text.strip() # å†æ¬¡stripä»¥é˜²æ›¿æ›å¾Œç”¢ç”Ÿå‰å¾Œç©ºæ ¼

# --- 4. è™•ç†åˆ†è¡ŒGPA/å­¸åˆ†å•é¡Œçš„å‡½æ•¸ (åœ¨æå–åŸå§‹è¡¨æ ¼å¾Œç«‹å³æ‡‰ç”¨) ---
def parse_gpa_credit_from_combined_cell(gpa_cell_content, credit_cell_content):
    """
    Handles cases where GPA and credit are combined in one cell, or extracted incorrectly.
    Returns cleaned GPA and credit values.
    """
    gpa = str(gpa_cell_content).strip()
    credit = str(credit_cell_content).strip()

    # Case 1: GPA cell contains both GPA and credit separated by newline
    if '\n' in gpa and credit == '':
        parts = gpa.split('\n')
        if len(parts) == 2:
            # The order might be GPA \n Credit or Credit \n GPA.
            # We need to determine which is which.
            gpa_candidate = parts[0].strip()
            credit_candidate = parts[1].strip()

            # If credit_candidate looks like a number, and gpa_candidate looks like a GPA grade
            if credit_candidate.replace('.', '').isdigit() and (gpa_candidate.isalpha() or gpa_candidate in ['æŠµå…', 'é€šé']):
                return gpa_candidate, credit_candidate
            elif gpa_candidate.replace('.', '').isdigit() and (credit_candidate.isalpha() or credit_candidate in ['æŠµå…', 'é€šé']):
                # If it's reversed (Credit \n GPA)
                return credit_candidate, gpa_candidate
            
    # Case 2: Credit cell contains both GPA and credit separated by newline
    if '\n' in credit and gpa == '':
        parts = credit.split('\n')
        if len(parts) == 2:
            credit_candidate = parts[0].strip()
            gpa_candidate = parts[1].strip()
            if credit_candidate.replace('.', '').isdigit() and (gpa_candidate.isalpha() or gpa_candidate in ['æŠµå…', 'é€šé']):
                return gpa_candidate, credit_candidate
            elif gpa_candidate.replace('.', '').isdigit() and (credit_candidate.isalpha() or credit_candidate in ['æŠµå…', 'é€šé']):
                 # If it's reversed (GPA \n Credit)
                return credit_candidate, gpa_candidate
    
    # Return original values if no specific pattern is matched
    return gpa, credit

# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é«” ---
def main():
    st.title("ç¸½å­¸åˆ†æŸ¥è©¢ç³»çµ± ğŸ“")
    st.write("è«‹ä¸Šå‚³æ‚¨çš„æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆï¼Œç³»çµ±å°‡æœƒç‚ºæ‚¨æŸ¥è©¢ç›®å‰ç¸½å­¸åˆ†èˆ‡è·é›¢ç•¢æ¥­æ‰€éœ€çš„å­¸åˆ†ã€‚")
    st.info("ğŸ’¡ ç¢ºä¿æ‚¨çš„æˆç¸¾å–® PDF æ˜¯æ¸…æ™°çš„è¡¨æ ¼æ ¼å¼ï¼Œä»¥ç²å¾—æœ€ä½³è§£ææ•ˆæœã€‚")

    uploaded_file = st.file_uploader("ä¸Šå‚³æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆ", type=["pdf"])

    if uploaded_file is not None:
        st.success("æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼æ­£åœ¨åˆ†æä¸­...")

        try:
            all_grades_data = []
            # ç¢ºä¿æ¬„ä½åç¨±èˆ‡ PDF ä¸­å¯¦éš›æå–å‡ºçš„åç¨±ä¸€è‡´
            # é€™äº›æ˜¯æ‚¨ PDF ä¸­è¡¨é ­å¯èƒ½å‡ºç¾çš„è©ï¼Œç”¨æ–¼åˆ¤æ–·åˆ—
            expected_header_keywords = ["å­¸å¹´åº¦", "å­¸æœŸ", "é¸èª²ä»£è™Ÿ", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]
            
            with pdfplumber.open(io.BytesIO(uploaded_file.getvalue())) as pdf:
                total_pages = len(pdf.pages)

                for page_num, page in enumerate(pdf.pages):
                    # æ ¹æ“šç¶“é©—ï¼Œå‰å¹¾è¡Œå¯èƒ½æ˜¯æ¨™é¡Œæˆ–ç„¡é—œä¿¡æ¯ï¼Œå¯ä»¥è£å‰ªæ‰
                    # è¬äº‘ç‘„æˆç¸¾ç¸½è¡¨.pdf çš„ç¬¬ä¸€é ç´„ 70 pixel ä»¥ä¸‹æ˜¯è¡¨æ ¼é–‹å§‹
                    # å…¶ä»–é é¢å¯èƒ½ä¸éœ€è¦é€™éº¼é«˜çš„è£å‰ª
                    # é‚±æ—­å»·çš„PDFç¬¬ä¸€é è¡¨æ ¼ä½ç½®è¼ƒä½ï¼Œä½†ç¬¬äºŒé é–‹å§‹å°±æ¯”è¼ƒå›ºå®š
                    top_y_crop = 170 if page_num == 0 else 50 # é‡å°ç¬¬ä¸€é åšæ›´å¤šè£å‰ª
                    bottom_y_crop = page.height - 30 # ä¿ç•™åº•éƒ¨30åƒç´ ç”¨æ–¼é ç¢¼/ç¶²å€ï¼Œé¿å…å½±éŸ¿è¡¨æ ¼

                    cropped_page = page.crop((0, top_y_crop, page.width, bottom_y_crop)) 
                    
                    # é‡å° pdfplumber 0.7.0 ç‰ˆæœ¬èª¿æ•´ table_settings
                    # 0.7.0 ç‰ˆæœ¬æ²’æœ‰ horizontal_strategy å’Œ vertical_strategy
                    # è€Œæ˜¯ä½¿ç”¨ table_settings ä¾†æ§åˆ¶è¡¨æ ¼æå–
                    table_settings = {
                        "vertical_strategy": "lines", # å˜—è©¦ç”¨ lines ç­–ç•¥ï¼Œè‹¥ä¸è¡Œå¯æ”¹ç‚º "text"
                        "horizontal_strategy": "lines", # å˜—è©¦ç”¨ lines ç­–ç•¥ï¼Œè‹¥ä¸è¡Œå¯æ”¹ç‚º "text"
                        "snap_tolerance": 3, # å¢åŠ å®¹éŒ¯åº¦ï¼Œå…è¨±ç·šæ¢æœ‰å°åå·®
                        "text_tolerance": 3, # å¢åŠ æ–‡å­—å®¹éŒ¯åº¦
                        "join_tolerance": 3, # å¢åŠ åˆä½µå®¹éŒ¯åº¦
                        "edge_min_length": 3, # æœ€å°é‚Šé•·ï¼Œé¿å…æå–åˆ°é›œè¨Š
                        "min_words_horizontal": 1, # ä¸€è¡Œæœ€å°‘ä¸€å€‹è©
                        "min_words_vertical": 1 # ä¸€åˆ—æœ€å°‘ä¸€å€‹è©
                    }
                    
                    tables = cropped_page.extract_tables(table_settings)
                    
                    if not tables:
                        continue # å¦‚æœç•¶å‰é é¢æ²’æœ‰æå–åˆ°è¡¨æ ¼ï¼Œç›´æ¥è·³é

                    for table_idx, table in enumerate(tables):
                        if not table or len(table) < 1: 
                            continue

                        # å°æ¯å€‹å–®å…ƒæ ¼å…ˆè½‰å­—ä¸²å† stripï¼Œä¸¦éæ¿¾æ‰å®Œå…¨ç©ºè¡Œ
                        # åœ¨é€™è£¡æ‡‰ç”¨ normalize_text
                        filtered_table = [
                            [normalize_text(cell) for cell in row]
                            for row in table if any(normalize_text(cell).strip() for cell in row)
                        ]
                        if not filtered_table:
                            continue
                        
                        header_row_found = False
                        header = []
                        header_row_start_idx = -1 # åˆå§‹åŒ–ç‚º-1ï¼Œè¡¨ç¤ºæ•¸æ“šå¾ç¬¬0è¡Œé–‹å§‹

                        # å°‹æ‰¾è¡¨é ­ï¼šæª¢æŸ¥å‰å¹¾è¡Œæ˜¯å¦åŒ…å«é—œéµå­—
                        # æª¢æŸ¥å‰5è¡Œï¼Œå› ç‚ºè¡¨é ­å¯èƒ½ä½”å¤šè¡Œ
                        potential_header_search_range = min(len(filtered_table), 5)
                        for h_idx in range(potential_header_search_range):
                            h_row_cells = [cell for cell in filtered_table[h_idx]] # å·²ç¶“é normalize_text
                            
                            # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„é—œéµå­—ä¾†è­˜åˆ¥ç‚ºè¡¨é ­
                            # è‡³å°‘åŒ…å« "å­¸å¹´åº¦", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"
                            # ç”±æ–¼è¡¨é ­å¯èƒ½å¤šè¡Œé¡¯ç¤ºï¼Œé€™è£¡åªéœ€è¦åˆ¤æ–·æ˜¯å¦å­˜åœ¨é—œéµå­—ï¼Œä¸è¦æ±‚å®Œå…¨åŒ¹é…å–®ä¸€åˆ—å
                            # é€™è£¡æ›´å¯¬é¬†ä¸€äº›ï¼Œåªè¦åŒ…å«ä¸»è¦å¹¾å€‹å°±èªç‚ºæ˜¯è¡¨é ­
                            if all(any(kw in cell for cell in h_row_cells) for kw in ["å­¸å¹´åº¦", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]):
                                header = h_row_cells
                                header_row_found = True
                                header_row_start_idx = h_idx
                                break
                        
                        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ˜ç¢ºçš„è¡¨é ­ï¼Œå˜—è©¦å°‡é æœŸåˆ—ä½œç‚ºè¡¨é ­ï¼Œä¸¦å‡è¨­æ•¸æ“šå¾ç¬¬ä¸€è¡Œé–‹å§‹
                        if not header_row_found:
                            # æª¢æŸ¥ç¬¬ä¸€è¡Œæ•¸æ“šæ˜¯å¦åƒæˆç¸¾æ•¸æ“šï¼ˆå­¸å¹´åº¦æ˜¯3ä½æ•¸å­—ï¼‰
                            if len(filtered_table[0]) > 0 and filtered_table[0][0].isdigit() and len(filtered_table[0][0]) == 3:
                                header = expected_header_keywords # å‡è¨­åˆ—é †åºèˆ‡é æœŸä¸€è‡´
                                header_row_start_idx = -1 # è¡¨ç¤ºæ•¸æ“šå¾ filtered_table[0] é–‹å§‹
                                header_row_found = True # æ¨™è¨˜ç‚ºæ‰¾åˆ°è¡¨é ­ (é»˜èªè¡¨é ­)
                            else:
                                continue # å¦‚æœä¸åƒæ•¸æ“šè¡Œï¼Œå‰‡è·³éæ­¤è¡¨æ ¼

                        # å‹•æ…‹æ˜ å°„åˆ—ååˆ°ç´¢å¼•
                        col_to_index = {}
                        # å˜—è©¦æ ¹æ“šé—œéµå­—æŸ¥æ‰¾åˆ—çš„ç´¢å¼•ï¼Œå„ªå…ˆåŒ¹é…å®Œæ•´åç¨±
                        # è™•ç†è¡¨é ­å–®å­—æ›è¡Œå•é¡Œï¼Œä¾‹å¦‚ "å­¸\nå¹´\nåº¦"
                        for i, h_text in enumerate(header):
                            if "å­¸å¹´åº¦" in h_text.replace(' ', ''): col_to_index["å­¸å¹´åº¦"] = i
                            elif "å­¸æœŸ" in h_text.replace(' ', ''): col_to_index["å­¸æœŸ"] = i
                            elif "é¸èª²ä»£è™Ÿ" in h_text.replace(' ', ''): col_to_index["é¸èª²ä»£è™Ÿ"] = i
                            elif "ç§‘ç›®åç¨±" in h_text.replace(' ', ''): col_to_index["ç§‘ç›®åç¨±"] = i
                            elif "å­¸åˆ†" in h_text.replace(' ', ''): col_to_index["å­¸åˆ†"] = i
                            elif "GPA" in h_text.replace(' ', ''): col_to_index["GPA"] = i

                        # æª¢æŸ¥æ˜¯å¦æ‰¾åˆ°æ‰€æœ‰é—œéµåˆ—
                        critical_cols = ["å­¸å¹´åº¦", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]
                        if not all(col in col_to_index for col in critical_cols):
                            # å¦‚æœç¼ºå°‘é—œéµåˆ—ï¼Œå‰‡è·³éæ­¤è¡¨æ ¼ (æˆ–æ‰“å°è­¦å‘Š)
                            # st.warning(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} ç¼ºå°‘é—œéµåˆ—ï¼Œè·³éã€‚")
                            continue

                        # ç²å–é—œéµåˆ—çš„ç´¢å¼• (ä½¿ç”¨ .get() ç¢ºä¿å®‰å…¨ï¼Œå¦‚æœæ²’æœ‰æ‰¾åˆ°å‰‡ç‚º None)
                        å­¸å¹´åº¦_idx = col_to_index.get("å­¸å¹´åº¦")
                        å­¸æœŸ_idx = col_to_index.get("å­¸æœŸ")
                        é¸èª²ä»£è™Ÿ_idx = col_to_index.get("é¸èª²ä»£è™Ÿ")
                        ç§‘ç›®åç¨±_idx = col_to_index.get("ç§‘ç›®åç¨±")
                        å­¸åˆ†_idx = col_to_index.get("å­¸åˆ†")
                        GPA_idx = col_to_index.get("GPA")

                        # æ§‹å»ºæ–°çš„æ•¸æ“šè¡Œ
                        processed_rows = []
                        # current_row_data_temp å„²å­˜ç•¶å‰æ­£åœ¨è™•ç†çš„è¡Œæ•¸æ“šï¼Œç”¨æ–¼åˆä½µè·¨è¡Œå…§å®¹
                        current_row_data_temp = [None] * len(expected_header_keywords) 

                        # ç¢ºå®šå¾ filtered_table çš„å“ªä¸€è¡Œé–‹å§‹è™•ç†æ•¸æ“š
                        data_rows_to_process = filtered_table[header_row_start_idx + 1:] if header_row_start_idx != -1 else filtered_table[:]

                        for row_num_in_table, row_cells in enumerate(data_rows_to_process):
                            # éæ¿¾æ‰åªåŒ…å«ç©ºå­—ä¸²æˆ– None çš„è¡Œ
                            if not any(cell.strip() for cell in row_cells):
                                continue

                            # ç¢ºä¿è¡Œè¶³å¤ é•·ï¼Œé¿å…ç´¢å¼•è¶Šç•Œ
                            max_idx_needed = -1
                            for idx in [å­¸å¹´åº¦_idx, å­¸æœŸ_idx, é¸èª²ä»£è™Ÿ_idx, ç§‘ç›®åç¨±_idx, å­¸åˆ†_idx, GPA_idx]:
                                if idx is not None:
                                    max_idx_needed = max(max_idx_needed, idx)
                            
                            # ç²å–é—œéµåˆ—çš„å€¼
                            å­¸å¹´åº¦_val = row_cells[å­¸å¹´åº¦_idx] if å­¸å¹´åº¦_idx is not None and å­¸å¹´åº¦_idx < len(row_cells) else ''
                            é¸èª²ä»£è™Ÿ_val = row_cells[é¸èª²ä»£è™Ÿ_idx] if é¸èª²ä»£è™Ÿ_idx is not None and é¸èª²ä»£è™Ÿ_idx < len(row_cells) else ''
                            ç§‘ç›®åç¨±_val = row_cells[ç§‘ç›®åç¨±_idx] if ç§‘ç›®åç¨±_idx is not None and ç§‘ç›®åç¨±_idx < len(row_cells) else ''
                            å­¸åˆ†_val = row_cells[å­¸åˆ†_idx] if å­¸åˆ†_idx is not None and å­¸åˆ†_idx < len(row_cells) else ''
                            GPA_val = row_cells[GPA_idx] if GPA_idx is not None and GPA_idx < len(row_cells) else ''

                            # åˆ¤æ–·æ˜¯å¦ç‚ºæ–°æˆç¸¾è¡Œ
                            # æ–°è¡Œçš„æ¨™èªŒï¼šå­¸å¹´åº¦æ˜¯3ä½æ•¸å­— AND é¸èª²ä»£è™Ÿæˆ–ç§‘ç›®åç¨±ä¸ç‚ºç©º
                            is_new_grade_row = False
                            if å­¸å¹´åº¦_val.isdigit() and len(å­¸å¹´åº¦_val) == 3 and \
                               (é¸èª²ä»£è™Ÿ_val.strip() != '' or ç§‘ç›®åç¨±_val.strip() != ''):
                                is_new_grade_row = True
                            
                            if is_new_grade_row:
                                # å¦‚æœæ˜¯æ–°æˆç¸¾è¡Œï¼Œå‰‡å°‡ä¸Šä¸€è¡Œçš„ç´¯ç©æ•¸æ“šæ·»åŠ åˆ° processed_rows
                                if current_row_data_temp and any(x is not None and x.strip() for x in current_row_data_temp):
                                    processed_rows.append(current_row_data_temp[:]) # æ·»åŠ å‰¯æœ¬
                                
                                # åˆå§‹åŒ–æ–°çš„ current_row_data_temp
                                current_row_data_temp = [""] * len(expected_header_keywords) # åˆå§‹åŒ–ç‚ºç©ºå­—ä¸²

                                # å¡«å……æ–°è¡Œçš„æ•¸æ“š
                                if å­¸å¹´åº¦_idx is not None: current_row_data_temp[expected_header_keywords.index("å­¸å¹´åº¦")] = å­¸å¹´åº¦_val
                                if å­¸æœŸ_idx is not None: current_row_data_temp[expected_header_keywords.index("å­¸æœŸ")] = (row_cells[å­¸æœŸ_idx] if å­¸æœŸ_idx < len(row_cells) else '')
                                if é¸èª²ä»£è™Ÿ_idx is not None: current_row_data_temp[expected_header_keywords.index("é¸èª²ä»£è™Ÿ")] = é¸èª²ä»£è™Ÿ_val
                                if ç§‘ç›®åç¨±_idx is not None: current_row_data_temp[expected_header_keywords.index("ç§‘ç›®åç¨±")] = ç§‘ç›®åç¨±_val
                                if å­¸åˆ†_idx is not None: current_row_data_temp[expected_header_keywords.index("å­¸åˆ†")] = å­¸åˆ†_val
                                if GPA_idx is not None: current_row_data_temp[expected_header_keywords.index("GPA")] = GPA_val
                                
                                # åœ¨é€™è£¡è™•ç†å–®å…ƒæ ¼å…§ GPA/å­¸åˆ†æ··å¯«çš„æƒ…æ³
                                current_gpa, current_credit = parse_gpa_credit_from_combined_cell(
                                    current_row_data_temp[expected_header_keywords.index("GPA")],
                                    current_row_data_temp[expected_header_keywords.index("å­¸åˆ†")]
                                )
                                current_row_data_temp[expected_header_keywords.index("GPA")] = current_gpa
                                current_row_data_temp[expected_header_keywords.index("å­¸åˆ†")] = current_credit

                            elif current_row_data_temp: 
                                # è™•ç†è·¨è¡Œæ•¸æ“šï¼ˆç§‘ç›®åç¨±æˆ–GPA/å­¸åˆ†å¯èƒ½æ›è¡Œï¼‰
                                # åˆ¤æ–·æ˜¯å¦ç‚ºçºŒè¡Œï¼šå­¸å¹´åº¦å’Œé¸èª²ä»£è™Ÿéƒ½æ‡‰è©²æ˜¯ç©ºçš„
                                is_continuation_candidate = (å­¸å¹´åº¦_val.strip() == '' and é¸èª²ä»£è™Ÿ_val.strip() == '')

                                # åˆä½µç§‘ç›®åç¨±
                                if is_continuation_candidate and ç§‘ç›®åç¨±_val.strip() != '':
                                    if current_row_data_temp[expected_header_keywords.index("ç§‘ç›®åç¨±")].strip() == "":
                                        current_row_data_temp[expected_header_keywords.index("ç§‘ç›®åç¨±")] = ç§‘ç›®åç¨±_val
                                    else:
                                        current_row_data_temp[expected_header_keywords.index("ç§‘ç›®åç¨±")] += " " + ç§‘ç›®åç¨±_val
                                
                                # åˆä½µå­¸åˆ†å’ŒGPAï¼Œä¸¦å„ªå…ˆè™•ç† `parse_gpa_credit_from_combined_cell`
                                # å¦‚æœç•¶å‰è¡Œçš„ å­¸åˆ† å’Œ GPA æ¬„ä½ä¸ç‚ºç©ºï¼Œä¸” å­¸å¹´åº¦ å’Œ é¸èª²ä»£è™Ÿ ç‚ºç©ºï¼Œå‰‡å˜—è©¦åˆä½µ
                                if is_continuation_candidate and (å­¸åˆ†_val.strip() != '' or GPA_val.strip() != ''):
                                    merged_gpa, merged_credit = parse_gpa_credit_from_combined_cell(GPA_val, å­¸åˆ†_val)
                                    
                                    # å¦‚æœå­¸åˆ†æ˜¯æ•¸å­—ï¼Œå‰‡æ›´æ–°ï¼Œå¦å‰‡ç¹¼çºŒç´¯ç©
                                    if merged_credit.replace('.', '').isdigit() and float(merged_credit) > 0:
                                        current_row_data_temp[expected_header_keywords.index("å­¸åˆ†")] = merged_credit
                                    elif current_row_data_temp[expected_header_keywords.index("å­¸åˆ†")].strip() == "" and å­¸åˆ†_val.strip() != "":
                                        current_row_data_temp[expected_header_keywords.index("å­¸åˆ†")] = å­¸åˆ†_val
                                    
                                    # å¦‚æœ GPA åƒå€‹æˆç¸¾ç­‰ç´šï¼Œå‰‡æ›´æ–°
                                    if merged_gpa.strip() != '' and (merged_gpa.isalpha() or merged_gpa in ['æŠµå…', 'é€šé']):
                                        current_row_data_temp[expected_header_keywords.index("GPA")] = merged_gpa
                                    elif current_row_data_temp[expected_header_keywords.index("GPA")].strip() == "" and GPA_val.strip() != "":
                                        current_row_data_temp[expected_header_keywords.index("GPA")] = GPA_val


                        # è™•ç†è¡¨æ ¼çš„æœ€å¾Œä¸€è¡Œ
                        if current_row_data_temp and any(x is not None and x.strip() for x in current_row_data_temp): 
                            processed_rows.append(current_row_data_temp[:])
                        
                        if processed_rows:
                            # ç¢ºä¿DataFrameçš„åˆ—åæ˜¯å›ºå®šçš„ expected_header_keywords
                            df_table = pd.DataFrame(processed_rows, columns=expected_header_keywords)
                            
                            # å°æ•´å€‹DataFrameé€²è¡Œæœ€å¾Œçš„æ¸…ç†ï¼Œå»é™¤Noneã€nanå­—ä¸²
                            for col in df_table.columns:
                                df_table[col] = df_table[col].astype(str).str.strip().replace('None', '').replace('nan', '')

                            all_grades_data.append(df_table)
                        else:
                            pass # æ²’æœ‰æå–åˆ°æœ‰æ•ˆæ•¸æ“šçš„è¡¨æ ¼å°±è·³é

            if not all_grades_data:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼æˆ–èª¿æ•´è¡¨æ ¼æå–è¨­å®šã€‚")
                # å³ä½¿æ²’æœ‰æ•¸æ“šï¼Œä¹Ÿå‰µå»ºä¸€å€‹ç©ºçš„ DataFrame ä»¥å…å¾ŒçºŒå ±éŒ¯
                full_grades_df = pd.DataFrame(columns=expected_header_keywords)
                return

            full_grades_df = pd.concat(all_grades_data, ignore_index=True)

            # å†æ¬¡æ¸…ç†æ•´å€‹DataFrameï¼Œç¢ºä¿æ²’æœ‰å®Œå…¨ç©ºè¡Œï¼Œä¸¦ä¸”æ ¹æ“šå­¸å¹´åº¦ç¯©é¸
            full_grades_df.dropna(how='all', inplace=True)
            
            # ä½¿ç”¨æ›´åš´æ ¼çš„å­¸å¹´åº¦ç¯©é¸ï¼Œç¢ºä¿æ˜¯ä¸‰ä½æ•¸å­—
            # ä¸¦æ¸…ç†é¸èª²ä»£è™Ÿä¸­çš„Noneæˆ–ç©ºå­—ä¸²
            full_grades_df = full_grades_df[
                full_grades_df['å­¸å¹´åº¦'].astype(str).str.match(r'^\d{3}$') &
                (full_grades_df['é¸èª²ä»£è™Ÿ'].astype(str).str.strip() != '') # ç¢ºä¿é¸èª²ä»£è™Ÿä¸ç‚ºç©º
            ]

            # éæ¿¾å‹ä½œæˆç¸¾ï¼Œç¢ºä¿ç§‘ç›®åç¨±åˆ—å­˜åœ¨
            if 'ç§‘ç›®åç¨±' in full_grades_df.columns:
                full_grades_df = full_grades_df[~full_grades_df['ç§‘ç›®åç¨±'].astype(str).str.contains('å‹ä½œæˆç¸¾', na=False)]
            
            # ç¢ºä¿ GPA åˆ—æ˜¯å­—ä¸²é¡å‹ä¸¦æ¸…ç†ç©ºç™½
            full_grades_df['GPA'] = full_grades_df['GPA'].astype(str).str.strip()
            full_grades_df['å­¸åˆ†'] = pd.to_numeric(full_grades_df['å­¸åˆ†'], errors='coerce').fillna(0)


            if not full_grades_df.empty:
                total_credits, remaining_credits, passed_courses_df = analyze_student_grades(full_grades_df)

                st.subheader("æŸ¥è©¢çµæœ âœ…")
                st.metric("ç›®å‰ç¸½å­¸åˆ†", total_credits)
                st.metric("è·é›¢ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±128å­¸åˆ†)", remaining_credits)

                st.subheader("é€šéçš„èª²ç¨‹åˆ—è¡¨ ğŸ“–")
                st.dataframe(passed_courses_df[['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']])

                with st.expander("æŸ¥çœ‹åŸå§‹æå–çš„æ•¸æ“š (ç”¨æ–¼é™¤éŒ¯)"):
                    st.dataframe(full_grades_df)
            else:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼ã€‚")

        except Exception as e:
            st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            st.info("è«‹ç¢ºèªæ‚¨çš„ PDF æ ¼å¼æ˜¯å¦ç‚ºæ¸…æ™°çš„è¡¨æ ¼ã€‚è‹¥å•é¡ŒæŒçºŒï¼Œå¯èƒ½æ˜¯ PDF çµæ§‹è¼ƒç‚ºè¤‡é›œï¼Œéœ€è¦èª¿æ•´ `pdfplumber` çš„è¡¨æ ¼æå–è¨­å®šã€‚")
            st.exception(e)

if __name__ == "__main__":
    main()
