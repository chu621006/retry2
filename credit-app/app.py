import streamlit as st
import pandas as pd
import pdfplumber
import re
from io import BytesIO

# --- è¼”åŠ©å‡½æ•¸ ---

def normalize_text(cell_content):
    """
    æ¨™æº–åŒ–å¾ pdfplumber æå–çš„å–®å…ƒæ ¼å…§å®¹ã€‚
    è™•ç† None å€¼ã€pdfplumber çš„ Text ç‰©ä»¶å’Œæ™®é€šå­—ä¸²ã€‚
    å°‡å¤šå€‹ç©ºç™½å­—å…ƒï¼ˆåŒ…æ‹¬æ›è¡Œï¼‰æ›¿æ›ç‚ºå–®å€‹ç©ºæ ¼ï¼Œä¸¦å»é™¤å…©ç«¯ç©ºç™½ã€‚
    æ›´ç©æ¥µåœ°ç§»é™¤éæ‰“å°å­—ç¬¦ã€‚
    """
    if cell_content is None:
        return ""

    text = ""
    if hasattr(cell_content, 'text'):
        text = str(cell_content.text)
    elif isinstance(cell_content, str):
        text = cell_content
    else:
        text = str(cell_content)
    
    # å°‡æ‰€æœ‰ç©ºç™½å­—å…ƒï¼ˆåŒ…æ‹¬æ›è¡Œã€tabã€å¤šå€‹ç©ºæ ¼ç­‰ï¼‰æ›¿æ›ç‚ºå–®å€‹ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    # ç§»é™¤æ‰€æœ‰éæ‰“å° ASCII å­—å…ƒï¼ˆä¾‹å¦‚ NULL, BEL, VT, FF ç­‰ï¼‰å’Œä¸€äº› unicode æ§åˆ¶å­—å…ƒ
    text = re.sub(r'[\x00-\x1F\x7F-\x9F]', '', text) 
    return text.strip()

def identify_gpa_and_credits(text):
    """
    è­˜åˆ¥æ–‡æœ¬ä¸­çš„å­¸åˆ†å’Œ GPAã€‚
    è¿”å› (å­¸åˆ†, GPA) çš„ tupleã€‚
    åŒæ™‚è™•ç†ã€ŒæŠµå…ã€å’Œã€Œé€šéã€æƒ…æ³ï¼Œé€™äº›æƒ…æ³é€šå¸¸æœ‰å­¸åˆ†ä½†ç„¡å¯¦éš›GPAæ•¸å€¼ã€‚
    """
    credit = None
    gpa = None
    original_text = text # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨æ–¼åˆ¤æ–·

    # æª¢æŸ¥æ˜¯å¦ç‚ºã€ŒæŠµå…ã€æˆ–ã€Œé€šéã€çš„èª²ç¨‹
    if "æŠµå…" in original_text:
        # å¾æŠµå…æ–‡å­—ä¸­å˜—è©¦æå–å­¸åˆ†ï¼Œå¦å‰‡é è¨­ç‚º0.0æˆ–æ ¹æ“šå­¸æ ¡è¦å‰‡
        # ä¾‹å¦‚ï¼šæŠµå… 3 å­¸åˆ†
        credit_match_defer = re.search(r'(\d+(\.\d+)?)\s*æŠµå…', original_text)
        if credit_match_defer:
            try:
                credit = float(credit_match_defer.group(1))
            except ValueError:
                credit = 0.0 # è‹¥è§£æä¸åˆ°ï¼Œé è¨­ç‚º0å­¸åˆ†
        else:
            credit = 0.0 # é è¨­æŠµå…çš„èª²ç¨‹å­¸åˆ†ç‚º0ï¼Œå…·é«”æ ¹æ“šå­¸æ ¡æ”¿ç­–èª¿æ•´
        gpa = "æŠµå…" # GPA è¨­ç½®ç‚ºç‰¹æ®Šæ¨™è¨˜
        return credit, gpa
    
    if "é€šé" in original_text:
        # å¾é€šéæ–‡å­—ä¸­å˜—è©¦æå–å­¸åˆ†ï¼Œå¦å‰‡é è¨­ç‚º0.0æˆ–æ ¹æ“šå­¸æ ¡è¦å‰‡
        credit_match_pass = re.search(r'(\d+(\.\d+)?)\s*é€šé', original_text)
        if credit_match_pass:
            try:
                credit = float(credit_match_pass.group(1))
            except ValueError:
                credit = 0.0 # è‹¥è§£æä¸åˆ°ï¼Œé è¨­ç‚º0å­¸åˆ†
        else:
            credit = 0.0 # é è¨­é€šéçš„èª²ç¨‹å­¸åˆ†ç‚º0ï¼Œå…·é«”æ ¹æ“šå­¸æ ¡æ”¿ç­–èª¿æ•´
        gpa = "é€šé" # GPA è¨­ç½®ç‚ºç‰¹æ®Šæ¨™è¨˜
        return credit, gpa


    # å˜—è©¦åŒ¹é…å­¸åˆ† (ä¾‹å¦‚ 2.0, 3, 2.5)
    credit_match = re.search(r'(\d+(\.\d+)?)\s*(å­¸åˆ†|credit|é»)', text, re.IGNORECASE)
    if credit_match:
        try:
            credit = float(credit_match.group(1))
        except ValueError:
            pass # è½‰æ›å¤±æ•—å‰‡ä¿æŒ None

    # å˜—è©¦åŒ¹é… GPA (ä¾‹å¦‚ 4.0, 3.7, A+, B-)
    # GPA å¯ä»¥æ˜¯æ•¸å­—ï¼Œä¹Ÿå¯ä»¥æ˜¯å­—æ¯ç­‰ç´š
    gpa_match_numeric = re.search(r'(\d(\.\d)?|\d\.\d{2}|[ABCFXabcfx][+\-]?)', text) # åŒ¹é… 0.0-4.0 æˆ–å­—æ¯ç­‰ç´š
    if gpa_match_numeric:
        gpa_str = gpa_match_numeric.group(1).upper()
        # æ’é™¤å¯èƒ½æ˜¯å­¸åˆ†çš„æ•¸å­—ï¼Œé™¤éå®ƒæ˜é¡¯æ˜¯GPA (ä¾‹å¦‚4.0)
        if '.' in gpa_str or len(gpa_str) <= 2: # ç°¡å–®åˆ¤æ–·ï¼Œæ•¸å­—æœ‰å°æ•¸é»ï¼Œæˆ–å­—æ¯ç­‰ç´šé€šå¸¸åªæœ‰1-2å­—
             try:
                gpa = float(gpa_str)
             except ValueError:
                gpa = gpa_str # å¦‚æœæ˜¯å­—æ¯ç­‰ç´šï¼Œä¿ç•™å­—ä¸²
        elif len(gpa_str) > 2 and not '.' in gpa_str:
            pass # å¦‚æœæ˜¯é•·æ•¸å­—ä¸”æ²’æœ‰å°æ•¸é»ï¼Œå¾ˆå¯èƒ½ä¸æ˜¯GPAï¼Œè·³é

    return credit, gpa

def is_grades_table(table, min_rows=5):
    """
    åˆ¤æ–·ä¸€å€‹ pdfplumber æå–çš„è¡¨æ ¼æ˜¯å¦ç‚ºæˆç¸¾è¡¨ã€‚
    é€™é€šéæª¢æŸ¥ç‰¹å®šé¡å‹çš„æ¬„ä½ï¼ˆå­¸å¹´ã€å­¸æœŸã€ç§‘ç›®åç¨±ã€å­¸åˆ†ã€GPAï¼‰çš„å…§å®¹æ¨¡å¼ä¾†å®Œæˆã€‚
    """
    if not table or not table.get("rows"):
        return False, {}, None

    rows = table["rows"]
    if len(rows) < min_rows: # ç¢ºä¿æœ‰è¶³å¤ çš„è³‡æ–™è¡Œä¾†åˆ¤æ–·
        return False, {}, None

    # ç²å–æ¨™é ­ï¼Œä¸¦æ­£è¦åŒ–ä»¥ä½œç‚ºæ½›åœ¨æ¬„ä½åç¨±
    header_row_raw = rows[0]
    header_row_normalized = [normalize_text(cell) for cell in header_row_raw]

    # ä½¿ç”¨å”¯ä¸€çš„æ¨™é ­åç¨±ï¼Œä¾‹å¦‚ 'Column_1', 'Column_2'
    normalized_columns = {f"Column_{i+1}": col_name for i, col_name in enumerate(header_row_normalized)}

    # --- ç¬¬ä¸€éšæ®µï¼šä¾æ“šæ¨™é ­æ–‡å­—ç›´æ¥åŒ¹é… ---
    identified_cols_by_header = {}
    
    # å­¸å¹´æ¬„ä½ (å„ªå…ˆåŒ¹é…å®Œæ•´é—œéµå­—ï¼Œå†åŒ¹é…éƒ¨åˆ†é—œéµå­—)
    year_keywords_full = ['å­¸å¹´åº¦', 'å­¸å¹´']
    year_keywords_partial = ['å­¸å¹´ åº¦', 'å­¸å¹´'] # åŒ…å«æ‰‹æ©Ÿç«¯å¯èƒ½çš„è®Šé«”
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in year_keywords_full):
            identified_cols_by_header['å­¸å¹´'] = col_id
            break
    if 'å­¸å¹´' not in identified_cols_by_header: # å¦‚æœå®Œæ•´é—œéµå­—æ²’æ‰¾åˆ°ï¼Œå˜—è©¦éƒ¨åˆ†é—œéµå­—
        for col_id, col_name in normalized_columns.items():
            if any(keyword in col_name for keyword in year_keywords_partial):
                identified_cols_by_header['å­¸å¹´'] = col_id
                break
            
    # å­¸æœŸæ¬„ä½
    semester_keywords_full = ['å­¸æœŸ']
    semester_keywords_partial = ['å­¸ æœŸ', 'å­¸æœŸ'] # åŒ…å«æ‰‹æ©Ÿç«¯å¯èƒ½çš„è®Šé«”
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in semester_keywords_full):
            identified_cols_by_header['å­¸æœŸ'] = col_id
            break
    if 'å­¸æœŸ' not in identified_cols_by_header: # å¦‚æœå®Œæ•´é—œéµå­—æ²’æ‰¾åˆ°ï¼Œå˜—è©¦éƒ¨åˆ†é—œéµå­—
        for col_id, col_name in normalized_columns.items():
            if any(keyword in col_name for keyword in semester_keywords_partial):
                identified_cols_by_header['å­¸æœŸ'] = col_id
                break

    # ç§‘ç›®åç¨±æ¬„ä½
    subject_keywords = ['ç§‘ç›®åç¨±', 'ç§‘ç›®', 'èª²ç¨‹åç¨±', 'èª²ç¨‹']
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in subject_keywords):
            identified_cols_by_header['ç§‘ç›®åç¨±'] = col_id
            break

    # å­¸åˆ†æ¬„ä½
    credit_keywords = ['å­¸åˆ†', 'å­¸åˆ†æ•¸', 'Credits', 'å­¸ åˆ†'] # å¢åŠ æ‰‹æ©Ÿç«¯å¯èƒ½çš„è®Šé«”
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in credit_keywords):
            identified_cols_by_header['å­¸åˆ†'] = col_id
            # æš«æ™‚å°‡GPAä¹ŸæŒ‡å‘å­¸åˆ†æ¬„ä½ï¼Œå¾ŒçºŒå†å¾å…§å®¹è§£æ
            identified_cols_by_header['GPA'] = col_id 
            break

    # GPA æ¬„ä½ (å¦‚æœå­˜åœ¨ç¨ç«‹çš„ GPA æ¬„ä½)
    gpa_keywords = ['GPA', 'å¹³å‡æˆç¸¾', 'Grade']
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in gpa_keywords):
            # å¦‚æœå­¸åˆ†å’ŒGPAéƒ½è¢«è­˜åˆ¥åˆ°åŒä¸€æ¬„ä½ï¼Œä¸”é€™æ¬¡æ‰¾åˆ°äº†æ˜ç¢ºçš„GPAæ¬„ä½ï¼Œæ›´æ–°GPAæ¬„ä½
            if 'å­¸åˆ†' in identified_cols_by_header and identified_cols_by_header['å­¸åˆ†'] == col_id:
                pass # ä¿æŒåŸæ¨£æˆ–åœ¨ä¸‹ä¸€éšæ®µå…§å®¹åˆ¤æ–·æ™‚ä¿®æ­£
            else:
                identified_cols_by_header['GPA'] = col_id
            break

    # å¦‚æœå·²ç¶“é€éæ¨™é ­è­˜åˆ¥åˆ°æ‰€æœ‰æ ¸å¿ƒæ¬„ä½ï¼Œå‰‡ç›´æ¥è¿”å›
    if identified_cols_by_header.get('ç§‘ç›®åç¨±') and \
       identified_cols_by_header.get('å­¸åˆ†') and \
       identified_cols_by_header.get('GPA'):
        # ç¢ºä¿å­¸åˆ†å’ŒGPAè‡³å°‘æœ‰ä¸€å€‹è¢«æ˜ç¢ºè­˜åˆ¥
        if identified_cols_by_header['å­¸åˆ†'] or identified_cols_by_header['GPA']:
            return True, identified_cols_by_header, header_row_normalized


    # --- ç¬¬äºŒéšæ®µï¼šè‹¥æ¨™é ­åŒ¹é…ä¸å®Œæ•´ï¼Œå‰‡ä½¿ç”¨å…§å®¹æ¨¡å¼è¼”åŠ©åˆ¤æ–· ---
    # åƒ…åœ¨æœªå®Œå…¨è­˜åˆ¥æ ¸å¿ƒæ¬„ä½æ™‚æ‰åŸ·è¡Œæ­¤éšæ®µ
    if not (identified_cols_by_header.get('ç§‘ç›®åç¨±') and \
            identified_cols_by_header.get('å­¸åˆ†') and \
            identified_cols_by_header.get('GPA')):

        sample_rows = rows[1:min(len(rows), 10)] # å¾ç¬¬ä¸€è¡Œï¼ˆå‡è¨­æ˜¯æ•¸æ“šï¼‰é–‹å§‹å–æ¨£ï¼Œæœ€å¤š10è¡Œ
        
        # å°æ¯å€‹æ¬„ä½é€²è¡Œåˆ†æ
        for col_idx, col_name in normalized_columns.items():
            # æ”¶é›†è©²æ¬„ä½çš„æ‰€æœ‰æ¨£æœ¬å…§å®¹
            col_samples = [normalize_text(row[int(col_name.split('_')[1])-1]) for row in sample_rows if len(row) > int(col_name.split('_')[1])-1]
            
            total_sample_count = len(col_samples)
            if total_sample_count == 0:
                continue

            subject_like_cells = 0
            credit_gpa_like_cells = 0
            year_like_cells = 0
            semester_like_cells = 0

            for cell_content in col_samples:
                if not cell_content:
                    continue

                # ç§‘ç›®æ¬„ä½ï¼šé€šå¸¸åŒ…å«ä¸­æ–‡ä¸”éç´”æ•¸å­—
                if re.search(r'[\u4e00-\u9fff]', cell_content) and not re.fullmatch(r'\d+(\.\d+)?', cell_content):
                    subject_like_cells += 1
                
                # å­¸åˆ†/GPAæ¬„ä½ï¼šåŒ…å«æ•¸å­—æˆ–é¡ä¼¼GPAçš„æ¨¡å¼ (ä¾‹å¦‚ 3.0, A+, 2)
                if re.search(r'(\d+(\.\d+)?|[ABCFXabcfx][+\-]?)', cell_content, re.IGNORECASE) or \
                   ("æŠµå…" in cell_content) or ("é€šé" in cell_content): # å¢åŠ å°ã€ŒæŠµå…ã€å’Œã€Œé€šéã€çš„åˆ¤æ–·
                    credit_gpa_like_cells += 1

                # å­¸å¹´æ¬„ä½ï¼šä¾‹å¦‚ 111, 109, 2023 (3-4ä½æ•¸å­—)
                if re.fullmatch(r'\d{3,4}', cell_content):
                    year_like_cells += 1
                
                # å­¸æœŸæ¬„ä½ï¼šåŒ…å« 'ä¸Š', 'ä¸‹', 'æš‘'
                if any(s in cell_content for s in ['ä¸Š', 'ä¸‹', 'æš‘']):
                    semester_like_cells += 1
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºæ½›åœ¨çš„ç›®æ¨™æ¬„ä½ï¼Œå°‡çµæœåˆä½µåˆ° identified_cols_by_header
            if subject_like_cells / total_sample_count >= 0.3 and 'ç§‘ç›®åç¨±' not in identified_cols_by_header: 
                identified_cols_by_header['ç§‘ç›®åç¨±'] = col_id
            if credit_gpa_like_cells / total_sample_count >= 0.3 and 'å­¸åˆ†' not in identified_cols_by_header: 
                identified_cols_by_header['å­¸åˆ†'] = col_id
                # å¦‚æœé‚„æ²’æœ‰æ˜ç¢ºçš„GPAæ¬„ä½ï¼Œæš«æ™‚å°‡GPAä¹ŸæŒ‡å‘é€™å€‹æ¬„ä½
                if 'GPA' not in identified_cols_by_header:
                    identified_cols_by_header['GPA'] = col_id
            if year_like_cells / total_sample_count >= 0.5 and 'å­¸å¹´' not in identified_cols_by_header: 
                identified_cols_by_header['å­¸å¹´'] = col_id
            if semester_like_cells / total_sample_count >= 0.5 and 'å­¸æœŸ' not in identified_cols_by_header: 
                identified_cols_by_header['å­¸æœŸ'] = col_id

    # æœ€çµ‚æª¢æŸ¥æ˜¯å¦æ‰€æœ‰å¿…è¦çš„æ¬„ä½éƒ½è¢«è­˜åˆ¥
    # åªè¦ç§‘ç›®å’Œå­¸åˆ†/GPAçš„è‡³å°‘ä¸€å€‹è¢«è­˜åˆ¥ï¼Œå°±èªç‚ºæ˜¯æˆç¸¾è¡¨
    if identified_cols_by_header.get('ç§‘ç›®åç¨±') and \
       (identified_cols_by_header.get('å­¸åˆ†') or identified_cols_by_header.get('GPA')):
        return True, identified_cols_by_header, header_row_normalized
    
    return False, {}, None

def calculate_total_credits(df, grades_mapping):
    """
    è¨ˆç®—ç¸½å­¸åˆ†æ•¸å’Œå¹³å‡ GPAã€‚
    ç¾åœ¨æœƒå°‡ã€ŒæŠµå…ã€å’Œã€Œé€šéã€çš„èª²ç¨‹å­¸åˆ†è¨ˆå…¥ç¸½å­¸åˆ†ï¼Œä½†ä¸è¨ˆå…¥ GPA å¹³å‡ã€‚
    """
    total_credits = 0.0
    weighted_gpa_sum = 0.0
    num_courses_for_gpa = 0

    st.write("--- è¨ˆç®—å­¸åˆ†æ•¸èˆ‡ GPA ---")

    # ç”¨äºå­˜æ”¾é€šéçš„å’Œä¸åŠæ ¼çš„ç§‘ç›®åˆ—è¡¨
    calculated_courses = []
    failed_courses = []

    for row_idx, row in df.iterrows():
        # æ¨™æº–åŒ–æ‰€æœ‰å–®å…ƒæ ¼å…§å®¹
        row_content = {k: normalize_text(v) for k, v in row.items()}
        
        # é‡æ–°æª¢æŸ¥ï¼Œç¢ºä¿æ²’æœ‰ header-like çš„å…§å®¹è¢«ç•¶ä½œæ•¸æ“šè¡Œ
        # é€™è£¡çš„ `row_content` å·²ç¶“æ˜¯ç¶“é `normalize_text` è™•ç†çš„
        header_keywords = ['å­¸å¹´ åº¦', 'å­¸ æœŸ', 'é¸èª²ä»£ è™Ÿ', 'ç§‘ç›®åç¨±', 'å­¸ åˆ†', 'GPA', 'å­¸å¹´åº¦', 'å­¸æœŸ', 'é¸èª²ä»£è™Ÿ']
        if any(keyword in str(v) for v in row_content.values() for keyword in header_keywords if v):
            st.warning(f"è©²è¡Œè¢«åˆ¤æ–·ç‚ºæ¨™é ­è¡Œæˆ–è¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚åŸå§‹è³‡æ–™åˆ—å…§å®¹: {list(row_content.values())}")
            continue

        # æ›´å»£æ³›åœ°æª¢æŸ¥è·³éæ¢ä»¶ï¼Œä¾‹å¦‚ç©ºè¡Œã€ç´”ç²¹çš„é çœ‰é è…³ä¿¡æ¯
        if not any(cell.strip() for cell in row_content.values()): # è¡Œä¸­æ‰€æœ‰å–®å…ƒæ ¼éƒ½ç‚ºç©º
            continue
        # æª¢æŸ¥è¡Œæ”¿æ€§æ–‡å­—ï¼Œé¿å…èª¤åˆ¤æ­£è¦èª²ç¨‹ç‚ºè¡Œæ”¿æ€§æ–‡å­—
        admin_keywords = ['é«”è‚²å®¤', 'æœ¬è¡¨åƒ…ä¾›æŸ¥è©¢', 'å­¸å£«ç­', 'ç ”ç©¶æ‰€', 'æˆç¸¾è­‰æ˜', 'ç¬¬', 'é ', 'ç¸½å¹³å‡', 'å­¸æ¥­å¹³å‡', 'ç¶²é ', 'å…±è¨ˆ'] # å¢åŠ â€œå…±è¨ˆâ€ä»¥è·³éç¸½çµè¡Œ
        if any(keyword in ' '.join(row_content.values()) for keyword in admin_keywords):
            continue

        # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨
        if not all(k in row_content for k in ['ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']):
            continue

        course_name = row_content.get('ç§‘ç›®åç¨±', '')
        raw_credit_gpa_content = row_content.get('å­¸åˆ†', '') 

        # å¾åŸå§‹å­¸åˆ†/GPAæ¬„ä½ä¸­è§£æå‡ºå­¸åˆ†å’ŒGPA
        parsed_credit, parsed_gpa = identify_gpa_and_credits(raw_credit_gpa_content)

        current_credit = parsed_credit
        current_gpa = parsed_gpa

        # å¦‚æœå–®ç¨çš„GPAæ¬„ä½è¢«è­˜åˆ¥å‡ºä¾†ï¼Œå‰‡å„ªå…ˆä½¿ç”¨å…¶å€¼
        if 'GPA' in row_content and row_content['GPA'] and row_content['GPA'] != raw_credit_gpa_content:
            _, gpa_from_gpa_col = identify_gpa_and_credits(row_content['GPA'])
            if gpa_from_gpa_col is not None:
                current_gpa = gpa_from_gpa_col
        
        # è™•ç†å­¸åˆ† (å³ä½¿ GPA ç„¡æ•ˆï¼Œå­¸åˆ†ä¹Ÿå¯èƒ½æœ‰æ•ˆ)
        if current_credit is None:
            # å¦‚æœå­¸åˆ†è§£æå¤±æ•—ï¼Œä½†åœ¨åŸå§‹æ–‡æœ¬ä¸­èƒ½æ‰¾åˆ°é¡ä¼¼æ•¸å­—çš„å€¼ï¼Œå˜—è©¦å¼·åˆ¶è½‰æ›
            credit_num_match = re.search(r'(\d+(\.\d+)?)', raw_credit_gpa_content)
            if credit_num_match:
                try:
                    current_credit = float(credit_num_match.group(1))
                except ValueError:
                    current_credit = 0.0 # æœ€çµ‚ä»ç„¡æ³•è§£æï¼Œè¨­ç‚º0
            else:
                current_credit = 0.0 # é è¨­ç‚º0ï¼Œä¸è¨ˆå…¥ç¸½å­¸åˆ†

        # å°æ–¼æŠµå…æˆ–é€šéçš„èª²ç¨‹ï¼Œå­¸åˆ†è¨ˆå…¥ç¸½å­¸åˆ†ï¼Œä½† GPA ä¸è¨ˆå…¥å¹³å‡
        if current_gpa in ["æŠµå…", "é€šé"]:
            total_credits += current_credit
            # é€™é¡èª²ç¨‹ä¸è¨ˆå…¥ GPA å¹³å‡
            calculated_courses.append({
                'å­¸å¹´': row_content.get('å­¸å¹´', ''),
                'å­¸æœŸ': row_content.get('å­¸æœŸ', ''),
                'ç§‘ç›®åç¨±': course_name,
                'å­¸åˆ†': current_credit,
                'GPA': current_gpa,
                'ç‹€æ…‹': current_gpa # æ¨™è¨˜ç‚ºæŠµå…æˆ–é€šé
            })
            continue # è·³éå¾ŒçºŒçš„ GPA è¨ˆç®—éƒ¨åˆ†

        # è½‰æ› GPA ç‚ºæ•¸å€¼ (å¦‚æœå®ƒæ˜¯å­—æ¯ç­‰ç´š)
        gpa_value = 0.0
        if isinstance(current_gpa, str) and current_gpa in grades_mapping:
            gpa_value = grades_mapping[current_gpa]
        elif isinstance(current_gpa, (float, int)):
            gpa_value = float(current_gpa)
        else:
            # å¦‚æœ GPA ç„¡æ•ˆï¼Œå‰‡ä¸è¨ˆå…¥ GPA è¨ˆç®—ï¼Œä½†å­¸åˆ†ä»è¨ˆå…¥ç¸½å­¸åˆ†
            calculated_courses.append({
                'å­¸å¹´': row_content.get('å­¸å¹´', ''),
                'å­¸æœŸ': row_content.get('å­¸æœŸ', ''),
                'ç§‘ç›®åç¨±': course_name,
                'å­¸åˆ†': current_credit,
                'GPA': current_gpa, # é¡¯ç¤ºè§£æåˆ°çš„åŸå§‹GPA
                'ç‹€æ…‹': 'GPA ç„¡æ•ˆ'
            })
            total_credits += current_credit
            continue 

        # ç´¯åŠ å­¸åˆ†å’ŒåŠ æ¬Š GPA
        total_credits += current_credit
        if gpa_value > 0: # åªæœ‰æœ‰æ•ˆ GPA çš„ç§‘ç›®æ‰è¨ˆå…¥åŠ æ¬Šå¹³å‡ (Fé€šå¸¸ç‚º0)
            weighted_gpa_sum += gpa_value * current_credit
            num_courses_for_gpa += 1 # è¨ˆæ•¸ç”¨æ–¼ç¢ºä¿æœ‰å¯¦éš›èª²ç¨‹åƒèˆ‡GPAè¨ˆç®—

        # åˆ¤æ–·æ˜¯å¦ç‚ºä¸åŠæ ¼ç§‘ç›® (GPA <= D-)
        is_failed = False
        if isinstance(current_gpa, str) and current_gpa.upper() in ['F', 'X', 'XF', 'E']:
            is_failed = True
        elif isinstance(gpa_value, (float, int)) and gpa_value < grades_mapping.get('D', 1.0): # D- å¯èƒ½ä½æ–¼1.0
            is_failed = True

        course_info = {
            'å­¸å¹´': row_content.get('å­¸å¹´', ''),
            'å­¸æœŸ': row_content.get('å­¸æœŸ', ''),
            'ç§‘ç›®åç¨±': course_name,
            'å­¸åˆ†': current_credit,
            'GPA': current_gpa,
            'GPAæ•¸å€¼': gpa_value # æ·»åŠ GPAæ•¸å€¼æ–¹ä¾¿æŸ¥çœ‹
        }
        
        if is_failed:
            course_info['ç‹€æ…‹'] = 'ä¸åŠæ ¼'
            failed_courses.append(course_info)
        else:
            course_info['ç‹€æ…‹'] = 'é€šé'
            calculated_courses.append(course_info)

    average_gpa = 0.0
    # ç¢ºä¿åªæœ‰ç•¶æœ‰ç§‘ç›®åƒèˆ‡ GPA è¨ˆç®—æ™‚æ‰é€²è¡Œé™¤æ³•ï¼Œé¿å…é™¤ä»¥é›¶
    if num_courses_for_gpa > 0: 
        average_gpa = weighted_gpa_sum / (total_credits if total_credits > 0 else 1) # é€™è£¡ç”¨total_creditså¯èƒ½ä¸æº–ï¼Œæ‡‰ä½¿ç”¨ num_courses_for_gpa_credits

    # é‡æ–°è¨ˆç®— num_courses_for_gpa_credits
    gpa_relevant_credits = 0.0
    for course in calculated_courses:
        if course['ç‹€æ…‹'] == 'é€šé': # å‡è¨­åªæœ‰ã€Œé€šéã€çš„èª²ç¨‹æ‰è¨ˆç®—GPAï¼Œæ’é™¤æŠµå…/ç„¡æ•ˆGPA
            if isinstance(course['GPAæ•¸å€¼'], (float, int)) and course['GPAæ•¸å€¼'] > 0: # ç¢ºä¿GPAæœ‰æ•ˆä¸”é0
                 gpa_relevant_credits += course['å­¸åˆ†']
    
    if gpa_relevant_credits > 0:
        average_gpa = weighted_gpa_sum / gpa_relevant_credits
    else:
        average_gpa = 0.0


    return total_credits, average_gpa, calculated_courses, failed_courses

def process_pdf_file(pdf_file, grades_mapping):
    """
    è™•ç†ä¸Šå‚³çš„ PDF æª”æ¡ˆï¼Œæå–è¡¨æ ¼ä¸¦è¨ˆç®—å­¸åˆ†å’Œ GPAã€‚
    """
    all_extracted_data = [] # ç”¨æ–¼å­˜å„²æ‰€æœ‰è¡Œçš„åŸå§‹å­—å…¸æ•¸æ“š

    # è¨­å®š pdfplumber çš„è¡¨æ ¼æå–åƒæ•¸
    table_settings = {
        "vertical_strategy": "text", 
        "horizontal_strategy": "text", 
        "snap_tolerance": 15,  # å¢å¤§å®¹å¿åº¦
        "join_tolerance": 18,  # å¢å¤§å®¹å¿åº¦
        "edge_min_length": 1,  # è¨­ç‚ºæ›´å°çš„å€¼
        "text_tolerance": 7,   # å¢å¤§å®¹å¿åº¦
        "min_words_vertical": 1, 
        "min_words_horizontal": 1, 
    }

    try:
        with pdfplumber.open(pdf_file) as pdf:
            for page_num, page in enumerate(pdf.pages):
                st.write(f"æ­£åœ¨è™•ç†é é¢: {page_num + 1}")
                # å˜—è©¦å¾é é¢æå–è¡¨æ ¼
                tables = page.extract_tables(table_settings)

                for table_idx, table in enumerate(tables):
                    st.write(f"  åµæ¸¬åˆ°è¡¨æ ¼ {table_idx + 1}")
                    # ä½¿ç”¨ is_grades_table åˆ¤æ–·æ˜¯å¦ç‚ºæˆç¸¾è¡¨
                    is_grade_table_result, identified_cols, original_header_normalized = is_grades_table(table)

                    if is_grade_table_result:
                        st.success(f"  é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} è¢«è­˜åˆ¥ç‚ºæˆç¸¾è¡¨ã€‚")
                        st.json({"è­˜åˆ¥åˆ°çš„å­¸å¹´æ¬„ä½": identified_cols.get('å­¸å¹´'), 
                                 "å­¸æœŸæ¬„ä½": identified_cols.get('å­¸æœŸ'),
                                 "ç§‘ç›®æ¬„ä½": identified_cols.get('ç§‘ç›®åç¨±'), 
                                 "å­¸åˆ†æ¬„ä½": identified_cols.get('å­¸åˆ†'), 
                                 "GPAæ¬„ä½": identified_cols.get('GPA')})

                        # è™•ç†åŸå§‹è¡¨æ ¼æ•¸æ“šï¼Œæº–å‚™ DataFrame
                        
                        # ç¢ºä¿ identified_cols ä¸­çš„æ¯å€‹è­˜åˆ¥åˆ°çš„ 'Column_X' éƒ½æœ‰å°æ‡‰çš„ç´¢å¼•
                        col_mapping = {}
                        for key, col_id in identified_cols.items():
                            if col_id and col_id.startswith('Column_'):
                                try:
                                    # æå– Column_X ä¸­çš„æ•¸å­— Xï¼Œè½‰æ›ç‚º 0-based index
                                    original_col_idx = int(col_id.split('_')[1]) - 1
                                    col_mapping[key] = original_col_idx
                                except ValueError:
                                    col_mapping[key] = None
                            else:
                                col_mapping[key] = None

                        # è·³éç¬¬ä¸€è¡Œï¼ˆæ¨™é ­è¡Œï¼‰ï¼Œå¾ç¬¬äºŒè¡Œé–‹å§‹è™•ç†æ•¸æ“š
                        for row_idx, row_cells in enumerate(table):
                            if row_idx == 0: # å‡è¨­ç¬¬ä¸€è¡Œæ˜¯æ¨™é ­
                                continue

                            # ç¢ºä¿è¡Œè¶³å¤ é•·ï¼Œå¯ä»¥è¨ªå•æ‰€æœ‰æ˜ å°„çš„åˆ—
                            max_idx = -1
                            if col_mapping:
                                max_idx = max(filter(lambda x: x is not None, col_mapping.values()))
                            
                            if not row_cells or len(row_cells) <= max_idx:
                                # st.warning(f"  è¡Œ {row_idx+1} (0-indexed: {row_idx}) å› é•·åº¦ä¸è¶³æˆ–ç‚ºç©ºè€Œè·³éã€‚å…§å®¹: {row_cells}")
                                continue

                            row_data = {}
                            # ä½¿ç”¨è­˜åˆ¥åˆ°çš„æ¬„ä½åç¨±å’ŒåŸå§‹ç´¢å¼•ä¾†æ§‹å»ºè¡Œæ•¸æ“š
                            for identified_key, original_col_idx in col_mapping.items():
                                if original_col_idx is not None and original_col_idx < len(row_cells):
                                    row_data[identified_key] = normalize_text(row_cells[original_col_idx])
                                else:
                                    row_data[identified_key] = "" # ç¢ºä¿æ¬„ä½å­˜åœ¨ï¼Œå³ä½¿ç‚ºç©º

                            # åƒ…ç•¶ç§‘ç›®åç¨±ä¸ç‚ºç©ºæ™‚æ‰æ·»åŠ è©²è¡Œ
                            if row_data.get('ç§‘ç›®åç¨±') and row_data.get('ç§‘ç›®åç¨±').strip():
                                all_extracted_data.append(row_data)

                    else:
                        st.info(f"  é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} æœªè­˜åˆ¥ç‚ºæˆç¸¾è¡¨ã€‚")
                        # åƒ…ç•¶ table[0] å­˜åœ¨æ™‚æ‰é¡¯ç¤ºå…§å®¹ï¼Œé¿å… IndexError
                        if table and table[0]:
                            st.warning("è©²è¡Œè¢«åˆ¤æ–·ç‚ºç©ºè¡Œã€æ¨™é ­è¡Œæˆ–è¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚åŸå§‹è³‡æ–™åˆ—å…§å®¹: " + str([normalize_text(c) for c in table[0]]))
                        else:
                            st.warning("è©²è¡Œè¢«åˆ¤æ–·ç‚ºç©ºè¡Œã€æ¨™é ­è¡Œæˆ–è¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚åŸå§‹è³‡æ–™åˆ—å…§å®¹: N/A")


    except Exception as e:
        st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame(), 0.0, 0.0, [], [] # è¿”å›ç©ºåˆ—è¡¨

    # å°‡æ‰€æœ‰æå–çš„æ•¸æ“šè½‰æ›ç‚º DataFrame
    df = pd.DataFrame(all_extracted_data)
    
    # ç¢ºä¿ DataFrame ä¸­å­˜åœ¨æ‰€æœ‰é æœŸçš„æ¬„ä½ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡æ·»åŠ ç©ºæ¬„ä½
    expected_cols = ['å­¸å¹´', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']
    for col in expected_cols:
        if col not in df.columns:
            df[col] = ''

    if df.empty:
        st.warning("æœªå¾ PDF ä¸­æå–åˆ°ä»»ä½•æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚")
        return pd.DataFrame(), 0.0, 0.0, [], [] # è¿”å›ç©ºåˆ—è¡¨

    # è¨ˆç®—ç¸½å­¸åˆ†æ•¸å’Œå¹³å‡ GPA
    total_credits, average_gpa, calculated_courses, failed_courses = calculate_total_credits(df.copy(), grades_mapping) # å‚³éå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹ df

    return df, total_credits, average_gpa, calculated_courses, failed_courses

# --- Streamlit ä»‹é¢ ---
st.title("ğŸ“ GPA åŠå­¸åˆ†è¨ˆç®—å™¨")

st.write("è«‹ä¸Šå‚³æ‚¨çš„æˆç¸¾å–® PDF æª”æ¡ˆï¼Œæˆ‘æœƒç‚ºæ‚¨è¨ˆç®—ç¸½å­¸åˆ†å’Œå¹³å‡ GPAã€‚")

# è‡ªå®šç¾© GPA ç­‰ç´šå°æ‡‰è¡¨
st.subheader("è¨­å®š GPA ç­‰ç´šå°æ‡‰è¡¨")
st.write("è«‹ç¢ºä¿æ‚¨çš„å­¸æ ¡æˆç¸¾ç­‰ç´šèˆ‡æ­¤è™•çš„ GPA å€¼å°æ‡‰æ­£ç¢ºã€‚æ‚¨å¯ä»¥ä¿®æ”¹å®ƒã€‚")

# é è¨­ GPA å°æ‡‰è¡¨
default_grades_mapping = {
    'A+': 4.3, 'A': 4.0, 'A-': 3.7,
    'B+': 3.3, 'B': 3.0, 'B-': 2.7,
    'C+': 2.3, 'C': 2.0, 'C-': 1.7,
    'D+': 1.3, 'D': 1.0, 'D-': 0.7,
    'F': 0.0, 'X': 0.0, 'XF': 0.0, # X æˆ– XF é€šå¸¸ä»£è¡¨ä¸åŠæ ¼
    'E': 0.0 # æŸäº›å­¸æ ¡å¯èƒ½ä½¿ç”¨ E ä»£è¡¨ä¸åŠæ ¼
}

# å…è¨±ç”¨æˆ¶ä¿®æ”¹å°æ‡‰è¡¨
edited_grades_mapping = {}
col1, col2 = st.columns(2)
for i, (grade, gpa_val) in enumerate(default_grades_mapping.items()):
    if i % 2 == 0:
        with col1:
            edited_grades_mapping[grade] = st.number_input(f"{grade} å°æ‡‰ GPA:", value=gpa_val, key=f"gpa_input_{grade}")
    else:
        with col2:
            edited_grades_mapping[grade] = st.number_input(f"{grade} å°æ‡‰ GPA:", value=gpa_val, key=f"gpa_input_{grade}")

uploaded_file = st.file_uploader("é¸æ“‡ä¸€å€‹ PDF æª”æ¡ˆ", type="pdf")

if uploaded_file is not None:
    st.success(f"æª”æ¡ˆ '{uploaded_file.name}' å·²æˆåŠŸä¸Šå‚³ï¼")
    
    # è®€å–æª”æ¡ˆå…§å®¹åˆ° BytesIO
    pdf_bytes = BytesIO(uploaded_file.getvalue())

    # è™•ç† PDF æª”æ¡ˆ
    with st.spinner("æ­£åœ¨è™•ç† PDFï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“..."):
        df_grades, total_credits, average_gpa, calculated_courses, failed_courses = process_pdf_file(pdf_bytes, edited_grades_mapping)
    
    if not df_grades.empty:
        st.subheader("æå–åˆ°çš„æˆç¸¾æ•¸æ“š (éƒ¨åˆ†é è¦½)")
        st.dataframe(df_grades)

        st.subheader("è¨ˆç®—çµæœ")
        st.metric("ç¸½å­¸åˆ†æ•¸", f"{total_credits:.2f}")
        st.metric("å¹³å‡ GPA", f"{average_gpa:.2f}")

        # é¡¯ç¤ºé€šéçš„ç§‘ç›®
        if calculated_courses:
            st.subheader("âœ… é€šéçš„ç§‘ç›®")
            calculated_df = pd.DataFrame(calculated_courses)
            # é¸æ“‡è¦é¡¯ç¤ºçš„åˆ—
            display_cols = ['å­¸å¹´', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA', 'ç‹€æ…‹']
            # éæ¿¾æ‰é‚£äº›åœ¨ DataFrame ä¸­ä¸å­˜åœ¨çš„åˆ—
            final_display_cols = [col for col in display_cols if col in calculated_df.columns]
            st.dataframe(calculated_df[final_display_cols], height=300, use_container_width=True)
            st.info("è«‹æ³¨æ„ï¼Œ'æŠµå…' æˆ– 'é€šé' çš„ç§‘ç›®å­¸åˆ†å·²è¨ˆå…¥ç¸½å­¸åˆ†ï¼Œä½† GPA ä¸è¨ˆå…¥å¹³å‡ã€‚")

        # é¡¯ç¤ºä¸åŠæ ¼çš„ç§‘ç›®
        if failed_courses:
            st.subheader("âŒ ä¸åŠæ ¼çš„ç§‘ç›®")
            failed_df = pd.DataFrame(failed_courses)
            # é¸æ“‡è¦é¡¯ç¤ºçš„åˆ—
            display_failed_cols = ['å­¸å¹´', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA', 'ç‹€æ…‹']
            # éæ¿¾æ‰é‚£äº›åœ¨ DataFrame ä¸­ä¸å­˜åœ¨çš„åˆ—
            final_display_failed_cols = [col for col in display_failed_cols if col in failed_df.columns]
            st.dataframe(failed_df[final_display_failed_cols], height=200, use_container_width=True)
            st.info("é€™äº›ç§‘ç›®å› æˆç¸¾ä¸åŠæ ¼ ('D', 'E', 'F' ç­‰) è€Œæœªè¨ˆå…¥ GPA å¹³å‡ã€‚")


        if calculated_courses or failed_courses:
            # ä¸‹è¼‰é€šéçš„ç§‘ç›®
            if calculated_courses:
                csv_data_passed = pd.DataFrame(calculated_courses).to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ä¸‹è¼‰é€šéçš„ç§‘ç›®åˆ—è¡¨ç‚º CSV",
                    data=csv_data_passed,
                    file_name=f"{uploaded_file.name.replace('.pdf', '')}_calculated_courses.csv",
                    mime="text/csv",
                    key="download_passed_btn"
                )
            # ä¸‹è¼‰ä¸åŠæ ¼çš„ç§‘ç›®
            if failed_courses:
                csv_data_failed = pd.DataFrame(failed_courses).to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ä¸‹è¼‰ä¸åŠæ ¼çš„ç§‘ç›®åˆ—è¡¨ç‚º CSV",
                    data=csv_data_failed,
                    file_name=f"{uploaded_file.name.replace('.pdf', '')}_failed_courses.csv",
                    mime="text/csv",
                    key="download_failed_btn"
                )
            
    else:
        st.error("æœªèƒ½å¾ä¸Šå‚³çš„ PDF æª”æ¡ˆä¸­æå–åˆ°ä»»ä½•æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æˆ–å˜—è©¦å…¶ä»–æª”æ¡ˆã€‚")
        st.info("æç¤ºï¼šç¢ºä¿æ‚¨çš„ PDF æˆç¸¾å–®æ˜¯æ–‡å­—å¯é¸å–çš„ï¼Œè€Œä¸æ˜¯åœ–ç‰‡æƒæä»¶ã€‚")

st.markdown("---")
st.write("å¦‚æœæ‚¨é‡åˆ°ä»»ä½•å•é¡Œï¼Œè«‹æª¢æŸ¥åŸå§‹ç¨‹å¼ç¢¼æˆ–æä¾›æ›´å¤šè©³ç´°è³‡è¨Šã€‚")
