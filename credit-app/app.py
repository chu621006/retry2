import streamlit as st
import pandas as pd
import pdfplumber
import re
from io import BytesIO

# --- è¼”åŠ©å‡½æ•¸ ---

def normalize_text(cell_content):
    """
    æ¨™æº–åŒ–å¾ pdfplumber æå–çš„å–®å…ƒæ ¼å…§å®¹ã€‚
    è™•ç† None å€¼ã€pdfplumber çš„ Text ç‰©ä»¶å’Œæ™®é€šå­—ä¸²ã€‚
    å°‡å¤šå€‹ç©ºç™½å­—å…ƒï¼ˆåŒ…æ‹¬æ›è¡Œï¼‰æ›¿æ›ç‚ºå–®å€‹ç©ºæ ¼ï¼Œä¸¦å»é™¤å…©ç«¯ç©ºç™½ã€‚
    æ›´ç©æ¥µåœ°ç§»é™¤éæ‰“å°å­—ç¬¦ã€‚
    """
    if cell_content is None:
        return ""

    text = ""
    if hasattr(cell_content, 'text'):
        text = str(cell_content.text)
    elif isinstance(cell_content, str):
        text = cell_content
    else:
        text = str(cell_content)
    
    # å°‡æ‰€æœ‰ç©ºç™½å­—å…ƒï¼ˆåŒ…æ‹¬æ›è¡Œã€tabã€å¤šå€‹ç©ºæ ¼ç­‰ï¼‰æ›¿æ›ç‚ºå–®å€‹ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    # ç§»é™¤æ‰€æœ‰éæ‰“å° ASCII å­—å…ƒï¼ˆä¾‹å¦‚ NULL, BEL, VT, FF ç­‰ï¼‰å’Œä¸€äº› unicode æ§åˆ¶å­—å…ƒ
    text = re.sub(r'[\x00-\x1F\x7F-\x9F]', '', text) 
    return text.strip()

def identify_gpa_and_credits(text):
    """
    è­˜åˆ¥æ–‡æœ¬ä¸­çš„å­¸åˆ†å’Œ GPAã€‚
    è¿”å› (å­¸åˆ†, GPA) çš„ tupleã€‚
    """
    credit = None
    gpa = None

    # å˜—è©¦åŒ¹é…å­¸åˆ† (ä¾‹å¦‚ 2.0, 3, 2.5)
    credit_match = re.search(r'(\d+(\.\d+)?)\s*(å­¸åˆ†|credit|é»)', text, re.IGNORECASE)
    if credit_match:
        try:
            credit = float(credit_match.group(1))
        except ValueError:
            pass # è½‰æ›å¤±æ•—å‰‡ä¿æŒ None

    # å˜—è©¦åŒ¹é… GPA (ä¾‹å¦‚ 4.0, 3.7, A+, B-)
    # GPA å¯ä»¥æ˜¯æ•¸å­—ï¼Œä¹Ÿå¯ä»¥æ˜¯å­—æ¯ç­‰ç´š
    gpa_match_numeric = re.search(r'(\d(\.\d)?|\d\.\d{2}|[ABCFXabcfx][+\-]?)', text) # åŒ¹é… 0.0-4.0 æˆ–å­—æ¯ç­‰ç´š
    if gpa_match_numeric:
        gpa_str = gpa_match_numeric.group(1).upper()
        # æ’é™¤å¯èƒ½æ˜¯å­¸åˆ†çš„æ•¸å­—ï¼Œé™¤éå®ƒæ˜é¡¯æ˜¯GPA (ä¾‹å¦‚4.0)
        if '.' in gpa_str or len(gpa_str) <= 2: # ç°¡å–®åˆ¤æ–·ï¼Œæ•¸å­—æœ‰å°æ•¸é»ï¼Œæˆ–å­—æ¯ç­‰ç´šé€šå¸¸åªæœ‰1-2å­—
             try:
                gpa = float(gpa_str)
             except ValueError:
                gpa = gpa_str # å¦‚æœæ˜¯å­—æ¯ç­‰ç´šï¼Œä¿ç•™å­—ä¸²
        elif len(gpa_str) > 2 and not '.' in gpa_str:
            pass # å¦‚æœæ˜¯é•·æ•¸å­—ä¸”æ²’æœ‰å°æ•¸é»ï¼Œå¾ˆå¯èƒ½ä¸æ˜¯GPAï¼Œè·³é

    return credit, gpa

def is_grades_table(table, min_rows=5):
    """
    åˆ¤æ–·ä¸€å€‹ pdfplumber æå–çš„è¡¨æ ¼æ˜¯å¦ç‚ºæˆç¸¾è¡¨ã€‚
    é€™é€šéæª¢æŸ¥ç‰¹å®šé¡å‹çš„æ¬„ä½ï¼ˆå­¸å¹´ã€å­¸æœŸã€ç§‘ç›®åç¨±ã€å­¸åˆ†ã€GPAï¼‰çš„å…§å®¹æ¨¡å¼ä¾†å®Œæˆã€‚
    """
    if not table or not table.get("rows"):
        return False, {}, None

    rows = table["rows"]
    if len(rows) < min_rows: # ç¢ºä¿æœ‰è¶³å¤ çš„è³‡æ–™è¡Œä¾†åˆ¤æ–·
        return False, {}, None

    # ç²å–æ¨™é ­ï¼Œä¸¦æ­£è¦åŒ–ä»¥ä½œç‚ºæ½›åœ¨æ¬„ä½åç¨±
    header_row_raw = rows[0]
    header_row_normalized = [normalize_text(cell) for cell in header_row_raw]

    # ä½¿ç”¨å”¯ä¸€çš„æ¨™é ­åç¨±ï¼Œä¾‹å¦‚ 'Column_1', 'Column_2'
    normalized_columns = {f"Column_{i+1}": col_name for i, col_name in enumerate(header_row_normalized)}

    # --- ç¬¬ä¸€éšæ®µï¼šä¾æ“šæ¨™é ­æ–‡å­—ç›´æ¥åŒ¹é… ---
    identified_cols_by_header = {}
    
    # å­¸å¹´æ¬„ä½
    year_keywords = ['å­¸å¹´', 'å­¸å¹´åº¦', 'å¹´åº¦']
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in year_keywords) and len(col_name) < 5: # é¿å…åŒ¹é…åˆ°éé•·çš„éå­¸å¹´æ–‡å­—
            identified_cols_by_header['å­¸å¹´'] = col_id
            break
            
    # å­¸æœŸæ¬„ä½
    semester_keywords = ['å­¸æœŸ', 'æœŸ']
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in semester_keywords) and len(col_name) < 5:
            identified_cols_by_header['å­¸æœŸ'] = col_id
            break

    # ç§‘ç›®åç¨±æ¬„ä½
    subject_keywords = ['ç§‘ç›®åç¨±', 'ç§‘ç›®', 'èª²ç¨‹åç¨±', 'èª²ç¨‹']
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in subject_keywords):
            identified_cols_by_header['ç§‘ç›®åç¨±'] = col_id
            break

    # å­¸åˆ†æ¬„ä½
    credit_keywords = ['å­¸åˆ†', 'å­¸åˆ†æ•¸', 'Credits']
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in credit_keywords):
            identified_cols_by_header['å­¸åˆ†'] = col_id
            # æš«æ™‚å°‡GPAä¹ŸæŒ‡å‘å­¸åˆ†æ¬„ä½ï¼Œå¾ŒçºŒå†å¾å…§å®¹è§£æ
            identified_cols_by_header['GPA'] = col_id 
            break

    # GPA æ¬„ä½ (å¦‚æœå­˜åœ¨ç¨ç«‹çš„ GPA æ¬„ä½)
    gpa_keywords = ['GPA', 'å¹³å‡æˆç¸¾', 'Grade']
    for col_id, col_name in normalized_columns.items():
        if any(keyword in col_name for keyword in gpa_keywords):
            # å¦‚æœå­¸åˆ†å’ŒGPAéƒ½è¢«è­˜åˆ¥åˆ°åŒä¸€æ¬„ä½ï¼Œä¸”é€™æ¬¡æ‰¾åˆ°äº†æ˜ç¢ºçš„GPAæ¬„ä½ï¼Œæ›´æ–°GPAæ¬„ä½
            if 'å­¸åˆ†' in identified_cols_by_header and identified_cols_by_header['å­¸åˆ†'] == col_id:
                # åˆ¤æ–·æ˜¯å¦é€™å€‹æ–°æ‰¾åˆ°çš„GPAæ¬„ä½æ›´åƒGPA (ä¾‹å¦‚ç´”æ•¸å­—æˆ–ç­‰ç´š)
                pass # ä¿æŒåŸæ¨£æˆ–åœ¨ä¸‹ä¸€éšæ®µå…§å®¹åˆ¤æ–·æ™‚ä¿®æ­£
            else:
                identified_cols_by_header['GPA'] = col_id
            break

    # å¦‚æœå·²ç¶“é€éæ¨™é ­è­˜åˆ¥åˆ°æ‰€æœ‰æ ¸å¿ƒæ¬„ä½ï¼Œå‰‡ç›´æ¥è¿”å›
    if identified_cols_by_header.get('ç§‘ç›®åç¨±') and \
       identified_cols_by_header.get('å­¸åˆ†') and \
       identified_cols_by_header.get('GPA'):
        # ç¢ºä¿å­¸åˆ†å’ŒGPAè‡³å°‘æœ‰ä¸€å€‹è¢«æ˜ç¢ºè­˜åˆ¥
        if identified_cols_by_header['å­¸åˆ†'] or identified_cols_by_header['GPA']:
            return True, identified_cols_by_header, header_row_normalized


    # --- ç¬¬äºŒéšæ®µï¼šè‹¥æ¨™é ­åŒ¹é…ä¸å®Œæ•´ï¼Œå‰‡ä½¿ç”¨å…§å®¹æ¨¡å¼è¼”åŠ©åˆ¤æ–· ---
    # åƒ…åœ¨æœªå®Œå…¨è­˜åˆ¥æ ¸å¿ƒæ¬„ä½æ™‚æ‰åŸ·è¡Œæ­¤éšæ®µ
    if not (identified_cols_by_header.get('ç§‘ç›®åç¨±') and \
            identified_cols_by_header.get('å­¸åˆ†') and \
            identified_cols_by_header.get('GPA')):

        sample_rows = rows[1:min(len(rows), 10)] # å¾ç¬¬ä¸€è¡Œï¼ˆå‡è¨­æ˜¯æ•¸æ“šï¼‰é–‹å§‹å–æ¨£ï¼Œæœ€å¤š10è¡Œ
        
        # å°æ¯å€‹æ¬„ä½é€²è¡Œåˆ†æ
        for col_idx, col_name in normalized_columns.items():
            # æ”¶é›†è©²æ¬„ä½çš„æ‰€æœ‰æ¨£æœ¬å…§å®¹
            col_samples = [normalize_text(row[int(col_name.split('_')[1])-1]) for row in sample_rows if len(row) > int(col_name.split('_')[1])-1]
            
            total_sample_count = len(col_samples)
            if total_sample_count == 0:
                continue

            subject_like_cells = 0
            credit_gpa_like_cells = 0
            year_like_cells = 0
            semester_like_cells = 0

            for cell_content in col_samples:
                if not cell_content:
                    continue

                # ç§‘ç›®æ¬„ä½ï¼šé€šå¸¸åŒ…å«ä¸­æ–‡ä¸”éç´”æ•¸å­—
                if re.search(r'[\u4e00-\u9fff]', cell_content) and not re.fullmatch(r'\d+(\.\d+)?', cell_content):
                    subject_like_cells += 1
                
                # å­¸åˆ†/GPAæ¬„ä½ï¼šåŒ…å«æ•¸å­—æˆ–é¡ä¼¼GPAçš„æ¨¡å¼ (ä¾‹å¦‚ 3.0, A+, 2)
                if re.search(r'(\d+(\.\d+)?|[ABCFXabcfx][+\-]?)', cell_content, re.IGNORECASE):
                    credit_gpa_like_cells += 1

                # å­¸å¹´æ¬„ä½ï¼šä¾‹å¦‚ 111, 109, 2023 (3-4ä½æ•¸å­—)
                if re.fullmatch(r'\d{3,4}', cell_content):
                    year_like_cells += 1
                
                # å­¸æœŸæ¬„ä½ï¼šåŒ…å« 'ä¸Š', 'ä¸‹', 'æš‘'
                if any(s in cell_content for s in ['ä¸Š', 'ä¸‹', 'æš‘']):
                    semester_like_cells += 1
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºæ½›åœ¨çš„ç›®æ¨™æ¬„ä½ï¼Œå°‡çµæœåˆä½µåˆ° identified_cols_by_header
            if subject_like_cells / total_sample_count >= 0.3 and 'ç§‘ç›®åç¨±' not in identified_cols_by_header: 
                identified_cols_by_header['ç§‘ç›®åç¨±'] = col_id
            if credit_gpa_like_cells / total_sample_count >= 0.3 and 'å­¸åˆ†' not in identified_cols_by_header: 
                identified_cols_by_header['å­¸åˆ†'] = col_id
                # å¦‚æœé‚„æ²’æœ‰æ˜ç¢ºçš„GPAæ¬„ä½ï¼Œæš«æ™‚å°‡GPAä¹ŸæŒ‡å‘é€™å€‹æ¬„ä½
                if 'GPA' not in identified_cols_by_header:
                    identified_cols_by_header['GPA'] = col_id
            if year_like_cells / total_sample_count >= 0.5 and 'å­¸å¹´' not in identified_cols_by_header: 
                identified_cols_by_header['å­¸å¹´'] = col_id
            if semester_like_cells / total_sample_count >= 0.5 and 'å­¸æœŸ' not in identified_cols_by_header: 
                identified_cols_by_header['å­¸æœŸ'] = col_id

    # æœ€çµ‚æª¢æŸ¥æ˜¯å¦æ‰€æœ‰å¿…è¦çš„æ¬„ä½éƒ½è¢«è­˜åˆ¥
    # åªè¦ç§‘ç›®å’Œå­¸åˆ†/GPAçš„è‡³å°‘ä¸€å€‹è¢«è­˜åˆ¥ï¼Œå°±èªç‚ºæ˜¯æˆç¸¾è¡¨
    if identified_cols_by_header.get('ç§‘ç›®åç¨±') and \
       (identified_cols_by_header.get('å­¸åˆ†') or identified_cols_by_header.get('GPA')):
        return True, identified_cols_by_header, header_row_normalized
    
    return False, {}, None

def calculate_total_credits(df, grades_mapping):
    """
    è¨ˆç®—ç¸½å­¸åˆ†æ•¸å’Œå¹³å‡ GPAã€‚
    """
    total_credits = 0.0
    weighted_gpa_sum = 0.0
    num_courses_for_gpa = 0

    st.write("--- è¨ˆç®—å­¸åˆ†æ•¸èˆ‡ GPA ---")

    for row_idx, row in df.iterrows():
        # æ¨™æº–åŒ–æ‰€æœ‰å–®å…ƒæ ¼å…§å®¹
        row_content = {k: normalize_text(v) for k, v in row.items()}
        
        # ç²å–åŸå§‹ Series çš„ valuesï¼Œç”¨æ–¼åˆ¤æ–·æ˜¯å¦ç‚ºæ‡‰è·³éçš„è¡Œ
        # æ³¨æ„ï¼šé€™è£¡çš„ `row.values` æ˜¯ DataFrame å¯¦éš›çš„åˆ—å€¼ï¼Œå…¶éµæ˜¯è‡ªå‹•ç”Ÿæˆçš„ 'Column_X'
        # ä½†åœ¨ `process_pdf_file` ä¸­ï¼Œæˆ‘å€‘å·²ç¶“å°‡å®ƒå€‘æ˜ å°„åˆ°äº† 'å­¸å¹´', 'å­¸æœŸ' ç­‰ã€‚
        # å› æ­¤ï¼Œé€™è£¡çš„åˆ¤æ–·æ‡‰åŸºæ–¼ `row_content` ä¸­çš„å€¼ï¼Œè€Œé `row.values()`ï¼Œ
        # ä¸”å·²åœ¨ is_grades_table å¤–å±¤è™•ç†äº† header_row_normalizedï¼Œç†è«–ä¸Šä¸æ‡‰è©²æœ‰ header è¡Œé€²åˆ°é€™è£¡ã€‚
        
        # é‡æ–°æª¢æŸ¥ï¼Œç¢ºä¿æ²’æœ‰ header-like çš„å…§å®¹è¢«ç•¶ä½œæ•¸æ“šè¡Œ
        header_keywords = ['å­¸å¹´', 'å­¸æœŸ', 'é¸èª²ä»£è™Ÿ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA', 'å­¸å¹´ åº¦', 'å­¸ æœŸ', 'é¸èª²ä»£ è™Ÿ', 'å­¸ åˆ†'] # å¢åŠ æ‰‹æ©Ÿç«¯çš„æ¨™é¡Œè®Šé«”
        # ä½¿ç”¨ str() è½‰æ›ä»¥ç¢ºä¿æ‰€æœ‰å€¼éƒ½æ˜¯å­—ä¸²ï¼Œé¿å… type error
        if any(keyword in str(v) for v in row_content.values() for keyword in header_keywords if v):
            st.warning(f"è©²è¡Œè¢«åˆ¤æ–·ç‚ºç©ºè¡Œã€æ¨™é ­è¡Œæˆ–è¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚åŸå§‹è³‡æ–™åˆ—å…§å®¹: {list(row_content.values())}")
            continue

        # æ›´å»£æ³›åœ°æª¢æŸ¥è·³éæ¢ä»¶ï¼Œä¾‹å¦‚ç©ºè¡Œã€ç´”ç²¹çš„é çœ‰é è…³ä¿¡æ¯
        if not any(cell.strip() for cell in row_content.values()): # è¡Œä¸­æ‰€æœ‰å–®å…ƒæ ¼éƒ½ç‚ºç©º
            # st.info(f"è©²è¡Œç‚ºç©ºè¡Œï¼Œå·²è·³éã€‚")
            continue
        # æª¢æŸ¥è¡Œæ”¿æ€§æ–‡å­—ï¼Œé¿å…èª¤åˆ¤æ­£è¦èª²ç¨‹ç‚ºè¡Œæ”¿æ€§æ–‡å­—
        admin_keywords = ['é«”è‚²å®¤', 'æœ¬è¡¨åƒ…ä¾›æŸ¥è©¢', 'å­¸å£«ç­', 'ç ”ç©¶æ‰€', 'æˆç¸¾è­‰æ˜', 'ç¬¬', 'é ', 'ç¸½å¹³å‡', 'å­¸æ¥­å¹³å‡', 'ç¶²é ']
        if any(keyword in ' '.join(row_content.values()) for keyword in admin_keywords):
            # st.info(f"è©²è¡Œè¢«åˆ¤æ–·ç‚ºè¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚")
            continue

        # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨
        if not all(k in row_content for k in ['ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']):
            # st.warning(f"è¡Œ {row_idx} ç¼ºå°‘å¿…è¦çš„æ¬„ä½ (ç§‘ç›®åç¨±, å­¸åˆ†, GPA)ï¼Œå·²è·³éã€‚å…§å®¹: {row_content}")
            continue

        course_name = row_content.get('ç§‘ç›®åç¨±', '')
        raw_credit_gpa_content = row_content.get('å­¸åˆ†', '') # ç”±æ–¼å­¸åˆ†å’ŒGPAå¯èƒ½åœ¨åŒä¸€æ¬„ä½ï¼Œé€™è£¡å–å…¶å…§å®¹

        # å¾åŸå§‹å­¸åˆ†/GPAæ¬„ä½ä¸­è§£æå‡ºå­¸åˆ†å’ŒGPA
        parsed_credit, parsed_gpa = identify_gpa_and_credits(raw_credit_gpa_content)

        current_credit = parsed_credit
        current_gpa = parsed_gpa

        # å¦‚æœå–®ç¨çš„GPAæ¬„ä½è¢«è­˜åˆ¥å‡ºä¾†ï¼Œå‰‡å„ªå…ˆä½¿ç”¨å…¶å€¼
        if 'GPA' in row_content and row_content['GPA'] and row_content['GPA'] != raw_credit_gpa_content:
            # å˜—è©¦å†æ¬¡è§£æä»¥ç¢ºä¿æ­£ç¢ºæ€§
            _, gpa_from_gpa_col = identify_gpa_and_credits(row_content['GPA'])
            if gpa_from_gpa_col is not None:
                current_gpa = gpa_from_gpa_col
        
        # æª¢æŸ¥æ˜¯å¦æˆåŠŸè§£æåˆ°å­¸åˆ†å’Œ GPA
        if current_credit is None:
            # st.warning(f"ç§‘ç›® '{course_name}' æœªèƒ½è§£æåˆ°å­¸åˆ†ï¼Œå·²è·³éæ­¤ç§‘ç›®è¨ˆç®—ã€‚åŸå§‹å…§å®¹: '{raw_credit_gpa_content}'")
            continue
        
        # è½‰æ› GPA ç‚ºæ•¸å€¼ (å¦‚æœå®ƒæ˜¯å­—æ¯ç­‰ç´š)
        gpa_value = 0.0
        if isinstance(current_gpa, str) and current_gpa in grades_mapping:
            gpa_value = grades_mapping[current_gpa]
        elif isinstance(current_gpa, (float, int)):
            gpa_value = float(current_gpa)
        else:
            # st.warning(f"ç§‘ç›® '{course_name}' æœªèƒ½è§£æåˆ°æœ‰æ•ˆ GPA æˆ– GPA ä¸åœ¨å°æ‡‰è¡¨ä¸­ï¼Œå·²è·³éæ­¤ç§‘ç›®è¨ˆç®—ã€‚åŸå§‹å…§å®¹: '{raw_credit_gpa_content}', è§£æçµæœ: '{current_gpa}'")
            continue # å¦‚æœ GPA ç„¡æ•ˆï¼Œå‰‡ä¸è¨ˆå…¥ GPA è¨ˆç®—

        # ç´¯åŠ å­¸åˆ†å’ŒåŠ æ¬Š GPA
        total_credits += current_credit
        if gpa_value > 0: # åªæœ‰æœ‰æ•ˆ GPA çš„ç§‘ç›®æ‰è¨ˆå…¥åŠ æ¬Šå¹³å‡
            weighted_gpa_sum += gpa_value * current_credit
            num_courses_for_gpa += 1 # è¨ˆæ•¸ç”¨æ–¼ç¢ºä¿æœ‰å¯¦éš›èª²ç¨‹åƒèˆ‡GPAè¨ˆç®—

    average_gpa = 0.0
    if total_credits > 0: # ä½¿ç”¨ total_credits ä½œç‚ºåˆ†æ¯ä¾†è¨ˆç®—å¹³å‡ GPA
        average_gpa = weighted_gpa_sum / total_credits

    return total_credits, average_gpa

def process_pdf_file(pdf_file, grades_mapping):
    """
    è™•ç†ä¸Šå‚³çš„ PDF æª”æ¡ˆï¼Œæå–è¡¨æ ¼ä¸¦è¨ˆç®—å­¸åˆ†å’Œ GPAã€‚
    """
    all_extracted_data = []

    # è¨­å®š pdfplumber çš„è¡¨æ ¼æå–åƒæ•¸
    table_settings = {
        "vertical_strategy": "text", 
        "horizontal_strategy": "text", 
        "snap_tolerance": 15,  # å¢å¤§å®¹å¿åº¦
        "join_tolerance": 18,  # å¢å¤§å®¹å¿åº¦
        "edge_min_length": 1,  # è¨­ç‚ºæ›´å°çš„å€¼
        "text_tolerance": 7,   # å¢å¤§å®¹å¿åº¦
        "min_words_vertical": 1, 
        "min_words_horizontal": 1, 
    }

    try:
        with pdfplumber.open(pdf_file) as pdf:
            for page_num, page in enumerate(pdf.pages):
                st.write(f"æ­£åœ¨è™•ç†é é¢: {page_num + 1}")
                # å˜—è©¦å¾é é¢æå–è¡¨æ ¼
                tables = page.extract_tables(table_settings)

                for table_idx, table in enumerate(tables):
                    st.write(f"  åµæ¸¬åˆ°è¡¨æ ¼ {table_idx + 1}")
                    # ä½¿ç”¨ is_grades_table åˆ¤æ–·æ˜¯å¦ç‚ºæˆç¸¾è¡¨
                    is_grade_table_result, identified_cols, original_header_normalized = is_grades_table(table)

                    if is_grade_table_result:
                        st.success(f"  é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} è¢«è­˜åˆ¥ç‚ºæˆç¸¾è¡¨ã€‚")
                        st.json({"è­˜åˆ¥åˆ°çš„å­¸å¹´æ¬„ä½": identified_cols.get('å­¸å¹´'), 
                                 "å­¸æœŸæ¬„ä½": identified_cols.get('å­¸æœŸ'),
                                 "ç§‘ç›®æ¬„ä½": identified_cols.get('ç§‘ç›®åç¨±'), 
                                 "å­¸åˆ†æ¬„ä½": identified_cols.get('å­¸åˆ†'), 
                                 "GPAæ¬„ä½": identified_cols.get('GPA')})

                        # è™•ç†åŸå§‹è¡¨æ ¼æ•¸æ“šï¼Œæº–å‚™ DataFrame
                        data_rows = []
                        
                        # ç¢ºä¿ identified_cols ä¸­çš„æ¯å€‹è­˜åˆ¥åˆ°çš„ 'Column_X' éƒ½æœ‰å°æ‡‰çš„ç´¢å¼•
                        col_mapping = {}
                        for key, col_id in identified_cols.items():
                            if col_id and col_id.startswith('Column_'):
                                try:
                                    # æå– Column_X ä¸­çš„æ•¸å­— Xï¼Œè½‰æ›ç‚º 0-based index
                                    original_col_idx = int(col_id.split('_')[1]) - 1
                                    col_mapping[key] = original_col_idx
                                except ValueError:
                                    col_mapping[key] = None
                            else:
                                col_mapping[key] = None

                        # è·³éç¬¬ä¸€è¡Œï¼ˆæ¨™é ­è¡Œï¼‰ï¼Œå¾ç¬¬äºŒè¡Œé–‹å§‹è™•ç†æ•¸æ“š
                        for row_idx, row_cells in enumerate(table):
                            if row_idx == 0: # å‡è¨­ç¬¬ä¸€è¡Œæ˜¯æ¨™é ­
                                continue

                            # ç¢ºä¿è¡Œè¶³å¤ é•·ï¼Œå¯ä»¥è¨ªå•æ‰€æœ‰æ˜ å°„çš„åˆ—
                            max_idx = -1
                            if col_mapping:
                                max_idx = max(filter(lambda x: x is not None, col_mapping.values()))
                            
                            if not row_cells or len(row_cells) <= max_idx:
                                # st.warning(f"  è¡Œ {row_idx+1} (0-indexed: {row_idx}) å› é•·åº¦ä¸è¶³æˆ–ç‚ºç©ºè€Œè·³éã€‚å…§å®¹: {row_cells}")
                                continue

                            row_data = {}
                            # ä½¿ç”¨è­˜åˆ¥åˆ°çš„æ¬„ä½åç¨±å’ŒåŸå§‹ç´¢å¼•ä¾†æ§‹å»ºè¡Œæ•¸æ“š
                            for identified_key, original_col_idx in col_mapping.items():
                                if original_col_idx is not None and original_col_idx < len(row_cells):
                                    row_data[identified_key] = normalize_text(row_cells[original_col_idx])
                                else:
                                    row_data[identified_key] = "" # ç¢ºä¿æ¬„ä½å­˜åœ¨ï¼Œå³ä½¿ç‚ºç©º

                            # åƒ…ç•¶ç§‘ç›®åç¨±ä¸ç‚ºç©ºæ™‚æ‰æ·»åŠ è©²è¡Œ
                            if row_data.get('ç§‘ç›®åç¨±') and row_data.get('ç§‘ç›®åç¨±').strip():
                                all_extracted_data.append(row_data)

                    else:
                        st.info(f"  é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} æœªè­˜åˆ¥ç‚ºæˆç¸¾è¡¨ã€‚")
                        st.warning("è©²è¡Œè¢«åˆ¤æ–·ç‚ºç©ºè¡Œã€æ¨™é ­è¡Œæˆ–è¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚åŸå§‹è³‡æ–™åˆ—å…§å®¹: " + str(original_header_normalized))


    except Exception as e:
        st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame(), 0.0, 0.0

    # å°‡æ‰€æœ‰æå–çš„æ•¸æ“šè½‰æ›ç‚º DataFrame
    df = pd.DataFrame(all_extracted_data)
    
    # ç¢ºä¿ DataFrame ä¸­å­˜åœ¨æ‰€æœ‰é æœŸçš„æ¬„ä½ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡æ·»åŠ ç©ºæ¬„ä½
    expected_cols = ['å­¸å¹´', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']
    for col in expected_cols:
        if col not in df.columns:
            df[col] = ''

    if df.empty:
        st.warning("æœªå¾ PDF ä¸­æå–åˆ°ä»»ä½•æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚")
        return pd.DataFrame(), 0.0, 0.0

    # è¨ˆç®—ç¸½å­¸åˆ†æ•¸å’Œå¹³å‡ GPA
    total_credits, average_gpa = calculate_total_credits(df.copy(), grades_mapping) # å‚³éå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹ df

    return df, total_credits, average_gpa

# --- Streamlit ä»‹é¢ ---
st.title("ğŸ“ GPA åŠå­¸åˆ†è¨ˆç®—å™¨")

st.write("è«‹ä¸Šå‚³æ‚¨çš„æˆç¸¾å–® PDF æª”æ¡ˆï¼Œæˆ‘æœƒç‚ºæ‚¨è¨ˆç®—ç¸½å­¸åˆ†å’Œå¹³å‡ GPAã€‚")

# è‡ªå®šç¾© GPA ç­‰ç´šå°æ‡‰è¡¨
st.subheader("è¨­å®š GPA ç­‰ç´šå°æ‡‰è¡¨")
st.write("è«‹ç¢ºä¿æ‚¨çš„å­¸æ ¡æˆç¸¾ç­‰ç´šèˆ‡æ­¤è™•çš„ GPA å€¼å°æ‡‰æ­£ç¢ºã€‚æ‚¨å¯ä»¥ä¿®æ”¹å®ƒã€‚")

# é è¨­ GPA å°æ‡‰è¡¨
default_grades_mapping = {
    'A+': 4.3, 'A': 4.0, 'A-': 3.7,
    'B+': 3.3, 'B': 3.0, 'B-': 2.7,
    'C+': 2.3, 'C': 2.0, 'C-': 1.7,
    'D+': 1.3, 'D': 1.0, 'D-': 0.7,
    'F': 0.0, 'X': 0.0, 'XF': 0.0 # X æˆ– XF é€šå¸¸ä»£è¡¨ä¸åŠæ ¼
}

# å…è¨±ç”¨æˆ¶ä¿®æ”¹å°æ‡‰è¡¨
edited_grades_mapping = {}
col1, col2 = st.columns(2)
for i, (grade, gpa_val) in enumerate(default_grades_mapping.items()):
    if i % 2 == 0:
        with col1:
            edited_grades_mapping[grade] = st.number_input(f"{grade} å°æ‡‰ GPA:", value=gpa_val, key=f"gpa_input_{grade}")
    else:
        with col2:
            edited_grades_mapping[grade] = st.number_input(f"{grade} å°æ‡‰ GPA:", value=gpa_val, key=f"gpa_input_{grade}")

uploaded_file = st.file_uploader("é¸æ“‡ä¸€å€‹ PDF æª”æ¡ˆ", type="pdf")

if uploaded_file is not None:
    st.success(f"æª”æ¡ˆ '{uploaded_file.name}' å·²æˆåŠŸä¸Šå‚³ï¼")
    
    # è®€å–æª”æ¡ˆå…§å®¹åˆ° BytesIO
    pdf_bytes = BytesIO(uploaded_file.getvalue())

    # è™•ç† PDF æª”æ¡ˆ
    with st.spinner("æ­£åœ¨è™•ç† PDFï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“..."):
        df_grades, total_credits, average_gpa = process_pdf_file(pdf_bytes, edited_grades_mapping)
    
    if not df_grades.empty:
        st.subheader("æå–åˆ°çš„æˆç¸¾æ•¸æ“š (éƒ¨åˆ†é è¦½)")
        st.dataframe(df_grades)

        st.subheader("è¨ˆç®—çµæœ")
        st.metric("ç¸½å­¸åˆ†æ•¸", f"{total_credits:.2f}")
        st.metric("å¹³å‡ GPA", f"{average_gpa:.2f}")
    else:
        st.error("æœªèƒ½å¾ä¸Šå‚³çš„ PDF æª”æ¡ˆä¸­æå–åˆ°ä»»ä½•æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æˆ–å˜—è©¦å…¶ä»–æª”æ¡ˆã€‚")
        st.info("æç¤ºï¼šç¢ºä¿æ‚¨çš„ PDF æˆç¸¾å–®æ˜¯æ–‡å­—å¯é¸å–çš„ï¼Œè€Œä¸æ˜¯åœ–ç‰‡æƒæä»¶ã€‚")

st.markdown("---")
st.write("å¦‚æœæ‚¨é‡åˆ°ä»»ä½•å•é¡Œï¼Œè«‹æª¢æŸ¥åŸå§‹ç¨‹å¼ç¢¼æˆ–æä¾›æ›´å¤šè©³ç´°è³‡è¨Šã€‚")
