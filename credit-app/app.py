import streamlit as st
import pandas as pd
import pdfplumber
import collections
import re 

# --- è¼”åŠ©å‡½æ•¸ ---
def normalize_text(cell_content):
    """
    æ¨™æº–åŒ–å¾ pdfplumber æå–çš„å–®å…ƒæ ¼å…§å®¹ã€‚
    è™•ç† None å€¼ã€pdfplumber çš„ Text ç‰©ä»¶å’Œæ™®é€šå­—ä¸²ã€‚
    å°‡å¤šå€‹ç©ºç™½å­—å…ƒï¼ˆåŒ…æ‹¬æ›è¡Œï¼‰æ›¿æ›ç‚ºå–®å€‹ç©ºæ ¼ï¼Œä¸¦å»é™¤å…©ç«¯ç©ºç™½ã€‚
    """
    if cell_content is None:
        return ""

    text = ""
    # æª¢æŸ¥æ˜¯å¦æ˜¯ pdfplumber çš„ Text ç‰©ä»¶ (å®ƒæœƒæœ‰ .text å±¬æ€§)
    if hasattr(cell_content, 'text'):
        text = str(cell_content.text)
    # å¦‚æœä¸æ˜¯ Text ç‰©ä»¶ï¼Œä½†æœ¬èº«æ˜¯å­—ä¸²
    elif isinstance(cell_content, str):
        text = cell_content
    # å…¶ä»–æƒ…æ³ï¼Œå˜—è©¦è½‰æ›ç‚ºå­—ä¸²
    else:
        text = str(cell_content)
    
    return re.sub(r'\s+', ' ', text).strip()

def make_unique_columns(columns_list):
    """
    å°‡åˆ—è¡¨ä¸­çš„æ¬„ä½åç¨±è½‰æ›ç‚ºå”¯ä¸€çš„åç¨±ï¼Œè™•ç†é‡è¤‡å’Œç©ºå­—ä¸²ã€‚
    å¦‚æœé‡åˆ°é‡è¤‡æˆ–ç©ºå­—ä¸²ï¼Œæœƒæ·»åŠ å¾Œç¶´ (ä¾‹å¦‚ 'Column_1', 'æ¬„ä½_2')ã€‚
    """
    seen = collections.defaultdict(int)
    unique_columns = []
    for col in columns_list:
        original_col_cleaned = normalize_text(col)
        
        # å°æ–¼ç©ºå­—ä¸²æˆ–éçŸ­çš„å­—ä¸²ï¼Œä½¿ç”¨ 'Column_X' æ ¼å¼
        if not original_col_cleaned or len(original_col_cleaned) < 2: 
            name_base = "Column"
            # ç¢ºä¿ç”Ÿæˆçš„ Column_X æ˜¯åœ¨ unique_columns ä¸­å”¯ä¸€çš„
            current_idx = 1
            while f"{name_base}_{current_idx}" in unique_columns:
                current_idx += 1
            name = f"{name_base}_{current_idx}"
        else:
            name = original_col_cleaned
        
        # è™•ç†åç¨±æœ¬èº«çš„é‡è¤‡
        final_name = name
        counter = seen[name]
        # å¦‚æœç•¶å‰ç”Ÿæˆçš„åç¨±å·²ç¶“å­˜åœ¨æ–¼ unique_columns ä¸­ï¼Œå‰‡æ·»åŠ å¾Œç¶´
        while final_name in unique_columns:
            counter += 1
            final_name = f"{name}_{counter}" 
        
        unique_columns.append(final_name)
        seen[name] = counter # æ›´æ–°è©²åŸºç¤åç¨±çš„æœ€å¤§è¨ˆæ•¸

    return unique_columns

def parse_credit_and_gpa(text):
    """
    å¾å–®å…ƒæ ¼æ–‡æœ¬ä¸­è§£æå­¸åˆ†å’Œ GPAã€‚
    è€ƒæ…® "A 2" (GPAåœ¨å·¦ï¼Œå­¸åˆ†åœ¨å³) å’Œ "2 A" (å­¸åˆ†åœ¨å·¦ï¼ŒGPAåœ¨å³) çš„æƒ…æ³ã€‚
    è¿”å› (å­¸åˆ†, GPA)ã€‚å¦‚æœè§£æå¤±æ•—ï¼Œè¿”å› (0.0, "")ã€‚
    """
    text_clean = normalize_text(text)
    
    # é¦–å…ˆæª¢æŸ¥æ˜¯å¦æ˜¯ã€Œé€šéã€æˆ–ã€ŒæŠµå…ã€ç­‰é—œéµè©
    if text_clean.lower() in ["é€šé", "æŠµå…", "pass", "exempt"]:
        # å¦‚æœæ˜¯é€™äº›é—œéµè©ï¼Œå­¸åˆ†é€šå¸¸ä¸æœƒç›´æ¥åœ¨å­—ä¸²ä¸­ï¼Œä½†å¯èƒ½åœ¨å…¶ä»–æ¬„ä½
        # åœ¨æ­¤å‡½æ•¸ä¸­ï¼Œæˆ‘å€‘åªè§£æç•¶å‰å–®å…ƒæ ¼çš„å…§å®¹ã€‚å¦‚æœå–®å…ƒæ ¼åªæœ‰é€™äº›è©ï¼Œå‰‡å­¸åˆ†ç‚º0
        # å¯¦éš›å­¸åˆ†æœƒåœ¨ calculate_total_credits ä¸­å¾å­¸åˆ†æ¬„ä½ç²å–
        return 0.0, text_clean # è¿”å›è§£æåˆ°çš„ã€Œé€šéã€ç­‰å­—ä¸²ä½œç‚º GPA

    # å˜—è©¦åŒ¹é… "GPA å­¸åˆ†" æ¨¡å¼ (ä¾‹å¦‚ "A 2", "C- 3")
    match_gpa_credit = re.match(r'([A-Fa-f][+\-]?)\s*(\d+(\.\d+)?)', text_clean)
    if match_gpa_credit:
        gpa = match_gpa_credit.group(1).upper()
        try:
            credit = float(match_gpa_credit.group(2))
            return credit, gpa
        except ValueError:
            pass # ç¹¼çºŒå˜—è©¦å…¶ä»–æ¨¡å¼

    # å˜—è©¦åŒ¹é… "å­¸åˆ† GPA" æ¨¡å¼ (ä¾‹å¦‚ "2 A", "3 B-")
    match_credit_gpa = re.match(r'(\d+(\.\d+)?)\s*([A-Fa-f][+\-]?)', text_clean)
    if match_credit_gpa:
        try:
            credit = float(match_credit_gpa.group(1))
            gpa = match_credit_gpa.group(3).upper()
            return credit, gpa
        except ValueError:
            pass # ç¹¼çºŒå˜—è©¦å…¶ä»–æ¨¡å¼
            
    # å˜—è©¦åªåŒ¹é…å­¸åˆ† (ç´”æ•¸å­—)
    credit_only_match = re.search(r'(\d+(\.\d+)?)', text_clean)
    if credit_only_match:
        try:
            credit = float(credit_only_match.group(1))
            # å¦‚æœåªæœ‰å­¸åˆ†ï¼ŒGPA è¨­ç‚ºç©º
            return credit, "" 
        except ValueError:
            pass

    # å˜—è©¦åªåŒ¹é… GPA (ç´”å­—æ¯)
    gpa_only_match = re.search(r'([A-Fa-f][+\-]?)', text_clean)
    if gpa_only_match:
        # å¦‚æœåªæœ‰ GPAï¼Œå­¸åˆ†è¨­ç‚º 0
        return 0.0, gpa_only_match.group(1).upper()

    return 0.0, ""

def is_grades_table(df):
    """
    åˆ¤æ–·ä¸€å€‹ DataFrame æ˜¯å¦ç‚ºæœ‰æ•ˆçš„æˆç¸¾å–®è¡¨æ ¼ã€‚
    é€éæª¢æŸ¥æ˜¯å¦å­˜åœ¨é æœŸçš„æ¬„ä½é—œéµå­—ä¾†åˆ¤æ–·ã€‚
    """
    # å°‡æ¬„ä½åç¨±è½‰æ›ç‚ºå°å¯«ä¸¦å»é™¤ç©ºç™½ï¼Œä»¥ä¾¿é€²è¡Œä¸å€åˆ†å¤§å°å¯«çš„åŒ¹é…
    normalized_columns = [re.sub(r'\s+', '', col).lower() for col in df.columns.tolist()]
    
    # å®šç¾©åˆ¤æ–·æˆç¸¾è¡¨æ ¼çš„æ ¸å¿ƒé—œéµå­—
    # é€™è£¡çš„é—œéµå­—æ‡‰è©²æ˜¯æˆç¸¾å–®è¡¨æ ¼ç‰¹æœ‰çš„ï¼Œè€Œä¸æ˜¯å…¶ä»–ä¿¡æ¯è¡¨æ ¼ä¹Ÿå¯èƒ½æœ‰çš„
    # ä¾‹å¦‚ï¼šç§‘ç›®åç¨±ã€å­¸åˆ†ã€GPAã€å­¸æœŸã€å­¸å¹´
    credit_keywords = ["å­¸åˆ†", "credits", "credit", "å­¸åˆ†æ•¸"]
    gpa_keywords = ["gpa", "æˆç¸¾", "grade"]
    subject_keywords = ["ç§‘ç›®åç¨±", "èª²ç¨‹åç¨±", "coursename", "subjectname", "ç§‘ç›®", "èª²ç¨‹"]
    year_sem_keywords = ["å­¸å¹´", "å­¸æœŸ", "year", "semester"]

    # æª¢æŸ¥æ˜¯å¦å­˜åœ¨è‡³å°‘ä¸€å€‹å­¸åˆ†æˆ–GPAé—œéµå­—
    has_credit_or_gpa_col = any(any(k in col for k in credit_keywords) for col in normalized_columns) or \
                            any(any(k in col for k in gpa_keywords) for col in normalized_columns)

    # æª¢æŸ¥æ˜¯å¦å­˜åœ¨è‡³å°‘ä¸€å€‹ç§‘ç›®åç¨±é—œéµå­—
    has_subject_col = any(any(k in col for k in subject_keywords) for col in normalized_columns)

    # æª¢æŸ¥æ˜¯å¦å­˜åœ¨å­¸å¹´æˆ–å­¸æœŸé—œéµå­—
    has_year_sem_col = any(any(k in col for k in year_sem_keywords) for col in normalized_columns)

    # å¦‚æœåŒæ™‚æœ‰ç§‘ç›®ã€å­¸åˆ†/GPAã€å­¸å¹´/å­¸æœŸï¼Œå‰‡å¾ˆå¯èƒ½æ˜¯æˆç¸¾è¡¨æ ¼
    if has_subject_col and has_credit_or_gpa_col and has_year_sem_col:
        return True
    
    # æ›´éˆæ´»çš„åˆ¤æ–·ï¼šå¦‚æœè¡¨æ ¼æœ‰è¶³å¤ å¤šçš„è¡Œï¼Œä¸¦ä¸”å…¶ä¸­çš„ä¸€äº›å–®å…ƒæ ¼å…§å®¹çœ‹èµ·ä¾†åƒèª²ç¨‹åã€å­¸åˆ†æˆ–GPA
    if len(df) > 5: # è‡³å°‘æœ‰5è¡Œæ•¸æ“šæ‰é€²è¡Œæ›´æ·±å±¤çš„åˆ¤æ–·
        # æª¢æŸ¥æ˜¯å¦å­˜åœ¨ä¸€åˆ—ï¼Œå…¶å¤§éƒ¨åˆ†å…§å®¹çœ‹èµ·ä¾†åƒç§‘ç›®åç¨±
        potential_subject_col_data_count = 0
        for col_name in df.columns:
            sample_data = df[col_name].head(len(df)).apply(normalize_text).tolist() # æª¢æŸ¥æ‰€æœ‰è¡Œ
            
            # è¨ˆæ•¸çœ‹èµ·ä¾†åƒç§‘ç›®åç¨±çš„å–®å…ƒæ ¼ (åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œé•·åº¦>4ï¼Œä¸æ˜¯ç´”æ•¸å­—æˆ–å–®å€‹å­—æ¯æˆç¸¾)
            subject_like_cells = sum(1 for item_str in sample_data 
                                     if re.search(r'[\u4e00-\u9fa5]', item_str) and len(item_str) > 4 
                                     and not item_str.isdigit() and not re.match(r'^[A-Fa-f][+\-]?$', item_str)
                                     and not item_str.lower() in ["é€šé", "æŠµå…", "pass", "exempt"])
            
            if subject_like_cells / len(sample_data) >= 0.5: # å¦‚æœè¶…éä¸€åŠçš„å–®å…ƒæ ¼åƒç§‘ç›®åç¨±
                potential_subject_col_data_count += 1
        
        # å¦‚æœè‡³å°‘æœ‰ä¸€åˆ—çœ‹èµ·ä¾†åƒç§‘ç›®åç¨±åˆ—ï¼Œä¸”ä¹‹å‰æ²’æœ‰æ˜ç¢ºçš„æ¬„ä½åŒ¹é…
        if potential_subject_col_data_count > 0:
            return True


    return False


def calculate_total_credits(df_list):
    """
    å¾æå–çš„ DataFrames åˆ—è¡¨ä¸­è¨ˆç®—ç¸½å­¸åˆ†ã€‚
    å°‹æ‰¾åŒ…å« 'å­¸åˆ†' æˆ– 'å­¸åˆ†(GPA)' é¡ä¼¼å­—æ¨£çš„æ¬„ä½é€²è¡ŒåŠ ç¸½ã€‚
    è¿”å›ç¸½å­¸åˆ†å’Œè¨ˆç®—å­¸åˆ†çš„ç§‘ç›®åˆ—è¡¨ï¼Œä»¥åŠä¸åŠæ ¼ç§‘ç›®åˆ—è¡¨ã€‚
    """
    total_credits = 0.0
    calculated_courses = [] 
    failed_courses = [] 

    credit_column_keywords = ["å­¸åˆ†", "å­¸åˆ†æ•¸", "å­¸åˆ†(GPA)", "å­¸ åˆ†", "Credits", "Credit"] 
    subject_column_keywords = ["ç§‘ç›®åç¨±", "èª²ç¨‹åç¨±", "Course Name", "Subject Name", "ç§‘ç›®", "èª²ç¨‹"] 
    gpa_column_keywords = ["GPA", "æˆç¸¾", "Grade"] 
    
    # æ›´æ–°ä¸åŠæ ¼åˆ¤æ–·ï¼Œä¸å†åŒ…å«ã€Œé€šéã€æˆ–ã€ŒæŠµå…ã€
    failing_grades = ["D", "D-", "E", "F", "X", "ä¸é€šé", "æœªé€šé", "ä¸åŠæ ¼"] 

    for df_idx, df in enumerate(df_list):
        found_credit_column = None
        found_subject_column = None 
        found_gpa_column = None 
        
        # æ­¥é©Ÿ 1: å„ªå…ˆåŒ¹é…æ˜ç¢ºçš„å­¸åˆ†ã€ç§‘ç›®å’Œ GPA é—œéµå­—
        for col_name_orig in df.columns:
            cleaned_col_for_match = "".join(char for char in normalize_text(col_name_orig) if '\u4e00' <= char <= '\u9fa5' or 'a' <= char <= 'z' or 'A' <= char <= 'Z' or '0' <= char <= '9').strip()
            
            if any(keyword in cleaned_col_for_match for keyword in credit_column_keywords):
                found_credit_column = col_name_orig 
            if any(keyword in cleaned_col_for_match for keyword in subject_column_keywords):
                found_subject_column = col_name_orig
            if any(keyword in cleaned_col_for_match for keyword in gpa_column_keywords):
                found_gpa_column = col_name_orig
            
            if found_credit_column and found_subject_column and found_gpa_column:
                break 
        
        # æ­¥é©Ÿ 2: å¦‚æœæ²’æœ‰æ˜ç¢ºåŒ¹é…ï¼Œå˜—è©¦å¾é€šç”¨åç¨± (Column_X) ä¸­çŒœæ¸¬æ¬„ä½
        potential_credit_columns = []
        potential_subject_columns = []
        potential_gpa_columns = []

        for col_name in df.columns: 
            sample_data = df[col_name].head(10).apply(normalize_text).tolist()
            total_sample_count = len(sample_data)

            # åˆ¤æ–·æ½›åœ¨å­¸åˆ†æ¬„ä½
            numeric_like_count = 0
            for item_str in sample_data:
                credit_val, _ = parse_credit_and_gpa(item_str)
                if 0.0 < credit_val <= 10.0: # å­¸åˆ†å¤§æ–¼0ä¸”åœ¨åˆç†ç¯„åœå…§
                    numeric_like_count += 1
            if total_sample_count > 0 and numeric_like_count / total_sample_count >= 0.6: 
                potential_credit_columns.append(col_name)

            # åˆ¤æ–·æ½›åœ¨ç§‘ç›®åç¨±æ¬„ä½ (æ›´æ™ºèƒ½çš„åˆ¤æ–·)
            subject_like_count = 0
            for item_str in sample_data:
                if re.search(r'[\u4e00-\u9fa5]', item_str) and len(item_str) > 4 and not item_str.isdigit() and not re.match(r'^[A-Fa-f][+\-]?$', item_str) and not item_str.lower() in ["é€šé", "æŠµå…", "pass", "exempt"]: 
                    subject_like_count += 1
            if total_sample_count > 0 and subject_like_count / total_sample_count >= 0.7: 
                potential_subject_columns.append(col_name)

            # åˆ¤æ–·æ½›åœ¨ GPA æ¬„ä½
            gpa_like_count = 0
            for item_str in sample_data:
                if re.match(r'^[A-Fa-f][+\-]?' , item_str) or (item_str.isdigit() and len(item_str) <=3) or item_str.lower() in ["é€šé", "æŠµå…", "pass", "exempt"]: 
                    gpa_like_count += 1
            if total_sample_count > 0 and gpa_like_count / total_sample_count >= 0.6: 
                potential_gpa_columns.append(col_name)

        # æ­¥é©Ÿ 3: æ ¹æ“šæ¨æ–·çµæœç¢ºå®šå­¸åˆ†ã€ç§‘ç›®å’Œ GPA æ¬„ä½
        # ç¢ºä¿å„ªå…ˆç´šï¼šç§‘ç›®åç¨±é€šå¸¸åœ¨æœ€å·¦ï¼Œå­¸åˆ†æ¬¡ä¹‹ï¼ŒGPA æœ€å³
        
        # å…ˆç¢ºå®šç§‘ç›®åç¨±
        if not found_subject_column and potential_subject_columns:
            # é¸æ“‡æœ€å·¦é‚Šçš„æ½›åœ¨ç§‘ç›®æ¬„ä½
            found_subject_column = sorted(potential_subject_columns, key=lambda x: df.columns.get_loc(x))[0]
        
        # å†ç¢ºå®šå­¸åˆ†æ¬„ä½ï¼Œå„ªå…ˆé è¿‘ç§‘ç›®åç¨±
        if not found_credit_column and potential_credit_columns:
            if found_subject_column:
                subject_col_idx = df.columns.get_loc(found_subject_column)
                # å°‹æ‰¾åœ¨ç§‘ç›®æ¬„ä½å³å´çš„å­¸åˆ†æ¬„ä½
                right_side_candidates = [col for col in potential_credit_columns if df.columns.get_loc(col) > subject_col_idx]
                if right_side_candidates:
                    found_credit_column = sorted(right_side_candidates, key=lambda x: df.columns.get_loc(x))[0]
                elif potential_credit_columns: 
                     found_credit_column = potential_credit_columns[0]
            else: 
                found_credit_column = potential_credit_columns[0]

        # æœ€å¾Œç¢ºå®š GPA æ¬„ä½ï¼Œå„ªå…ˆé è¿‘å­¸åˆ†æ¬„ä½
        if not found_gpa_column and potential_gpa_columns:
            if found_credit_column:
                credit_col_idx = df.columns.get_loc(found_credit_column)
                # å°‹æ‰¾åœ¨å­¸åˆ†æ¬„ä½å³å´çš„ GPA æ¬„ä½
                right_side_candidates = [col for col in potential_gpa_columns if df.columns.get_loc(col) > credit_col_idx]
                if right_side_candidates:
                    found_gpa_column = sorted(right_side_candidates, key=lambda x: df.columns.get_loc(x))[0]
                elif potential_gpa_columns: 
                    found_gpa_column = potential_gpa_columns[0]
            else: 
                found_gpa_column = potential_gpa_columns[0]


        if found_credit_column: # åªæœ‰æ‰¾åˆ°å­¸åˆ†æ¬„ä½æ‰é€²è¡Œè™•ç†
            try:
                for row_idx, row in df.iterrows():
                    # å˜—è©¦å¾å­¸åˆ†æˆ– GPA æ¬„ä½ç²å–å­¸åˆ†å’Œ GPA
                    extracted_credit = 0.0
                    extracted_gpa = ""

                    # å¾å­¸åˆ†æ¬„ä½æå–å­¸åˆ†å’Œæ½›åœ¨çš„GPA
                    if found_credit_column in row: # ç¢ºä¿æ¬„ä½å­˜åœ¨æ–¼ç•¶å‰è¡Œ
                        extracted_credit, extracted_gpa_from_credit_col = parse_credit_and_gpa(row[found_credit_column])
                        if extracted_gpa_from_credit_col: 
                            extracted_gpa = extracted_gpa_from_credit_col
                    
                    # å¦‚æœGPAæ¬„ä½å­˜åœ¨ä¸”ç›®å‰æ²’æœ‰ç²å–åˆ°GPAï¼Œå‰‡å¾GPAæ¬„ä½ç²å–
                    if found_gpa_column in row and not extracted_gpa: # ç¢ºä¿æ¬„ä½å­˜åœ¨æ–¼ç•¶å‰è¡Œ
                        gpa_from_gpa_col = normalize_text(row[found_gpa_column])
                        if gpa_from_gpa_col:
                            extracted_gpa = gpa_from_gpa_col.upper()
                    
                    # ç¢ºä¿å­¸åˆ†å€¼ä¸ç‚º None
                    if extracted_credit is None:
                        extracted_credit = 0.0

                    is_failing_grade = False
                    # æª¢æŸ¥æ˜¯å¦ç‚ºä¸åŠæ ¼æˆç¸¾ï¼Œä¸åŒ…å«ã€Œé€šéã€æˆ–ã€ŒæŠµå…ã€
                    if extracted_gpa:
                        gpa_clean = re.sub(r'[+\-]', '', extracted_gpa).upper() 
                        if gpa_clean in failing_grades:
                            is_failing_grade = True
                        elif gpa_clean.isdigit(): # å¦‚æœ GPA æ˜¯æ•¸å­—ï¼Œä¾‹å¦‚åˆ†æ•¸ï¼Œå‡è¨­60åˆ†ä»¥ä¸‹ä¸åŠæ ¼ (å¯æ ¹æ“šå­¸æ ¡æ¨™æº–èª¿æ•´)
                            try:
                                numeric_gpa = float(gpa_clean)
                                if numeric_gpa < 60: # å‡è¨­ 60 åˆ†ä»¥ä¸‹ç‚ºä¸åŠæ ¼
                                    is_failing_grade = True
                            except ValueError:
                                pass
                    
                    # è™•ç†ã€Œé€šéã€å’Œã€ŒæŠµå…ã€æƒ…æ³ï¼šç¾åœ¨å®ƒå€‘æœƒè¢«è¨ˆå…¥å­¸åˆ†ï¼Œé™¤éå­¸åˆ†ç‚º0
                    is_passed_or_exempt_grade = False
                    if (found_gpa_column in row and normalize_text(row[found_gpa_column]).lower() in ["é€šé", "æŠµå…", "pass", "exempt"]) or \
                       (found_credit_column in row and normalize_text(row[found_credit_column]).lower() in ["é€šé", "æŠµå…", "pass", "exempt"]):
                        is_passed_or_exempt_grade = True
                        
                    course_name = "æœªçŸ¥ç§‘ç›®" 
                    if found_subject_column in row: # ç¢ºä¿æ¬„ä½å­˜åœ¨æ–¼ç•¶å‰è¡Œ
                        temp_name = normalize_text(row[found_subject_column])
                        if len(temp_name) > 2 and re.search(r'[\u4e00-\u9fa5]', temp_name): # ç¢ºä¿æ˜¯æœ‰æ•ˆçš„ä¸­æ–‡ç§‘ç›®å
                            course_name = temp_name
                        elif not temp_name: # å¦‚æœç§‘ç›®åç¨±æ¬„ä½æ˜¯ç©ºçš„ï¼Œå˜—è©¦å¾å‰ä¸€åˆ—ç²å–ï¼ˆå¸¸è¦‹æ–¼åˆä½µå–®å…ƒæ ¼ï¼‰
                            try:
                                current_col_idx = df.columns.get_loc(found_subject_column)
                                if current_col_idx > 0: 
                                    prev_col_name = df.columns[current_col_idx - 1]
                                    if prev_col_name in row: # ç¢ºä¿å‰ä¸€åˆ—å­˜åœ¨æ–¼ç•¶å‰è¡Œ
                                        temp_name_prev_col = normalize_text(row[prev_col_name])
                                        if len(temp_name_prev_col) > 2 and re.search(r'[\u4e00-\u9fa5]', temp_name_prev_col):
                                            course_name = temp_name_prev_col
                            except Exception:
                                pass

                    # å˜—è©¦ç²å–å­¸å¹´åº¦å’Œå­¸æœŸ
                    acad_year = ""
                    semester = ""
                    # é€™äº›é€šå¸¸åœ¨è¡¨æ ¼çš„å‰å…©åˆ—
                    if len(df.columns) > 0 and df.columns[0] in row:
                        acad_year = normalize_text(row[df.columns[0]])
                    if len(df.columns) > 1 and df.columns[1] in row:
                        semester = normalize_text(row[df.columns[1]])


                    # åˆ¤æ–·æ˜¯å¦è¨ˆå…¥ç¸½å­¸åˆ†æˆ–ä¸åŠæ ¼å­¸åˆ†
                    # åªæœ‰åœ¨ extracted_credit > 0 æˆ–è€…æ˜ç¢ºæœ‰ã€Œé€šé/æŠµå…ã€æ¨™è¨˜çš„æƒ…æ³ä¸‹ï¼Œæ‰è¢«è¦–ç‚ºæœ‰æ•ˆèª²ç¨‹ã€‚
                    # åŒæ™‚ï¼Œè‹¥è¢«åˆ¤æ–·ç‚ºä¸åŠæ ¼ï¼Œå‰‡æ­¸é¡åˆ°ä¸åŠæ ¼åˆ—è¡¨ã€‚
                    if is_failing_grade:
                        failed_courses.append({
                            "å­¸å¹´åº¦": acad_year,
                            "å­¸æœŸ": semester,
                            "ç§‘ç›®åç¨±": course_name, 
                            "å­¸åˆ†": extracted_credit, 
                            "GPA": extracted_gpa, 
                            "ä¾†æºè¡¨æ ¼": df_idx + 1
                        })
                    elif extracted_credit > 0 or is_passed_or_exempt_grade: # å¦‚æœå­¸åˆ†å¤§æ–¼0ï¼Œæˆ–æˆç¸¾æ˜¯é€šé/æŠµå…ï¼Œå°±è¦–ç‚ºé€šéèª²ç¨‹
                        # åªæœ‰å­¸åˆ†å¤§æ–¼0æ‰åŠ ç¸½ï¼Œå³ä½¿æ˜¯ã€Œé€šé/æŠµå…ã€ä½†å­¸åˆ†æ˜¯0ï¼Œä¹Ÿä¸è¨ˆå…¥ç¸½å­¸åˆ†ï¼Œåªåˆ—å‡º
                        if extracted_credit > 0: 
                            total_credits += extracted_credit
                        calculated_courses.append({
                            "å­¸å¹´åº¦": acad_year,
                            "å­¸æœŸ": semester,
                            "ç§‘ç›®åç¨±": course_name, 
                            "å­¸åˆ†": extracted_credit, 
                            "GPA": extracted_gpa, 
                            "ä¾†æºè¡¨æ ¼": df_idx + 1
                        })
                
            except Exception as e:
                st.warning(f"è¡¨æ ¼ {df_idx + 1} çš„å­¸åˆ†è¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: `{e}`ã€‚è©²è¡¨æ ¼çš„å­¸åˆ†å¯èƒ½ç„¡æ³•è¨ˆå…¥ç¸½æ•¸ã€‚è«‹æª¢æŸ¥å­¸åˆ†å’ŒGPAæ¬„ä½æ•¸æ“šæ˜¯å¦æ­£ç¢ºã€‚")
        else:
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å­¸åˆ†æ¬„ä½ï¼Œå‰‡è©²è¡¨æ ¼ä¸æ‡‰è¢«è¦–ç‚ºæˆç¸¾å–®ï¼Œæ­¤è™•ä¸å†é¡¯ç¤ºé¡å¤–è­¦å‘Šï¼Œå› ç‚ºis_grades_tableå·²è™•ç†
            pass 
            
    return total_credits, calculated_courses, failed_courses

def process_pdf_file(uploaded_file):
    """
    ä½¿ç”¨ pdfplumber è™•ç†ä¸Šå‚³çš„ PDF æª”æ¡ˆï¼Œæå–è¡¨æ ¼ã€‚
    æ­¤å‡½æ•¸å…§éƒ¨å°‡æ¸›å°‘ Streamlit çš„ç›´æ¥è¼¸å‡ºï¼Œåªè¿”å›æå–çš„æ•¸æ“šã€‚
    """
    all_grades_data = []

    try:
        with pdfplumber.open(uploaded_file) as pdf:
            for page_num, page in enumerate(pdf.pages):
                current_page = page 

                table_settings = {
                    "vertical_strategy": "lines", 
                    "horizontal_strategy": "lines", 
                    "snap_tolerance": 3,  
                    "join_tolerance": 5,  
                    "edge_min_length": 3, 
                    "text_tolerance": 2,  
                    "min_words_vertical": 1, 
                    "min_words_horizontal": 1, 
                }
                
                try:
                    tables = current_page.extract_tables(table_settings)

                    if not tables:
                        st.info(f"é é¢ **{page_num + 1}** æœªåµæ¸¬åˆ°è¡¨æ ¼ã€‚é€™å¯èƒ½æ˜¯ç”±æ–¼ PDF æ ¼å¼è¤‡é›œæˆ–è¡¨æ ¼æå–è¨­å®šä¸é©ç”¨ã€‚")
                        continue

                    for table_idx, table in enumerate(tables):
                        processed_table = []
                        for row in table:
                            normalized_row = [normalize_text(cell) for cell in row]
                            processed_table.append(normalized_row)
                        
                        if not processed_table:
                            st.info(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ **{table_idx + 1}** æå–å¾Œç‚ºç©ºã€‚")
                            continue

                        if len(processed_table) > 0:
                            header_row = processed_table[0]
                            data_rows = processed_table[1:]
                        else:
                            header_row = []
                            data_rows = []

                        unique_columns = make_unique_columns(header_row)

                        if data_rows:
                            num_columns_header = len(unique_columns)
                            cleaned_data_rows = []
                            for row in data_rows:
                                if len(row) > num_columns_header:
                                    cleaned_data_rows.append(row[:num_columns_header])
                                elif len(row) < num_columns_header: 
                                    cleaned_data_rows.append(row + [''] * (num_columns_header - len(row)))
                                else:
                                    cleaned_data_rows.append(row)

                            try:
                                df_table = pd.DataFrame(cleaned_data_rows, columns=unique_columns)
                                # ä½¿ç”¨ is_grades_table å‡½æ•¸ä¾†éæ¿¾éæˆç¸¾å–®è¡¨æ ¼
                                if is_grades_table(df_table):
                                    all_grades_data.append(df_table)
                                    st.success(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} å·²è­˜åˆ¥ç‚ºæˆç¸¾å–®è¡¨æ ¼ä¸¦å·²è™•ç†ã€‚")
                                else:
                                    # é¡¯ç¤ºæ›´è©³ç´°çš„è·³éåŸå› ï¼Œå¯ä»¥å¹«åŠ©ç”¨æˆ¶ç†è§£
                                    st.info(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} (æ¨™é¡Œç¯„ä¾‹: {header_row}) æœªè­˜åˆ¥ç‚ºæˆç¸¾å–®è¡¨æ ¼ï¼Œå·²è·³éã€‚")
                            except Exception as e_df:
                                st.error(f"é é¢ {page_num + 1} è¡¨æ ¼ {table_idx + 1} è½‰æ›ç‚º DataFrame æ™‚ç™¼ç”ŸéŒ¯èª¤: `{e_df}`")
                                st.error(f"åŸå§‹è™•ç†å¾Œæ•¸æ“šç¯„ä¾‹: {processed_table[:2]} (å‰å…©è¡Œ)")
                                st.error(f"ç”Ÿæˆçš„å”¯ä¸€æ¬„ä½åç¨±: {unique_columns}")
                        else:
                            st.info(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ **{table_idx + 1}** æ²’æœ‰æ•¸æ“šè¡Œã€‚")

                except Exception as e_table:
                    st.error(f"é é¢ **{page_num + 1}** è™•ç†è¡¨æ ¼æ™‚ç™¼ç”ŸéŒ¯èª¤: `{e_table}`")
                    st.warning("é€™å¯èƒ½æ˜¯ç”±æ–¼ PDF æ ¼å¼è¤‡é›œæˆ–è¡¨æ ¼æå–è¨­å®šä¸é©ç”¨ã€‚è«‹æª¢æŸ¥ PDF çµæ§‹ã€‚")

    except pdfplumber.PDFSyntaxError as e_pdf_syntax:
        st.error(f"è™•ç† PDF èªæ³•æ™‚ç™¼ç”ŸéŒ¯èª¤: `{e_pdf_syntax}`ã€‚æª”æ¡ˆå¯èƒ½å·²æå£æˆ–æ ¼å¼ä¸æ­£ç¢ºã€‚")
    except Exception as e:
        st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”Ÿä¸€èˆ¬éŒ¯èª¤: `{e}`")
        st.error("è«‹ç¢ºèªæ‚¨çš„ PDF æ ¼å¼æ˜¯å¦ç‚ºæ¸…æ™°çš„è¡¨æ ¼ã€‚è‹¥å•é¡ŒæŒçºŒï¼Œå¯èƒ½æ˜¯ PDF çµæ§‹è¼ƒç‚ºè¤‡é›œï¼Œéœ€è¦èª¿æ•´ `pdfplumber` çš„è¡¨æ ¼æå–è¨­å®šã€‚")

    return all_grades_data

# --- Streamlit æ‡‰ç”¨ä¸»é«” ---
def main():
    st.set_page_config(page_title="PDF æˆç¸¾å–®å­¸åˆ†è¨ˆç®—å·¥å…·", layout="wide")
    st.title("ğŸ“„ PDF æˆç¸¾å–®å­¸åˆ†è¨ˆç®—å·¥å…·")

    st.write("è«‹ä¸Šå‚³æ‚¨çš„ PDF æˆç¸¾å–®æª”æ¡ˆï¼Œå·¥å…·å°‡å˜—è©¦æå–å…¶ä¸­çš„è¡¨æ ¼æ•¸æ“šä¸¦è¨ˆç®—ç¸½å­¸åˆ†ã€‚")
    st.write("æ‚¨ä¹Ÿå¯ä»¥è¼¸å…¥ç›®æ¨™å­¸åˆ†ï¼ŒæŸ¥çœ‹é‚„å·®å¤šå°‘å­¸åˆ†ã€‚")

    uploaded_file = st.file_uploader("é¸æ“‡ä¸€å€‹ PDF æª”æ¡ˆ", type="pdf")

    if uploaded_file is not None:
        st.success(f"å·²ä¸Šå‚³æª”æ¡ˆ: **{uploaded_file.name}**")
        with st.spinner("æ­£åœ¨è™•ç† PDFï¼Œè«‹ç¨å€™..."):
            extracted_dfs = process_pdf_file(uploaded_file)

        if extracted_dfs:
            total_credits, calculated_courses, failed_courses = calculate_total_credits(extracted_dfs)

            st.markdown("---")
            st.markdown("## âœ… æŸ¥è©¢çµæœ") 
            st.markdown(f"ç›®å‰ç¸½å­¸åˆ†: <span style='color:green; font-size: 24px;'>**{total_credits:.2f}**</span>", unsafe_allow_html=True)
            
            target_credits = st.number_input("è¼¸å…¥æ‚¨çš„ç›®æ¨™å­¸åˆ† (ä¾‹å¦‚ï¼š128)", min_value=0.0, value=128.0, step=1.0, 
                                            help="æ‚¨å¯ä»¥è¨­å®šä¸€å€‹ç•¢æ¥­å­¸åˆ†ç›®æ¨™ï¼Œå·¥å…·æœƒå¹«æ‚¨è¨ˆç®—é‚„å·®å¤šå°‘å­¸åˆ†ã€‚")
            
            credit_difference = target_credits - total_credits
            if credit_difference > 0:
                st.write(f"è·é›¢ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±{target_credits:.0f}å­¸åˆ†) **{credit_difference:.2f}**")
            elif credit_difference < 0:
                st.write(f"å·²è¶…è¶Šç•¢æ¥­å­¸åˆ† (å…±{target_credits:.0f}å­¸åˆ†) **{abs(credit_difference):.2f}**")
            else:
                st.write(f"å·²é”åˆ°ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±{target_credits:.0f}å­¸åˆ†) **0.00**")


            st.markdown("---")
            st.markdown("### ğŸ“š é€šéçš„èª²ç¨‹åˆ—è¡¨") 
            if calculated_courses:
                courses_df = pd.DataFrame(calculated_courses)
                # ç¢ºä¿æ¬„ä½é †åºèˆ‡æˆªåœ–ä¸€è‡´ï¼Œä¸”åªåŒ…å« GPA å’Œå­¸åˆ†
                display_cols = ['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']
                final_display_cols = [col for col in display_cols if col in courses_df.columns]
                
                st.dataframe(courses_df[final_display_cols], height=300, use_container_width=True) 
            else:
                st.info("æ²’æœ‰æ‰¾åˆ°å¯ä»¥è¨ˆç®—å­¸åˆ†çš„ç§‘ç›®ã€‚")

            if failed_courses:
                st.markdown("---")
                st.markdown("### âš ï¸ ä¸åŠæ ¼çš„èª²ç¨‹åˆ—è¡¨")
                failed_df = pd.DataFrame(failed_courses)
                display_failed_cols = ['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA', 'ä¾†æºè¡¨æ ¼']
                final_display_failed_cols = [col for col in display_failed_cols if col in failed_df.columns]
                st.dataframe(failed_df[final_display_failed_cols], height=200, use_container_width=True)
                st.info("é€™äº›ç§‘ç›®å› æˆç¸¾ä¸åŠæ ¼ ('D', 'E', 'F' ç­‰) è€Œæœªè¨ˆå…¥ç¸½å­¸åˆ†ã€‚") # æ›´æ–°è¨Šæ¯

            # æä¾›ä¸‹è¼‰é¸é … 
            if calculated_courses or failed_courses:
                if calculated_courses:
                    csv_data_passed = pd.DataFrame(calculated_courses).to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ä¸‹è¼‰é€šéçš„ç§‘ç›®åˆ—è¡¨ç‚º CSV",
                        data=csv_data_passed,
                        file_name=f"{uploaded_file.name.replace('.pdf', '')}_calculated_courses.csv",
                        mime="text/csv",
                        key="download_passed_btn"
                    )
                if failed_courses:
                    csv_data_failed = pd.DataFrame(failed_courses).to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ä¸‹è¼‰ä¸åŠæ ¼çš„ç§‘ç›®åˆ—è¡¨ç‚º CSV",
                        data=csv_data_failed,
                        file_name=f"{uploaded_file.name.replace('.pdf', '')}_failed_courses.csv",
                        mime="text/csv",
                        key="download_failed_btn"
                    )
            
        else:
            st.warning("æœªå¾ PDF ä¸­æå–åˆ°ä»»ä½•è¡¨æ ¼æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF å…§å®¹æˆ–å˜—è©¦èª¿æ•´ `pdfplumber` çš„è¡¨æ ¼æå–è¨­å®šã€‚")
    else:
        st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹è™•ç†ã€‚")

if __name__ == "__main__":
    main()
