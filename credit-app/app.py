import streamlit as st
import pandas as pd
import pdfplumber
import re
from io import BytesIO

# --- è¼”åŠ©å‡½æ•¸ ---

def normalize_text(cell_content):
    """
    æ¨™æº–åŒ–å¾ pdfplumber æå–çš„å–®å…ƒæ ¼å…§å®¹ã€‚
    è™•ç† None å€¼ã€pdfplumber çš„ Text ç‰©ä»¶å’Œæ™®é€šå­—ä¸²ã€‚
    å°‡å¤šå€‹ç©ºç™½å­—å…ƒï¼ˆåŒ…æ‹¬æ›è¡Œï¼‰æ›¿æ›ç‚ºå–®å€‹ç©ºæ ¼ï¼Œä¸¦å»é™¤å…©ç«¯ç©ºç™½ã€‚
    æ›´ç©æ¥µåœ°ç§»é™¤éæ‰“å°å­—ç¬¦ã€‚
    """
    if cell_content is None:
        return ""

    text = ""
    if hasattr(cell_content, 'text'):
        text = str(cell_content.text)
    elif isinstance(cell_content, str):
        text = cell_content
    else:
        text = str(cell_content)
    
    # å°‡æ‰€æœ‰ç©ºç™½å­—å…ƒï¼ˆåŒ…æ‹¬æ›è¡Œã€tabã€å¤šå€‹ç©ºæ ¼ç­‰ï¼‰æ›¿æ›ç‚ºå–®å€‹ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    # ç§»é™¤æ‰€æœ‰éæ‰“å° ASCII å­—å…ƒï¼ˆä¾‹å¦‚ NULL, BEL, VT, FF ç­‰ï¼‰å’Œä¸€äº› unicode æ§åˆ¶å­—å…ƒ
    text = re.sub(r'[\x00-\x1F\x7F-\x9F]', '', text) 
    return text.strip()

def identify_gpa_and_credits(text):
    """
    è­˜åˆ¥æ–‡æœ¬ä¸­çš„å­¸åˆ†å’Œ GPAã€‚
    è¿”å› (å­¸åˆ†, GPA) çš„ tupleã€‚
    """
    credit = None
    gpa = None

    # å˜—è©¦åŒ¹é…å­¸åˆ† (ä¾‹å¦‚ 2.0, 3, 2.5)
    credit_match = re.search(r'(\d+(\.\d+)?)\s*(å­¸åˆ†|credit|é»)', text, re.IGNORECASE)
    if credit_match:
        try:
            credit = float(credit_match.group(1))
        except ValueError:
            pass # è½‰æ›å¤±æ•—å‰‡ä¿æŒ None

    # å˜—è©¦åŒ¹é… GPA (ä¾‹å¦‚ 4.0, 3.7, A+, B-)
    # GPA å¯ä»¥æ˜¯æ•¸å­—ï¼Œä¹Ÿå¯ä»¥æ˜¯å­—æ¯ç­‰ç´š
    gpa_match_numeric = re.search(r'(\d(\.\d)?|\d\.\d{2}|[ABCFXabcfx][+\-]?)', text) # åŒ¹é… 0.0-4.0 æˆ–å­—æ¯ç­‰ç´š
    if gpa_match_numeric:
        gpa_str = gpa_match_numeric.group(1).upper()
        # æ’é™¤å¯èƒ½æ˜¯å­¸åˆ†çš„æ•¸å­—ï¼Œé™¤éå®ƒæ˜é¡¯æ˜¯GPA (ä¾‹å¦‚4.0)
        if '.' in gpa_str or len(gpa_str) <= 2: # ç°¡å–®åˆ¤æ–·ï¼Œæ•¸å­—æœ‰å°æ•¸é»ï¼Œæˆ–å­—æ¯ç­‰ç´šé€šå¸¸åªæœ‰1-2å­—
             try:
                gpa = float(gpa_str)
             except ValueError:
                gpa = gpa_str # å¦‚æœæ˜¯å­—æ¯ç­‰ç´šï¼Œä¿ç•™å­—ä¸²
        elif len(gpa_str) > 2 and not '.' in gpa_str:
            pass # å¦‚æœæ˜¯é•·æ•¸å­—ä¸”æ²’æœ‰å°æ•¸é»ï¼Œå¾ˆå¯èƒ½ä¸æ˜¯GPAï¼Œè·³é

    return credit, gpa

def is_grades_table(table, min_rows=5):
    """
    åˆ¤æ–·ä¸€å€‹ pdfplumber æå–çš„è¡¨æ ¼æ˜¯å¦ç‚ºæˆç¸¾è¡¨ã€‚
    é€™é€šéæª¢æŸ¥ç‰¹å®šé¡å‹çš„æ¬„ä½ï¼ˆå­¸å¹´ã€å­¸æœŸã€ç§‘ç›®åç¨±ã€å­¸åˆ†ã€GPAï¼‰çš„å…§å®¹æ¨¡å¼ä¾†å®Œæˆã€‚
    """
    if not table or not table.get("rows"):
        return False, {}, None

    rows = table["rows"]
    if len(rows) < min_rows: # ç¢ºä¿æœ‰è¶³å¤ çš„è³‡æ–™è¡Œä¾†åˆ¤æ–·
        return False, {}, None

    # å‡è¨­æ¨™é ­è¡Œæ˜¯ç¬¬ä¸€è¡Œï¼Œå–æ¨£å‰å¹¾è¡Œï¼ˆæˆ–æ›´å¤šï¼‰ä¾†åˆ†ææ¬„ä½å…§å®¹
    sample_rows = rows[1:min(len(rows), 10)] # å¾ç¬¬ä¸€è¡Œï¼ˆå‡è¨­æ˜¯æ•¸æ“šï¼‰é–‹å§‹å–æ¨£ï¼Œæœ€å¤š10è¡Œ
    
    # ç²å–æ¨™é ­ï¼Œä¸¦æ­£è¦åŒ–ä»¥ä½œç‚ºæ½›åœ¨æ¬„ä½åç¨±
    header_row = [normalize_text(cell) for cell in rows[0]]
    # ä½¿ç”¨å”¯ä¸€çš„æ¨™é ­åç¨±ï¼Œä¾‹å¦‚ 'Column_1', 'Column_2'
    normalized_columns = {f"Column_{i+1}": col_name for i, col_name in enumerate(header_row)}

    potential_subject_cols = []
    potential_credit_gpa_cols = []
    potential_year_cols = []
    potential_semester_cols = []
    
    # å°æ¯å€‹æ¬„ä½é€²è¡Œåˆ†æ
    for col_idx, col_name in normalized_columns.items():
        # æ”¶é›†è©²æ¬„ä½çš„æ‰€æœ‰æ¨£æœ¬å…§å®¹
        col_samples = [normalize_text(row[int(col_name.split('_')[1])-1]) for row in sample_rows if len(row) > int(col_name.split('_')[1])-1]
        
        total_sample_count = len(col_samples)
        if total_sample_count == 0:
            continue

        subject_like_cells = 0
        credit_gpa_like_cells = 0
        year_like_cells = 0
        semester_like_cells = 0

        for cell_content in col_samples:
            if not cell_content:
                continue

            # ç§‘ç›®æ¬„ä½ï¼šé€šå¸¸åŒ…å«ä¸­æ–‡ä¸”éç´”æ•¸å­—
            if re.search(r'[\u4e00-\u9fff]', cell_content) and not re.fullmatch(r'\d+(\.\d+)?', cell_content):
                subject_like_cells += 1
            
            # å­¸åˆ†/GPAæ¬„ä½ï¼šåŒ…å«æ•¸å­—æˆ–é¡ä¼¼GPAçš„æ¨¡å¼ (ä¾‹å¦‚ 3.0, A+, 2)
            if re.search(r'(\d+(\.\d+)?|[ABCFXabcfx][+\-]?)', cell_content, re.IGNORECASE):
                credit_gpa_like_cells += 1

            # å­¸å¹´æ¬„ä½ï¼šä¾‹å¦‚ 111, 109, 2023 (3-4ä½æ•¸å­—)
            if re.fullmatch(r'\d{3,4}', cell_content):
                year_like_cells += 1
            
            # å­¸æœŸæ¬„ä½ï¼šåŒ…å« 'ä¸Š', 'ä¸‹', 'æš‘'
            if any(s in cell_content for s in ['ä¸Š', 'ä¸‹', 'æš‘']):
                semester_like_cells += 1
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºæ½›åœ¨çš„ç›®æ¨™æ¬„ä½ï¼Œèª¿æ•´é–¾å€¼
        if subject_like_cells / total_sample_count >= 0.3: # é™ä½é–¾å€¼
            potential_subject_cols.append(col_name)
        if credit_gpa_like_cells / total_sample_count >= 0.3: # é™ä½é–¾å€¼
            potential_credit_gpa_cols.append(col_name)
        if year_like_cells / total_sample_count >= 0.5: # é™ä½é–¾å€¼
            potential_year_cols.append(col_name)
        if semester_like_cells / total_sample_count >= 0.5: # é™ä½é–¾å€¼
            potential_semester_cols.append(col_name)

    # æª¢æŸ¥æ˜¯å¦è‡³å°‘æ‰¾åˆ°ä¸€å€‹ç§‘ç›®æ¬„ä½ï¼Œä»¥åŠä¸€å€‹å­¸åˆ†/GPAæ¬„ä½ï¼Œä¸¦è©¦åœ–æ‰¾åˆ°å­¸å¹´å’Œå­¸æœŸ
    if not potential_subject_cols:
        # print("æœªè­˜åˆ¥åˆ°ç§‘ç›®æ¬„ä½")
        return False, {}, None
    if not potential_credit_gpa_cols:
        # print("æœªè­˜åˆ¥åˆ°å­¸åˆ†/GPAæ¬„ä½")
        return False, {}, None
    
    # å„ªå…ˆé¸æ“‡çœ‹èµ·ä¾†æœ€åƒçš„æ¬„ä½ï¼ˆä¾‹å¦‚ï¼Œé€šå¸¸ç¬¬ä¸€å€‹ç¬¦åˆæ¢ä»¶çš„å°±æ˜¯ï¼‰
    found_cols = {
        'å­¸å¹´': potential_year_cols[0] if potential_year_cols else None,
        'å­¸æœŸ': potential_semester_cols[0] if potential_semester_cols else None,
        'ç§‘ç›®åç¨±': potential_subject_cols[0] if potential_subject_cols else None,
        'å­¸åˆ†': None, # GPAå’Œå­¸åˆ†å¯èƒ½åœ¨åŒä¸€å€‹æ¬„ä½ï¼Œç¨å¾Œè§£æ
        'GPA': None
    }

    # é‡å°å­¸åˆ†å’ŒGPAï¼Œå¾ potential_credit_gpa_cols ä¸­é¸ä¸€å€‹
    # æˆ‘å€‘éœ€è¦æ‰¾åˆ°ä¸€å€‹æœ€ä½³çš„å­¸åˆ†/GPAæ¬„ä½ï¼Œé€™å€‹æ¬„ä½æ‡‰è©²æ˜¯åŒ…å«æœ€å¤šå­¸åˆ†/GPAè³‡è¨Šçš„ã€‚
    # é€™è£¡å¯ä»¥ç°¡å–®é¸ç¬¬ä¸€å€‹ï¼Œæˆ–æ ¹æ“šå¾ŒçºŒå¯¦éš›è§£æåˆ¤æ–·
    if potential_credit_gpa_cols:
        found_cols['å­¸åˆ†'] = potential_credit_gpa_cols[0]
        found_cols['GPA'] = potential_credit_gpa_cols[0] # æš«æ™‚æŒ‡å‘åŒä¸€å€‹ï¼Œå¾ŒçºŒè§£æ

    # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰å¿…è¦çš„æ¬„ä½éƒ½è¢«è­˜åˆ¥
    if not all(found_cols[key] for key in ['ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']):
        # print("éƒ¨åˆ†æ ¸å¿ƒæ¬„ä½æœªè­˜åˆ¥åˆ°")
        # å³ä½¿å­¸å¹´å­¸æœŸæ²’æœ‰ï¼Œåªè¦ç§‘ç›®å­¸åˆ†GPAæœ‰ï¼Œä¹Ÿç®—
        if found_cols['ç§‘ç›®åç¨±'] and found_cols['å­¸åˆ†']: # åªè¦æœ‰ç§‘ç›®å’ŒGPA/å­¸åˆ†ç›¸é—œæ¬„ä½å°±å˜—è©¦è§£æ
             return True, found_cols, header_row # è¿”å›åŸå§‹æ¨™é ­ä»¥ä¾¿ç´¢å¼•
        return False, {}, None

    return True, found_cols, header_row # è¿”å›åŸå§‹æ¨™é ­ä»¥ä¾¿ç´¢å¼•

def calculate_total_credits(df, grades_mapping):
    """
    è¨ˆç®—ç¸½å­¸åˆ†æ•¸å’Œå¹³å‡ GPAã€‚
    """
    total_credits = 0.0
    weighted_gpa_sum = 0.0
    num_courses_for_gpa = 0

    st.write("--- è¨ˆç®—å­¸åˆ†æ•¸èˆ‡ GPA ---")

    for row_idx, row in df.iterrows():
        # æ¨™æº–åŒ–æ‰€æœ‰å–®å…ƒæ ¼å…§å®¹
        row_content = {k: normalize_text(v) for k, v in row.items()}
        
        # è·³éç©ºè¡Œã€æ¨™é ­è¡Œæˆ–è¡Œæ”¿æ€§æ–‡å­—
        # é€™è£¡æœƒæª¢æŸ¥åŸå§‹åˆ—å…§å®¹ï¼Œæ‰€ä»¥ç¢ºä¿åŸå§‹åˆ—åœ¨è™•ç†å‰æ˜¯ä¹¾æ·¨çš„
        original_row_values = list(row.values()) # ç²å–åŸå§‹ Series çš„ values
        # å¦‚æœåŸå§‹è³‡æ–™åˆ—å…§å®¹åŒ…å«å­¸å¹´åº¦ã€å­¸æœŸç­‰å­—æ¨£ï¼Œå‰‡è·³éï¼Œå› ç‚ºé€™é€šå¸¸æ˜¯æ¨™é ­è¡Œè¢«éŒ¯èª¤è­˜åˆ¥
        if any(keyword in original_row_values for keyword in ['å­¸å¹´åº¦', 'å­¸æœŸ', 'é¸èª²ä»£è™Ÿ', 'ç§‘â½¬åç¨±', 'å­¸åˆ†', 'GPA']):
            st.warning(f"è©²è¡Œè¢«åˆ¤æ–·ç‚ºç©ºè¡Œã€æ¨™é ­è¡Œæˆ–è¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚åŸå§‹è³‡æ–™åˆ—å…§å®¹: {original_row_values}")
            continue

        # æ›´å»£æ³›åœ°æª¢æŸ¥è·³éæ¢ä»¶ï¼Œä¾‹å¦‚ç©ºè¡Œã€ç´”ç²¹çš„é çœ‰é è…³ä¿¡æ¯
        if not any(cell.strip() for cell in row_content.values()): # è¡Œä¸­æ‰€æœ‰å–®å…ƒæ ¼éƒ½ç‚ºç©º
            # st.info(f"è©²è¡Œç‚ºç©ºè¡Œï¼Œå·²è·³éã€‚")
            continue
        # æª¢æŸ¥è¡Œæ”¿æ€§æ–‡å­—ï¼Œé¿å…èª¤åˆ¤æ­£è¦èª²ç¨‹ç‚ºè¡Œæ”¿æ€§æ–‡å­—
        admin_keywords = ['é«”è‚²å®¤', 'æœ¬è¡¨åƒ…ä¾›æŸ¥è©¢', 'å­¸å£«ç­', 'ç ”ç©¶æ‰€', 'æˆç¸¾è­‰æ˜', 'ç¬¬', 'é ', 'ç¸½å¹³å‡', 'å­¸æ¥­å¹³å‡']
        if any(keyword in ' '.join(row_content.values()) for keyword in admin_keywords):
            # st.info(f"è©²è¡Œè¢«åˆ¤æ–·ç‚ºè¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚")
            continue

        # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨
        if not all(k in row_content for k in ['ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']):
            # st.warning(f"è¡Œ {row_idx} ç¼ºå°‘å¿…è¦çš„æ¬„ä½ (ç§‘ç›®åç¨±, å­¸åˆ†, GPA)ï¼Œå·²è·³éã€‚å…§å®¹: {row_content}")
            continue

        course_name = row_content.get('ç§‘ç›®åç¨±', '')
        raw_credit_gpa = row_content.get('å­¸åˆ†', '') # ç”±æ–¼å­¸åˆ†å’ŒGPAå¯èƒ½åœ¨åŒä¸€æ¬„ä½ï¼Œé€™è£¡å–å…¶å…§å®¹

        # å¾åŸå§‹å­¸åˆ†/GPAæ¬„ä½ä¸­è§£æå‡ºå­¸åˆ†å’ŒGPA
        parsed_credit, parsed_gpa = identify_gpa_and_credits(raw_credit_gpa)

        current_credit = parsed_credit
        current_gpa = parsed_gpa

        # å¦‚æœå–®ç¨çš„GPAæ¬„ä½è¢«è­˜åˆ¥å‡ºä¾†ï¼Œå‰‡å„ªå…ˆä½¿ç”¨å…¶å€¼
        if 'GPA' in row_content and row_content['GPA'] != raw_credit_gpa:
            # å˜—è©¦å†æ¬¡è§£æä»¥ç¢ºä¿æ­£ç¢ºæ€§
            _, gpa_from_gpa_col = identify_gpa_and_credits(row_content['GPA'])
            if gpa_from_gpa_col is not None:
                current_gpa = gpa_from_gpa_col
        
        # æª¢æŸ¥æ˜¯å¦æˆåŠŸè§£æåˆ°å­¸åˆ†å’Œ GPA
        if current_credit is None:
            # st.warning(f"ç§‘ç›® '{course_name}' æœªèƒ½è§£æåˆ°å­¸åˆ†ï¼Œå·²è·³éæ­¤ç§‘ç›®è¨ˆç®—ã€‚åŸå§‹å…§å®¹: '{raw_credit_gpa}'")
            continue
        
        # è½‰æ› GPA ç‚ºæ•¸å€¼ (å¦‚æœå®ƒæ˜¯å­—æ¯ç­‰ç´š)
        gpa_value = 0.0
        if isinstance(current_gpa, str) and current_gpa in grades_mapping:
            gpa_value = grades_mapping[current_gpa]
        elif isinstance(current_gpa, (float, int)):
            gpa_value = float(current_gpa)
        else:
            # st.warning(f"ç§‘ç›® '{course_name}' æœªèƒ½è§£æåˆ°æœ‰æ•ˆ GPA æˆ– GPA ä¸åœ¨å°æ‡‰è¡¨ä¸­ï¼Œå·²è·³éæ­¤ç§‘ç›®è¨ˆç®—ã€‚åŸå§‹å…§å®¹: '{raw_credit_gpa}', è§£æçµæœ: '{current_gpa}'")
            continue # å¦‚æœ GPA ç„¡æ•ˆï¼Œå‰‡ä¸è¨ˆå…¥ GPA è¨ˆç®—

        # ç´¯åŠ å­¸åˆ†å’ŒåŠ æ¬Š GPA
        total_credits += current_credit
        if gpa_value > 0: # åªæœ‰æœ‰æ•ˆ GPA çš„ç§‘ç›®æ‰è¨ˆå…¥åŠ æ¬Šå¹³å‡
            weighted_gpa_sum += gpa_value * current_credit
            num_courses_for_gpa += 1 # è¨ˆæ•¸ç”¨æ–¼ç¢ºä¿æœ‰å¯¦éš›èª²ç¨‹åƒèˆ‡GPAè¨ˆç®—

    average_gpa = 0.0
    if total_credits > 0: # ä½¿ç”¨ total_credits ä½œç‚ºåˆ†æ¯ä¾†è¨ˆç®—å¹³å‡ GPA
        average_gpa = weighted_gpa_sum / total_credits

    return total_credits, average_gpa

def process_pdf_file(pdf_file, grades_mapping):
    """
    è™•ç†ä¸Šå‚³çš„ PDF æª”æ¡ˆï¼Œæå–è¡¨æ ¼ä¸¦è¨ˆç®—å­¸åˆ†å’Œ GPAã€‚
    """
    all_extracted_data = []

    # è¨­å®š pdfplumber çš„è¡¨æ ¼æå–åƒæ•¸
    table_settings = {
        "vertical_strategy": "text", 
        "horizontal_strategy": "text", 
        "snap_tolerance": 15,  # å¢å¤§å®¹å¿åº¦
        "join_tolerance": 18,  # å¢å¤§å®¹å¿åº¦
        "edge_min_length": 1,  # è¨­ç‚ºæ›´å°çš„å€¼
        "text_tolerance": 7,   # å¢å¤§å®¹å¿åº¦
        "min_words_vertical": 1, 
        "min_words_horizontal": 1, 
    }

    try:
        with pdfplumber.open(pdf_file) as pdf:
            for page_num, page in enumerate(pdf.pages):
                st.write(f"æ­£åœ¨è™•ç†é é¢: {page_num + 1}")
                # å˜—è©¦å¾é é¢æå–è¡¨æ ¼
                tables = page.extract_tables(table_settings)

                for table_idx, table in enumerate(tables):
                    st.write(f"  åµæ¸¬åˆ°è¡¨æ ¼ {table_idx + 1}")
                    # ä½¿ç”¨ is_grades_table åˆ¤æ–·æ˜¯å¦ç‚ºæˆç¸¾è¡¨
                    is_grade_table_result, identified_cols, original_header = is_grades_table(table)

                    if is_grade_table_result:
                        st.success(f"  é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} è¢«è­˜åˆ¥ç‚ºæˆç¸¾è¡¨ã€‚")
                        st.json({"è­˜åˆ¥åˆ°çš„å­¸å¹´æ¬„ä½": identified_cols.get('å­¸å¹´'), 
                                 "å­¸æœŸæ¬„ä½": identified_cols.get('å­¸æœŸ'),
                                 "ç§‘ç›®æ¬„ä½": identified_cols.get('ç§‘ç›®åç¨±'), 
                                 "å­¸åˆ†æ¬„ä½": identified_cols.get('å­¸åˆ†'), 
                                 "GPAæ¬„ä½": identified_cols.get('GPA')})

                        # è™•ç†åŸå§‹è¡¨æ ¼æ•¸æ“šï¼Œæº–å‚™ DataFrame
                        data_rows = []
                        header_map_to_idx = {col_name: i for i, col_name in enumerate(original_header)}
                        
                        # ç¢ºä¿ identified_cols ä¸­çš„æ¯å€‹è­˜åˆ¥åˆ°çš„ 'Column_X' éƒ½æœ‰å°æ‡‰çš„ç´¢å¼•
                        col_mapping = {}
                        for key, col_id in identified_cols.items():
                            if col_id and col_id.startswith('Column_'):
                                try:
                                    # æå– Column_X ä¸­çš„æ•¸å­— X
                                    original_col_idx = int(col_id.split('_')[1]) - 1
                                    col_mapping[key] = original_col_idx
                                except ValueError:
                                    col_mapping[key] = None
                            else:
                                col_mapping[key] = None

                        # è·³éç¬¬ä¸€è¡Œï¼ˆæ¨™é ­è¡Œï¼‰ï¼Œå¾ç¬¬äºŒè¡Œé–‹å§‹è™•ç†æ•¸æ“š
                        for row_idx, row_cells in enumerate(table):
                            if row_idx == 0: # å‡è¨­ç¬¬ä¸€è¡Œæ˜¯æ¨™é ­ï¼Œä½†åœ¨ is_grades_table ä¸­å·²ç¶“è™•ç†é
                                continue

                            # ç¢ºä¿è¡Œè¶³å¤ é•·
                            if not row_cells or len(row_cells) < max(header_map_to_idx.values()) + 1 if header_map_to_idx else 0:
                                continue

                            row_data = {}
                            # ä½¿ç”¨è­˜åˆ¥åˆ°çš„æ¬„ä½åç¨±å’ŒåŸå§‹ç´¢å¼•ä¾†æ§‹å»ºè¡Œæ•¸æ“š
                            for identified_key, original_col_idx in col_mapping.items():
                                if original_col_idx is not None and original_col_idx < len(row_cells):
                                    row_data[identified_key] = normalize_text(row_cells[original_col_idx])
                                else:
                                    row_data[identified_key] = "" # ç¢ºä¿æ¬„ä½å­˜åœ¨ï¼Œå³ä½¿ç‚ºç©º

                            # åƒ…ç•¶ç§‘ç›®åç¨±ä¸ç‚ºç©ºæ™‚æ‰æ·»åŠ è©²è¡Œ
                            if row_data.get('ç§‘ç›®åç¨±'):
                                all_extracted_data.append(row_data)

                    else:
                        st.info(f"  é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} æœªè­˜åˆ¥ç‚ºæˆç¸¾è¡¨ã€‚åŸå§‹è³‡æ–™åˆ—å…§å®¹: {table[0] if table else 'N/A'}")
                        st.json({"è­˜åˆ¥åˆ°çš„å­¸å¹´æ¬„ä½": identified_cols.get('å­¸å¹´'), 
                                 "å­¸æœŸæ¬„ä½": identified_cols.get('å­¸æœŸ'),
                                 "ç§‘ç›®æ¬„ä½": identified_cols.get('ç§‘ç›®åç¨±'), 
                                 "å­¸åˆ†æ¬„ä½": identified_cols.get('å­¸åˆ†'), 
                                 "GPAæ¬„ä½": identified_cols.get('GPA')})
                        st.warning("è©²è¡Œè¢«åˆ¤æ–·ç‚ºç©ºè¡Œã€æ¨™é ­è¡Œæˆ–è¡Œæ”¿æ€§æ–‡å­—ï¼Œå·²è·³éã€‚åŸå§‹è³‡æ–™åˆ—å…§å®¹: " + str([normalize_text(c) for c in table[0]]))


    except Exception as e:
        st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame(), 0.0, 0.0

    # å°‡æ‰€æœ‰æå–çš„æ•¸æ“šè½‰æ›ç‚º DataFrame
    df = pd.DataFrame(all_extracted_data)
    
    # ç¢ºä¿ DataFrame ä¸­å­˜åœ¨æ‰€æœ‰é æœŸçš„æ¬„ä½ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡æ·»åŠ ç©ºæ¬„ä½
    expected_cols = ['å­¸å¹´', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']
    for col in expected_cols:
        if col not in df.columns:
            df[col] = ''

    if df.empty:
        st.warning("æœªå¾ PDF ä¸­æå–åˆ°ä»»ä½•æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚")
        return pd.DataFrame(), 0.0, 0.0

    # è¨ˆç®—ç¸½å­¸åˆ†æ•¸å’Œå¹³å‡ GPA
    total_credits, average_gpa = calculate_total_credits(df.copy(), grades_mapping) # å‚³éå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹ df

    return df, total_credits, average_gpa

# --- Streamlit ä»‹é¢ ---
st.title("ğŸ“ GPA åŠå­¸åˆ†è¨ˆç®—å™¨")

st.write("è«‹ä¸Šå‚³æ‚¨çš„æˆç¸¾å–® PDF æª”æ¡ˆï¼Œæˆ‘æœƒç‚ºæ‚¨è¨ˆç®—ç¸½å­¸åˆ†å’Œå¹³å‡ GPAã€‚")

# è‡ªå®šç¾© GPA ç­‰ç´šå°æ‡‰è¡¨
st.subheader("è¨­å®š GPA ç­‰ç´šå°æ‡‰è¡¨")
st.write("è«‹ç¢ºä¿æ‚¨çš„å­¸æ ¡æˆç¸¾ç­‰ç´šèˆ‡æ­¤è™•çš„ GPA å€¼å°æ‡‰æ­£ç¢ºã€‚æ‚¨å¯ä»¥ä¿®æ”¹å®ƒã€‚")

# é è¨­ GPA å°æ‡‰è¡¨
default_grades_mapping = {
    'A+': 4.3, 'A': 4.0, 'A-': 3.7,
    'B+': 3.3, 'B': 3.0, 'B-': 2.7,
    'C+': 2.3, 'C': 2.0, 'C-': 1.7,
    'D+': 1.3, 'D': 1.0, 'D-': 0.7,
    'F': 0.0, 'X': 0.0, 'XF': 0.0 # X æˆ– XF é€šå¸¸ä»£è¡¨ä¸åŠæ ¼
}

# å…è¨±ç”¨æˆ¶ä¿®æ”¹å°æ‡‰è¡¨
edited_grades_mapping = {}
col1, col2 = st.columns(2)
for i, (grade, gpa_val) in enumerate(default_grades_mapping.items()):
    if i % 2 == 0:
        with col1:
            edited_grades_mapping[grade] = st.number_input(f"{grade} å°æ‡‰ GPA:", value=gpa_val, key=f"gpa_input_{grade}")
    else:
        with col2:
            edited_grades_mapping[grade] = st.number_input(f"{grade} å°æ‡‰ GPA:", value=gpa_val, key=f"gpa_input_{grade}")

uploaded_file = st.file_uploader("é¸æ“‡ä¸€å€‹ PDF æª”æ¡ˆ", type="pdf")

if uploaded_file is not None:
    st.success(f"æª”æ¡ˆ '{uploaded_file.name}' å·²æˆåŠŸä¸Šå‚³ï¼")
    
    # è®€å–æª”æ¡ˆå…§å®¹åˆ° BytesIO
    pdf_bytes = BytesIO(uploaded_file.getvalue())

    # è™•ç† PDF æª”æ¡ˆ
    with st.spinner("æ­£åœ¨è™•ç† PDFï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“..."):
        df_grades, total_credits, average_gpa = process_pdf_file(pdf_bytes, edited_grades_mapping)
    
    if not df_grades.empty:
        st.subheader("æå–åˆ°çš„æˆç¸¾æ•¸æ“š (éƒ¨åˆ†é è¦½)")
        st.dataframe(df_grades)

        st.subheader("è¨ˆç®—çµæœ")
        st.metric("ç¸½å­¸åˆ†æ•¸", f"{total_credits:.2f}")
        st.metric("å¹³å‡ GPA", f"{average_gpa:.2f}")
    else:
        st.error("æœªèƒ½å¾ä¸Šå‚³çš„ PDF æª”æ¡ˆä¸­æå–åˆ°ä»»ä½•æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æˆ–å˜—è©¦å…¶ä»–æª”æ¡ˆã€‚")
        st.info("æç¤ºï¼šç¢ºä¿æ‚¨çš„ PDF æˆç¸¾å–®æ˜¯æ–‡å­—å¯é¸å–çš„ï¼Œè€Œä¸æ˜¯åœ–ç‰‡æƒæä»¶ã€‚")

st.markdown("---")
st.write("å¦‚æœæ‚¨é‡åˆ°ä»»ä½•å•é¡Œï¼Œè«‹æª¢æŸ¥åŸå§‹ç¨‹å¼ç¢¼æˆ–æä¾›æ›´å¤šè©³ç´°è³‡è¨Šã€‚")
