import streamlit as st
import pandas as pd
import io
import pdfplumber
import re

# --- 1. å®šç¾©è¼”åŠ©å‡½æ•¸ ---

def normalize_text(text):
    """
    æ¨™æº–åŒ–æ–‡æœ¬ï¼šç§»é™¤æ›è¡Œç¬¦ã€å…¨å½¢ç©ºæ ¼ï¼Œä¸¦ä¿®å‰ªç©ºç™½ã€‚
    """
    if text is None:
        return ""
    text = str(text) # ç¢ºä¿è¼¸å…¥æ˜¯å­—ä¸²
    # ç§»é™¤æ›è¡Œç¬¦ã€å›è»Šç¬¦ï¼Œä¸¦å°‡å…¨å½¢ç©ºæ ¼è½‰æ›ç‚ºåŠå½¢ç©ºæ ¼ï¼Œç„¶å¾Œä¿®å‰ªå‰å¾Œç©ºç™½
    text = text.replace('\n', ' ').replace('\r', '').replace('\u3000', ' ').strip()
    # é‡å°ä¸­æ–‡æ¨™é»ç¬¦è™Ÿçš„æ›¿æ›ï¼Œé€™éƒ¨åˆ†æ‚¨ä¹‹å‰å¯èƒ½æœ‰å®šç¾©ï¼Œé€™è£¡å¯ä»¥ä¿ç•™æˆ–æ·»åŠ 
    text = text.replace('ï¼Œ', ',').replace('ã€‚', '.').replace('ï¼š', ':').replace('ï¼›', ';')
    text = text.replace('ã€€', ' ') # å†æ¬¡è™•ç†å…¨å½¢ç©ºæ ¼
    return text

def parse_gpa_to_numeric(gpa_str):
    """
    å°‡ GPA å­—ä¸²è½‰æ›ç‚ºæ•¸å€¼ï¼Œè™•ç†ç‰¹æ®Šå€¼å¦‚ 'æŠµå…' å’Œ 'é€šé'ã€‚
    """
    gpa_str = normalize_text(gpa_str)
    gpa_mapping = {
        'A+': 4.3, 'A': 4.0, 'A-': 3.7,
        'B+': 3.3, 'B': 3.0, 'B-': 2.7,
        'C+': 2.3, 'C': 2.0, 'C-': 1.7,
        # 'D+': 1.3, 'D': 1.0, 'D-': 0.7, # æ ¹æ“šæ‚¨çš„èªªæ˜ï¼ŒD ç‚ºä¸åŠæ ¼ï¼Œä¸è¨ˆå…¥å­¸åˆ†ï¼Œä½†ç‚ºä¿ç•™åŸå§‹GPAå€¼ï¼Œæ­¤è™•ä»ä¿ç•™æ˜ å°„
        'D+': 0.0, 'D': 0.0, 'D-': 0.0, # å‡è¨­ D ç­‰ç´šä¸è¨ˆå…¥æœ‰æ•ˆGPAè¨ˆç®—
        'E': 0.0, 'F': 0.0, 'X': 0.0,
        'æŠµå…': 0.0, 'é€šé': 0.0, '': 0.0, 'None': 0.0
    }
    return gpa_mapping.get(gpa_str, 0.0)

def parse_gpa_credit_from_combined_cell(gpa_cell_content, credit_cell_content):
    """
    è™•ç† GPA å’Œå­¸åˆ†å¯èƒ½åˆä½µåœ¨ä¸€å€‹å–®å…ƒæ ¼ï¼Œæˆ–æå–ä¸æ­£ç¢ºçš„æƒ…æ³ã€‚
    è¿”å›æ¸…ç†å¾Œçš„ GPA å’Œå­¸åˆ†å€¼ã€‚
    """
    # ç¢ºä¿æ‰€æœ‰è¼¸å…¥éƒ½æ˜¯å­—ä¸²ä¸¦æ­£è¦åŒ–
    original_gpa_str = normalize_text(gpa_cell_content)
    original_credit_str = normalize_text(credit_cell_content)

    parsed_gpa = original_gpa_str
    parsed_credit = original_credit_str

    # å®šç¾©ä¸€å€‹æ­£å‰‡è¡¨é”å¼ä¾†åŒ¹é…å¯èƒ½çš„æˆç¸¾å’Œå­¸åˆ†æ•¸å­—
    # å…è¨±æˆç¸¾éƒ¨åˆ†åŒ…å«å­—æ¯ã€+/-ã€ä¸­æ–‡çš„æŠµå…/é€šéï¼Œæ•¸å­—éƒ¨åˆ†åŒ…å«æ•¸å­—å’Œé»
    # (\S*) åŒ¹é…éç©ºç™½å­—ç¬¦ä½œç‚ºæˆç¸¾éƒ¨åˆ†ï¼ˆç›¡å¯èƒ½å¤šï¼‰
    # (\d*\.?\d*) åŒ¹é…æ•¸å­—æˆ–æµ®é»æ•¸ä½œç‚ºå­¸åˆ†éƒ¨åˆ†
    grade_credit_pattern = re.compile(r'^\s*([A-Z\+\-\u4F5C\u4F4D\u62B5\u514D\u901A\u904E]*)\s*(\d*\.?\d*)\s*$')
    # é€™è£¡é¡å¤–åŠ å…¥äº† "ä½œ" "ä½" æ˜¯ç‚ºäº†è™•ç† "æŠµå…" çš„ç°¡é«”å­—å•é¡Œï¼Œå¯ä»¥æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´

    # å˜—è©¦å¾åŸå§‹ GPA å–®å…ƒæ ¼è§£æ
    match_gpa_cell = grade_credit_pattern.match(original_gpa_str)
    # å˜—è©¦å¾åŸå§‹ Credit å–®å…ƒæ ¼è§£æ
    match_credit_cell = grade_credit_pattern.match(original_credit_str)

    # æƒ…æ³1ï¼šå­¸åˆ†å–®å…ƒæ ¼æ˜¯ç©ºçš„æˆ–çœ‹èµ·ä¾†åƒæˆç¸¾ï¼Œå˜—è©¦å¾ GPA å–®å…ƒæ ¼è§£æ
    # å¦‚æœåŸå§‹å­¸åˆ†çœ‹èµ·ä¾†ä¸åƒæ•¸å­—ï¼Œä¸”åŸå§‹ GPA å–®å…ƒæ ¼æœ‰å…§å®¹
    if (not original_credit_str.replace('.', '', 1).isdigit() and original_gpa_str):
        if match_gpa_cell:
            grade_part_g = match_gpa_cell.group(1).strip()
            num_part_g = match_gpa_cell.group(2).strip()

            # å¦‚æœ GPA å–®å…ƒæ ¼åŒ…å«æˆç¸¾å’Œæ•¸å­—ï¼Œä¸¦ä¸”å­¸åˆ†å–®å…ƒæ ¼æ˜¯ç©ºçš„æˆ–åªæœ‰æˆç¸¾
            if (parse_gpa_to_numeric(grade_part_g) != 0.0 or grade_part_g in ['æŠµå…', 'é€šé']) and num_part_g.replace('.', '', 1).isdigit():
                parsed_gpa = grade_part_g
                parsed_credit = num_part_g
            # å¦‚æœ GPA å–®å…ƒæ ¼åªæœ‰æˆç¸¾
            elif (parse_gpa_to_numeric(grade_part_g) != 0.0 or grade_part_g in ['æŠµå…', 'é€šé']) and not num_part_g:
                parsed_gpa = grade_part_g
                parsed_credit = original_credit_str if original_credit_str.replace('.', '', 1).isdigit() else '' # ç¢ºä¿å­¸åˆ†é‚„æ˜¯æ•¸å­—
            # å¦‚æœ GPA å–®å…ƒæ ¼åªæœ‰æ•¸å­—
            elif num_part_g.replace('.', '', 1).isdigit() and not grade_part_g:
                parsed_credit = num_part_g
                parsed_gpa = original_gpa_str if (parse_gpa_to_numeric(original_gpa_str) != 0.0 or original_gpa_str in ['æŠµå…', 'é€šé']) else ''


    # æƒ…æ³2ï¼šGPA å–®å…ƒæ ¼æ˜¯ç©ºçš„æˆ–çœ‹èµ·ä¾†åƒå­¸åˆ†æ•¸å­—ï¼Œå˜—è©¦å¾ Credit å–®å…ƒæ ¼è§£æ
    # å¦‚æœåŸå§‹ GPA çœ‹èµ·ä¾†ä¸åƒæˆç¸¾ï¼Œä¸”åŸå§‹ Credit å–®å…ƒæ ¼æœ‰å…§å®¹
    if (not (parse_gpa_to_numeric(original_gpa_str) != 0.0 or original_gpa_str in ['æŠµå…', 'é€šé']) and original_credit_str):
        if match_credit_cell:
            grade_part_c = match_credit_cell.group(1).strip()
            num_part_c = match_credit_cell.group(2).strip()

            # å¦‚æœ Credit å–®å…ƒæ ¼åŒ…å«æˆç¸¾å’Œæ•¸å­—ï¼Œä¸¦ä¸” GPA å–®å…ƒæ ¼æ˜¯ç©ºçš„æˆ–åªæœ‰å­¸åˆ†
            if (parse_gpa_to_numeric(grade_part_c) != 0.0 or grade_part_c in ['æŠµå…', 'é€šé']) and num_part_c.replace('.', '', 1).isdigit():
                parsed_gpa = grade_part_c
                parsed_credit = num_part_c
            # å¦‚æœ Credit å–®å…ƒæ ¼åªæœ‰æˆç¸¾
            elif (parse_gpa_to_numeric(grade_part_c) != 0.0 or grade_part_c in ['æŠµå…', 'é€šé']) and not num_part_c:
                parsed_gpa = grade_part_c
                parsed_credit = original_credit_str if original_credit_str.replace('.', '', 1).isdigit() else ''
            # å¦‚æœ Credit å–®å…ƒæ ¼åªæœ‰æ•¸å­—
            elif num_part_c.replace('.', '', 1).isdigit() and not grade_part_c:
                parsed_credit = num_part_c
                parsed_gpa = original_gpa_str if (parse_gpa_to_numeric(original_gpa_str) != 0.0 or original_gpa_str in ['æŠµå…', 'é€šé']) else ''


    # æœ€çµ‚æ ¡é©—ï¼šç¢ºä¿ GPA æ˜¯æˆç¸¾æ ¼å¼ï¼Œå­¸åˆ†æ˜¯æ•¸å­—æ ¼å¼
    final_gpa = parsed_gpa
    final_credit = parsed_credit

    is_gpa_format = (parse_gpa_to_numeric(final_gpa) != 0.0 or final_gpa in ['æŠµå…', 'é€šé']) and not final_gpa.replace('.', '', 1).isdigit()
    is_credit_format = final_credit.replace('.', '', 1).isdigit()

    # å¦‚æœ GPA æ¬„ä½æ˜¯æ•¸å­—æ ¼å¼ï¼Œå­¸åˆ†æ¬„ä½æ˜¯æˆç¸¾æ ¼å¼ï¼Œå‰‡äº¤æ›
    if final_gpa.replace('.', '', 1).isdigit() and (parse_gpa_to_numeric(final_credit) != 0.0 or final_credit in ['æŠµå…', 'é€šé']):
        final_gpa, final_credit = final_credit, final_gpa

    # å¦‚æœè§£æçµæœä¸æ˜¯é æœŸçš„æ ¼å¼ï¼Œç›¡å¯èƒ½ä½¿ç”¨åŸå§‹å€¼ï¼ˆå¦‚æœåŸå§‹å€¼ç¬¦åˆå–®ä¸€æ ¼å¼ï¼‰
    if not is_gpa_format and (parse_gpa_to_numeric(original_gpa_str) != 0.0 or original_gpa_str in ['æŠµå…', 'é€šé']):
        final_gpa = original_gpa_str
    if not is_credit_format and original_credit_str.replace('.', '', 1).isdigit():
        final_credit = original_credit_str

    # ç¢ºä¿è¿”å›çš„å­¸åˆ†æ˜¯ç©ºå­—ä¸²æˆ–æ•¸å­—å­—ä¸²
    if not final_credit.replace('.', '', 1).isdigit() and final_credit != '':
        final_credit = '' # å¦‚æœæœ€çµ‚å­¸åˆ†ä¸æ˜¯æ•¸å­—ï¼Œå‰‡æ¸…ç©º

    return final_gpa, final_credit

def analyze_student_grades(df):
    """
    åˆ†æå­¸ç”Ÿçš„æˆç¸¾ DataFrameï¼Œè¨ˆç®—ç¸½å­¸åˆ†ã€æ‰€éœ€å­¸åˆ†å’Œé€šéçš„èª²ç¨‹ã€‚
    """
    if df.empty:
        return 0, 128, pd.DataFrame(columns=['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA'])

    # ç¢ºä¿ GPA å’Œ å­¸åˆ† æ¬„ä½æ˜¯æ­£ç¢ºçš„æ•¸æ“šé¡å‹
    df['GPA_Numeric'] = df['GPA'].apply(parse_gpa_to_numeric)
    # å°‡ 'å­¸åˆ†' è½‰æ›ç‚ºæ•¸å€¼ï¼Œç„¡æ³•è½‰æ›çš„è¨­ç‚º NaNï¼Œç„¶å¾Œå¡«å……ç‚º 0
    df['å­¸åˆ†'] = pd.to_numeric(df['å­¸åˆ†'], errors='coerce').fillna(0)

    # å‡è¨­é€šéçš„æ¨™æº–æ˜¯ GPA > 0 (A+åˆ°C-)ï¼Œæˆ–ç‚º 'æŠµå…' æˆ– 'é€šé'ï¼Œä¸”å­¸åˆ†å¤§æ–¼ 0
    # æ ¹æ“šæ‚¨çš„éœ€æ±‚ï¼Œ'D' ç­‰ç´šçš„ GPA_Numeric ç‚º 0ï¼Œå› æ­¤ä¸æœƒè¢«è¨ˆå…¥
    passed_courses_df = df[
        ((df['GPA_Numeric'] > 0) | (df['GPA'].isin(['æŠµå…', 'é€šé']))) &
        (df['å­¸åˆ†'] > 0) # ç¢ºä¿å­¸åˆ†å¤§æ–¼ 0 ä¸”ä¸æ˜¯å‹ä½œæ•™è‚²ï¼ˆå·²åœ¨å‰é¢éæ¿¾ï¼‰
    ].copy() # ä½¿ç”¨ .copy() é¿å… SettingWithCopyWarning

    total_credits = passed_courses_df['å­¸åˆ†'].sum()
    required_credits = 128
    remaining_credits = max(0, required_credits - total_credits)

    return total_credits, remaining_credits, passed_courses_df

# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é«” ---
def main():
    st.title("ç¸½å­¸åˆ†æŸ¥è©¢ç³»çµ± ğŸ“")
    st.write("è«‹ä¸Šå‚³æ‚¨çš„æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆï¼Œç³»çµ±å°‡æœƒç‚ºæ‚¨æŸ¥è©¢ç›®å‰ç¸½å­¸åˆ†èˆ‡è·é›¢ç•¢æ¥­æ‰€éœ€çš„å­¸åˆ†ã€‚")
    st.info("ğŸ’¡ ç¢ºä¿æ‚¨çš„æˆç¸¾å–® PDF æ˜¯æ¸…æ™°çš„è¡¨æ ¼æ ¼å¼ï¼Œä»¥ç²å¾—æœ€ä½³è§£ææ•ˆæœã€‚")

    uploaded_file = st.file_uploader("ä¸Šå‚³æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆ", type=["pdf"])

    # ç¢ºä¿ all_grades_data å’Œ full_grades_df åœ¨ main å‡½æ•¸é–‹å§‹æ™‚è¢«åˆå§‹åŒ–
    all_grades_data = []  # æ¯æ¬¡ä¸Šå‚³æª”æ¡ˆæ™‚é‡æ–°åˆå§‹åŒ–
    full_grades_df = pd.DataFrame()  # æ¯æ¬¡ä¸Šå‚³æª”æ¡ˆæ™‚é‡æ–°åˆå§‹åŒ–

    if uploaded_file is not None:
        st.success("æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼æ­£åœ¨åˆ†æä¸­...")

        try:
            expected_header_keywords = ["å­¸å¹´åº¦", "å­¸æœŸ", "é¸èª²ä»£è™Ÿ", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]
            
            with pdfplumber.open(io.BytesIO(uploaded_file.getvalue())) as pdf:
                total_pages = len(pdf.pages)

                for page_num, page in enumerate(pdf.pages):
                    st.write(f"æ­£åœ¨è™•ç†é é¢ {page_num + 1}/{total_pages}...") # å¢åŠ é€²åº¦é¡¯ç¤º
                    top_y_crop = 0
                    bottom_y_crop = page.height

                    # é‡å°ç‰¹å®šæª”æ¡ˆåèª¿æ•´è£å‰ªé«˜åº¦ï¼Œå¯ä»¥å˜—è©¦æ›´å¯¬é¬†çš„ç¯„åœæˆ–çµ±ä¸€è™•ç†
                    # é€™è£¡çµ±ä¸€è¨­ç½®ä¸€å€‹è¼ƒå¤§çš„è£å‰ªç¯„åœï¼Œå¦‚æœä»æœ‰å•é¡Œï¼Œå†è€ƒæ…®æ›´ç²¾ç¢ºèª¿æ•´
                    if "è¬äº‘ç‘„æˆç¸¾ç¸½è¡¨.pdf" in uploaded_file.name:
                        # è¬é›²è±çš„ PDF é¦–é å’Œå¾ŒçºŒé é¢çš„è£å‰ªYè»¸å·®ç•°ä¸å¤§ï¼Œå¯ä»¥å˜—è©¦çµ±ä¸€
                        top_y_crop = 120 # é™ä½ä¸€é»é»ï¼Œæ¸›å°‘åˆ‡åˆ°è¡¨æ ¼çš„é¢¨éšª
                        bottom_y_crop = page.height - 30
                    elif "é‚±æ—­å»·æˆç¸¾ç¸½è¡¨.pdf" in uploaded_file.name:
                        # é‚±æ—­å»·çš„ PDF é¦–é å¯èƒ½éœ€è¦æ›´é«˜çš„è£å‰ª
                        top_y_crop = 200 if page_num == 0 else 80 # ç¨å¾®èª¿ä½é»
                        bottom_y_crop = page.height - 30
                    else: # é è¨­é€šç”¨è¨­ç½®
                        top_y_crop = 100 if page_num == 0 else 50
                        bottom_y_crop = page.height - 30

                    cropped_page = page.crop((0, top_y_crop, page.width, bottom_y_crop))
                    
                    # èª¿æ•´ table_settingsï¼Œå¢åŠ å®¹å¿åº¦ï¼Œæé«˜æå–æˆåŠŸç‡
                    table_settings = {
                        "vertical_strategy": "lines",
                        "horizontal_strategy": "lines",
                        "snap_tolerance": 3,  # å¢åŠ å®¹å¿åº¦
                        "text_tolerance": 3,  # å¢åŠ å®¹å¿åº¦
                        "join_tolerance": 3,  # å¢åŠ å®¹å¿åº¦
                        "edge_min_length": 5, # ç¨å¾®å¢åŠ æœ€å°ç·šæ®µé•·åº¦
                        "min_words_horizontal": 1,
                        "min_words_vertical": 1,
                        "snap_vertical": None, # è®“ pdfplumber è‡ªå‹•åˆ¤æ–·
                        "snap_horizontal": None # è®“ pdfplumber è‡ªå‹•åˆ¤æ–·
                    }
                    
                    tables = cropped_page.extract_tables(table_settings)
                    
                    if not tables:
                        st.write(f"é é¢ {page_num + 1}: æœªèƒ½æå–åˆ°ä»»ä½•è¡¨æ ¼ã€‚")
                        continue

                    for table_idx, table in enumerate(tables):
                        if not table or len(table) < 1:
                            continue

                        filtered_table = []
                        for row in table:
                            # ç¢ºä¿ cell æ˜¯å­—ä¸²ï¼Œä¸¦å‘¼å« normalize_text
                            normalized_row = [normalize_text(cell) for cell in row]  
                            if any(cell.strip() for cell in normalized_row):
                                filtered_table.append(normalized_row)
                        
                        if not filtered_table:
                            st.write(f"é é¢ {page_num + 1}, è¡¨æ ¼ {table_idx + 1}: éæ¿¾å¾Œç„¡æœ‰æ•ˆæ•¸æ“šã€‚")
                            continue
                        
                        header_row_found = False
                        header = []
                        header_row_start_idx = -1

                        potential_header_search_range = min(len(filtered_table), 5)
                        for h_idx in range(potential_header_search_range):
                            h_row_cells = [cell.strip() for cell in filtered_table[h_idx]]
                            
                            # å¼·åŒ–è¡¨é ­åŒ¹é…ï¼Œä½¿ç”¨æ­£å‰‡è¡¨é”å¼æˆ–æ›´å¯¬é¬†çš„åŒ…å«æª¢æŸ¥
                            header_match_criteria = [
                                any(re.search(r'å­¸å¹´', cell) for cell in h_row_cells),
                                any(re.search(r'ç§‘ç›®åç¨±', cell) for cell in h_row_cells),
                                any(re.search(r'å­¸åˆ†', cell) for cell in h_row_cells),
                                any(re.search(r'GPA', cell) for cell in h_row_cells)
                            ]

                            if all(header_match_criteria):
                                header = h_row_cells
                                header_row_found = True
                                header_row_start_idx = h_idx
                                st.write(f"é é¢ {page_num + 1}, è¡¨æ ¼ {table_idx + 1}: æ‰¾åˆ°è¡¨é ­ã€‚")
                                break
                        
                        if not header_row_found:
                            # å‚™ç”¨æ–¹æ¡ˆï¼šå¦‚æœç¬¬ä¸€è¡Œçœ‹èµ·ä¾†åƒæ•¸æ“šï¼ˆå­¸å¹´åº¦æ˜¯ä¸‰ä½æ•¸å­—ï¼‰ï¼Œå‰‡å‡è¨­ç¬¬ä¸€è¡Œç‚ºæ•¸æ“šè¡Œ
                            if len(filtered_table[0]) > 0 and filtered_table[0][0].isdigit() and len(filtered_table[0][0]) == 3:
                                header = expected_header_keywords # ä½¿ç”¨é æœŸè¡¨é ­ä½œç‚ºåˆ—å
                                header_row_start_idx = -1 # è¡¨ç¤ºæ²’æœ‰æ˜ç¢ºè¡¨é ­è¡Œï¼Œæ•¸æ“šå¾ç¬¬ä¸€è¡Œé–‹å§‹
                                header_row_found = True
                                st.write(f"é é¢ {page_num + 1}, è¡¨æ ¼ {table_idx + 1}: æœªæ‰¾åˆ°æ˜ç¢ºè¡¨é ­ï¼Œå‡å®šç¬¬ä¸€è¡Œæ˜¯æ•¸æ“šã€‚")
                            else:
                                st.warning(f"é é¢ {page_num + 1}, è¡¨æ ¼ {table_idx + 1}: æœªèƒ½è­˜åˆ¥è¡¨é ­æˆ–æœ‰æ•ˆæ•¸æ“šè¡Œï¼Œè·³éæ­¤è¡¨æ ¼ã€‚")
                                continue

                        col_to_index = {}
                        for i, h_text in enumerate(header):
                            # ä½¿ç”¨æ›´å¯¬é¬†çš„åŒ¹é…ä¾†æ‰¾åˆ°åˆ—ç´¢å¼•
                            if re.search(r'å­¸å¹´', h_text): col_to_index["å­¸å¹´åº¦"] = i
                            elif re.search(r'å­¸æœŸ', h_text): col_to_index["å­¸æœŸ"] = i
                            elif re.search(r'ä»£è™Ÿ', h_text): col_to_index["é¸èª²ä»£è™Ÿ"] = i
                            elif re.search(r'ç§‘ç›®åç¨±', h_text): col_to_index["ç§‘ç›®åç¨±"] = i
                            elif re.search(r'å­¸åˆ†', h_text): col_to_index["å­¸åˆ†"] = i
                            elif re.search(r'GPA', h_text): col_to_index["GPA"] = i

                        critical_cols = ["å­¸å¹´åº¦", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]
                        if not all(col in col_to_index for col in critical_cols):
                            st.warning(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} ç¼ºå°‘é—œéµåˆ—ã€‚è·³éæ­¤è¡¨æ ¼ã€‚")
                            continue

                        # å¾ col_to_index å®‰å…¨åœ°ç²å–ç´¢å¼•
                        å­¸å¹´åº¦_idx = col_to_index.get("å­¸å¹´åº¦")
                        å­¸æœŸ_idx = col_to_index.get("å­¸æœŸ")
                        é¸èª²ä»£è™Ÿ_idx = col_to_index.get("é¸èª²ä»£è™Ÿ")
                        ç§‘ç›®åç¨±_idx = col_to_index.get("ç§‘ç›®åç¨±")
                        å­¸åˆ†_idx = col_to_index.get("å­¸åˆ†")
                        GPA_idx = col_to_index.get("GPA")

                        processed_rows = []
                        current_row_data_temp = {key: "" for key in expected_header_keywords} # ä½¿ç”¨å­—å…¸å­˜å„²ï¼Œæ›´å¥å£¯

                        data_rows_to_process = filtered_table[header_row_start_idx + 1:] if header_row_start_idx != -1 else filtered_table[:]

                        for row_num_in_table, row_cells in enumerate(data_rows_to_process):
                            # ç¢ºä¿ row_cells_padded è¶³å¤ é•·ï¼Œä»¥é˜²ç´¢å¼•è¶Šç•Œ
                            max_idx_needed = max( å­¸å¹´åº¦_idx if å­¸å¹´åº¦_idx is not None else -1,
                                                å­¸æœŸ_idx if å­¸æœŸ_idx is not None else -1,
                                                é¸èª²ä»£è™Ÿ_idx if é¸èª²ä»£è™Ÿ_idx is not None else -1,
                                                ç§‘ç›®åç¨±_idx if ç§‘ç›®åç¨±_idx is not None else -1,
                                                å­¸åˆ†_idx if å­¸åˆ†_idx is not None else -1,
                                                GPA_idx if GPA_idx is not None else -1)

                            row_cells_padded = row_cells + [''] * (max_idx_needed + 1 - len(row_cells))

                            # å®‰å…¨åœ°ç²å–æ¯å€‹å–®å…ƒæ ¼çš„å€¼
                            å­¸å¹´åº¦_val = normalize_text(row_cells_padded[å­¸å¹´åº¦_idx]) if å­¸å¹´åº¦_idx is not None and å­¸å¹´åº¦_idx < len(row_cells_padded) else ''
                            å­¸æœŸ_val = normalize_text(row_cells_padded[å­¸æœŸ_idx]) if å­¸æœŸ_idx is not None and å­¸æœŸ_idx < len(row_cells_padded) else ''
                            é¸èª²ä»£è™Ÿ_val = normalize_text(row_cells_padded[é¸èª²ä»£è™Ÿ_idx]) if é¸èª²ä»£è™Ÿ_idx is not None and é¸èª²ä»£è™Ÿ_idx < len(row_cells_padded) else ''
                            ç§‘ç›®åç¨±_val = normalize_text(row_cells_padded[ç§‘ç›®åç¨±_idx]) if ç§‘ç›®åç¨±_idx is not None and ç§‘ç›®åç¨±_idx < len(row_cells_padded) else ''
                            å­¸åˆ†_val_raw = normalize_text(row_cells_padded[å­¸åˆ†_idx]) if å­¸åˆ†_idx is not None and å­¸åˆ†_idx < len(row_cells_padded) else ''
                            GPA_val_raw = normalize_text(row_cells_padded[GPA_idx]) if GPA_idx is not None and GPA_idx < len(row_cells_padded) else ''

                            is_new_grade_row = False
                            # åˆ¤æ–·æ˜¯å¦ç‚ºæ–°çš„èª²ç¨‹è¡Œï¼šå­¸å¹´åº¦æ˜¯ä¸‰ä½æ•¸å­—ï¼Œä¸”ç§‘ç›®åç¨±ä¸ç‚ºç©º
                            # æ¸›å°‘å°é¸èª²ä»£è™Ÿçš„ä¾è³´ï¼Œå› ç‚ºå®ƒå¯èƒ½åœ¨æŸäº›è¡Œä¸­æ˜¯ç©ºçš„
                            if å­¸å¹´åº¦_val.isdigit() and len(å­¸å¹´åº¦_val) == 3 and ç§‘ç›®åç¨±_val.strip() != '':
                                is_new_grade_row = True
                            
                            # æˆ–è€…ï¼Œå¦‚æœç§‘ç›®åç¨±ä¸ç‚ºç©ºï¼Œä¸”å‰å…©å€‹æ¬„ä½éƒ½ç‚ºç©ºï¼Œä¹Ÿå¯èƒ½æ˜¯ä¸€å€‹æ–°è¡Œï¼ˆé‡å°è·¨é çš„ç¬¬ä¸€æ¬¡å‡ºç¾ï¼‰
                            elif å­¸å¹´åº¦_val.strip() == '' and å­¸æœŸ_val.strip() == '' and ç§‘ç›®åç¨±_val.strip() != '':
                                # åˆ¤æ–·é€™æ˜¯å¦æ˜¯ä¸€å€‹æ‡‰è©²ç¨ç«‹çš„æ–°è¡Œï¼Œè€Œä¸æ˜¯å‰ä¸€è¡Œçš„å»¶çºŒ
                                # å¦‚æœæœ¬è¡Œæœ‰å­¸åˆ†æˆ–GPAï¼Œæ›´å¯èƒ½æ˜¯æ–°è¡Œ
                                if å­¸åˆ†_val_raw.strip() != '' or GPA_val_raw.strip() != '':
                                    is_new_grade_row = True

                            if is_new_grade_row:
                                # å¦‚æœå·²ç¶“æœ‰æ­£åœ¨è™•ç†çš„è¡Œæ•¸æ“šï¼Œå…ˆå°‡å…¶æ·»åŠ åˆ° processed_rows
                                if current_row_data_temp['ç§‘ç›®åç¨±'].strip() != "": # ç¢ºä¿æœ‰å¯¦éš›å…§å®¹æ‰æ·»åŠ 
                                    processed_rows.append(list(current_row_data_temp.values())) # è½‰ç‚ºåˆ—è¡¨å†æ·»åŠ 
                                
                                # é–‹å§‹è™•ç†æ–°çš„è¡Œ
                                current_row_data_temp = {key: "" for key in expected_header_keywords}
                                current_row_data_temp["å­¸å¹´åº¦"] = å­¸å¹´åº¦_val
                                current_row_data_temp["å­¸æœŸ"] = å­¸æœŸ_val
                                current_row_data_temp["é¸èª²ä»£è™Ÿ"] = é¸èª²ä»£è™Ÿ_val
                                current_row_data_temp["ç§‘ç›®åç¨±"] = ç§‘ç›®åç¨±_val
                                
                                current_gpa, current_credit = parse_gpa_credit_from_combined_cell(GPA_val_raw, å­¸åˆ†_val_raw)
                                current_row_data_temp["GPA"] = current_gpa
                                current_row_data_temp["å­¸åˆ†"] = current_credit

                            elif current_row_data_temp['ç§‘ç›®åç¨±'].strip() != "": # å¦‚æœä¸æ˜¯æ–°è¡Œï¼Œå‰‡å¯èƒ½æ˜¯å‰ä¸€è¡Œçš„å»¶çºŒ
                                # åˆ¤æ–·æ˜¯å¦ç‚ºç§‘ç›®åç¨±çš„å»¶çºŒè¡Œ
                                if å­¸å¹´åº¦_val.strip() == '' and å­¸æœŸ_val.strip() == '' and é¸èª²ä»£è™Ÿ_val.strip() == '' and ç§‘ç›®åç¨±_val.strip() != '':
                                    current_row_data_temp["ç§‘ç›®åç¨±"] += " " + ç§‘ç›®åç¨±_val
                                
                                # å°æ–¼å»¶çºŒè¡Œï¼Œå¦‚æœå­¸åˆ†æˆ– GPA è¢«æ‰¾åˆ°ï¼Œå‰‡æ›´æ–°
                                # é¿å…è¦†è“‹å·²ç¶“å­˜åœ¨çš„æœ‰æ•ˆå€¼ï¼Œåªåœ¨ç•¶å‰ç‚ºç©ºæ™‚æ›´æ–°
                                if (å­¸åˆ†_val_raw.strip() != '' or GPA_val_raw.strip() != ''):
                                    merged_gpa, merged_credit = parse_gpa_credit_from_combined_cell(GPA_val_raw, å­¸åˆ†_val_raw)
                                    
                                    if current_row_data_temp["å­¸åˆ†"].strip() == "" and merged_credit.strip() != "":
                                        current_row_data_temp["å­¸åˆ†"] = merged_credit
                                    if current_row_data_temp["GPA"].strip() == "" and merged_gpa.strip() != "":
                                        current_row_data_temp["GPA"] = merged_gpa

                        # å°‡æœ€å¾Œä¸€è¡Œçš„æ•¸æ“šæ·»åŠ åˆ° processed_rows
                        if current_row_data_temp['ç§‘ç›®åç¨±'].strip() != "":
                            processed_rows.append(list(current_row_data_temp.values()))
                        
                        if processed_rows:
                            df_table = pd.DataFrame(processed_rows, columns=expected_header_keywords)
                            
                            # å° DataFrame ä¸­çš„æ‰€æœ‰åˆ—é€²è¡Œæœ€çµ‚çš„å­—ä¸²æ¸…ç†
                            for col in df_table.columns:
                                df_table[col] = df_table[col].astype(str).str.strip().replace('None', '').replace('nan', '')

                            all_grades_data.append(df_table)
                        else:
                            st.write(f"é é¢ {page_num + 1}, è¡¨æ ¼ {table_idx + 1}: æ²’æœ‰å¯è™•ç†çš„èª²ç¨‹æ•¸æ“šã€‚")

            if not all_grades_data:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼æˆ–èª¿æ•´è¡¨æ ¼æå–è¨­å®šã€‚")
                full_grades_df = pd.DataFrame(columns=expected_header_keywords)
            else:
                full_grades_df = pd.concat(all_grades_data, ignore_index=True)

                # é€²ä¸€æ­¥æ¸…ç† DataFrame
                full_grades_df.dropna(how='all', inplace=True)
                
                # éæ¿¾æ‰ä¸ç¬¦åˆå­¸å¹´åº¦å’Œé¸èª²ä»£è™Ÿæ¨¡å¼çš„è¡Œ
                # å­¸å¹´åº¦å¿…é ˆæ˜¯ä¸‰ä½æ•¸å­—ï¼Œç§‘ç›®åç¨±ä¸èƒ½ç‚ºç©ºï¼Œé¸èª²ä»£è™Ÿå¯ä»¥ç‚ºç©ºä½†ä¸èƒ½æ˜¯é›œè³ª
                if 'å­¸å¹´åº¦' in full_grades_df.columns and 'ç§‘ç›®åç¨±' in full_grades_df.columns:
                    full_grades_df = full_grades_df[
                        full_grades_df['å­¸å¹´åº¦'].astype(str).str.match(r'^\d{3}$') &
                        (full_grades_df['ç§‘ç›®åç¨±'].astype(str).str.strip() != '') &
                        (~full_grades_df['ç§‘ç›®åç¨±'].astype(str).str.contains(r'^\s*$', na=False)) # ç¢ºä¿ç§‘ç›®åç¨±ä¸æ˜¯å…¨ç©ºç™½
                    ]
                
                # éæ¿¾æ‰ã€Œå‹ä½œæˆç¸¾ã€
                if 'ç§‘ç›®åç¨±' in full_grades_df.columns:
                    full_grades_df = full_grades_df[~full_grades_df['ç§‘ç›®åç¨±'].astype(str).str.contains('å‹ä½œ', na=False)] # æ›´å»£æ³›åœ°åŒ¹é…â€œå‹ä½œâ€
                
                # ç¢ºä¿ GPA æ¬„ä½æ˜¯å­—ä¸²ä¸¦ä¿®å‰ª
                if 'GPA' in full_grades_df.columns:
                    full_grades_df['GPA'] = full_grades_df['GPA'].astype(str).str.strip()
                
                # å°‡å­¸åˆ†è½‰æ›ç‚ºæ•¸å€¼ï¼Œéæ•¸å­—çš„è¨­ç‚º0
                if 'å­¸åˆ†' in full_grades_df.columns:
                    full_grades_df['å­¸åˆ†'] = pd.to_numeric(full_grades_df['å­¸åˆ†'], errors='coerce').fillna(0)


            if not full_grades_df.empty:
                total_credits, remaining_credits, passed_courses_df = analyze_student_grades(full_grades_df)

                st.subheader("æŸ¥è©¢çµæœ âœ…")
                st.metric("ç›®å‰ç¸½å­¸åˆ†", total_credits)
                st.metric("è·é›¢ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±128å­¸åˆ†)", remaining_credits)

                st.subheader("é€šéçš„èª²ç¨‹åˆ—è¡¨ ğŸ“–")
                st.dataframe(passed_courses_df[['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']])

                with st.expander("æŸ¥çœ‹åŸå§‹æå–çš„æ•¸æ“š (ç”¨æ–¼é™¤éŒ¯)"):
                    st.dataframe(full_grades_df)
            else:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼ã€‚")

        except Exception as e:
            st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            st.info("è«‹ç¢ºèªæ‚¨çš„ PDF æ ¼å¼æ˜¯å¦ç‚ºæ¸…æ™°çš„è¡¨æ ¼ã€‚è‹¥å•é¡ŒæŒçºŒï¼Œå¯èƒ½æ˜¯ PDF çµæ§‹è¼ƒç‚ºè¤‡é›œï¼Œéœ€è¦èª¿æ•´ `pdfplumber` çš„è¡¨æ ¼æå–è¨­å®šã€‚")
            st.exception(e) # é¡¯ç¤ºå®Œæ•´çš„éŒ¯èª¤è¿½è¹¤ï¼Œæ–¹ä¾¿é™¤éŒ¯

if __name__ == "__main__":
    main()
