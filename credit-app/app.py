import streamlit as st
import pandas as pd
import io
import pdfplumber

# --- 1. GPA è½‰æ›å‡½æ•¸ ---
def parse_gpa_to_numeric(gpa_str):
    """
    Converts GPA string to a numeric value for comparison.
    This mapping can be adjusted based on specific grading scales.
    For this example, we define C- and above as passing.
    """
    gpa_map = {
        'A+': 4.3, 'A': 4.0, 'A-': 3.7,
        'B+': 3.3, 'B': 3.0, 'B-': 2.7,
        'C+': 2.3, 'C': 2.0, 'C-': 1.7,
        'D+': 1.3, 'D': 1.0, 'D-': 0.7,
        'E': 0.0, 'F': 0.0,
        'æŠµå…': 999.0, # Special value for 'æŠµå…' - treated as passed for credit count
        'é€šé': 999.0  # Special value for 'é€šé' - treated as passed for credit count
    }
    return gpa_map.get(str(gpa_str).strip(), 0.0)

# --- 2. æˆç¸¾åˆ†æå‡½æ•¸ ---
def analyze_student_grades(df):
    """
    Analyzes a DataFrame of student grades to calculate total earned credits
    and remaining credits for graduation.
    """
    GRADUATION_REQUIREMENT = 128 # Set the total graduation requirement

    df['å­¸åˆ†'] = pd.to_numeric(df['å­¸åˆ†'], errors='coerce').fillna(0)
    df['GPA_Numeric'] = df['GPA'].apply(parse_gpa_to_numeric)
    
    # Define "passed" condition: GPA_Numeric >= 1.7 OR GPA is 'æŠµå…' OR GPA is 'é€šé'
    # Use original 'GPA' column for 'æŠµå…'/'é€šé' check to avoid relying on 999.0 for actual GPA calculation
    # Also ensure å­¸åˆ† is greater than 0 for credit counting
    df['æ˜¯å¦é€šé'] = (df['GPA_Numeric'] >= 1.7) | \
                   (df['GPA'].astype(str).str.strip() == 'æŠµå…') | \
                   (df['GPA'].astype(str).str.strip() == 'é€šé')
    
    # Filter for courses that passed and have credits > 0
    passed_courses_df = df[df['æ˜¯å¦é€šé'] & (df['å­¸åˆ†'] > 0)].copy()

    # Calculate total earned credits by summing 'å­¸åˆ†' for passed courses
    total_earned_credits = passed_courses_df['å­¸åˆ†'].sum()
    
    # Calculate remaining credits: Graduation requirement minus total earned credits
    # Ensure it's not negative
    remaining_credits_to_graduate = max(0, GRADUATION_REQUIREMENT - total_earned_credits)

    return total_earned_credits, remaining_credits_to_graduate, passed_courses_df

# --- 3. å­—å…ƒæ­£è¦åŒ–å‡½æ•¸ ---
def normalize_text(text):
    """
    Normalizes specific problematic Unicode characters often found in PDF extraction
    to their standard Traditional Chinese/ASCII counterparts.
    """
    if text is None:
        return ""
    text = str(text).replace('\n', ' ').strip()
    # Normalize common full-width or variant characters
    text = text.replace('â½¬', 'ç›®') # CJK UNIFIED IDEOGRAPH-2F4D -> CJK UNIFIED IDEOGRAPH-76EE (ç›®)
    text = text.replace('â½‡', 'æ—¥') # CJK UNIFIED IDEOGRAPH-2F31 -> CJK UNIFIED IDEOGRAPH-65E5 (æ—¥)
    text = text.replace('ï¼ˆ', '(') # FULLWIDTH LEFT PARENTHESIS -> LEFT PARENTHESIS
    text = text.replace('ï¼‰', ')') # FULLWIDTH RIGHT PARENTHESIS -> RIGHT PARENTHESIS
    text = text.replace('â¼€', 'ä¸€') # CJK RADICAL ONE -> CJK UNIFIED IDEOGRAPH-4E00 (ä¸€)
    text = text.replace('ï¼£', 'C') # FULLWIDTH LATIN CAPITAL LETTER C -> LATIN CAPITAL LETTER C
    text = text.replace('ï¼¡', 'A') # FULLWIDTH LATIN CAPITAL LETTER A -> LATIN CAPITAL LETTER A
    text = text.replace('ï¼¢', 'B') # FULLWIDTH LATIN CAPITAL LETTER B -> LATIN CAPITAL LETTER B
    text = text.replace('ï¼¤', 'D') # FULLWIDTH LATIN CAPITAL LETTER D -> LATIN CAPITAL LETTER D
    text = text.replace('ï¼¥', 'E') # FULLWIDTH LATIN CAPITAL LETTER E -> LATIN CAPITAL LETTER E
    text = text.replace('ï¼¦', 'F') # FULLWIDTH LATIN CAPITAL LETTER F -> LATIN CAPITAL LETTER F
    text = text.replace('ï¼§', 'G') # FULLWIDTH LATIN CAPITAL LETTER G -> LATIN CAPITAL LETTER G
    return text


# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é«” ---
def main():
    st.title("ç¸½å­¸åˆ†æŸ¥è©¢ç³»çµ± ğŸ“")
    st.write("è«‹ä¸Šå‚³æ‚¨çš„æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆï¼Œç³»çµ±å°‡æœƒç‚ºæ‚¨æŸ¥è©¢ç›®å‰ç¸½å­¸åˆ†èˆ‡è·é›¢ç•¢æ¥­æ‰€éœ€çš„å­¸åˆ†ã€‚")
    st.info("ğŸ’¡ ç¢ºä¿æ‚¨çš„æˆç¸¾å–® PDF æ˜¯æ¸…æ™°çš„è¡¨æ ¼æ ¼å¼ï¼Œä»¥ç²å¾—æœ€ä½³è§£ææ•ˆæœã€‚")

    uploaded_file = st.file_uploader("ä¸Šå‚³æˆç¸¾ç¸½è¡¨ PDF æª”æ¡ˆ", type=["pdf"])

    if uploaded_file is not None:
        st.success("æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼æ­£åœ¨åˆ†æä¸­...")

        try:
            all_grades_data = []
            expected_columns_order = ["å­¸å¹´åº¦", "å­¸æœŸ", "é¸èª²ä»£è™Ÿ", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]
            
            st.subheader("é™¤éŒ¯è³‡è¨Š (é–‹ç™¼è€…å°ˆç”¨) ğŸ•µï¸")
            debug_info_placeholder = st.empty()
            debug_messages = []

            with pdfplumber.open(io.BytesIO(uploaded_file.getvalue())) as pdf:
                total_pages = len(pdf.pages)

                for page_num, page in enumerate(pdf.pages):
                    debug_messages.append(f"--- æ­£åœ¨è™•ç†é é¢ {page_num + 1}/{total_pages} ---")

                    # é€™è£¡å¯ä»¥æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´è£å‰ªç¯„åœï¼Œä»¥ç¢ºä¿è¡¨é ­å’Œè¡¨æ ¼æ•¸æ“šéƒ½è¢«åŒ…å«
                    top_y_crop = 60 
                    bottom_y_crop = page.height 

                    cropped_page = page.crop((0, top_y_crop, page.width, bottom_y_crop)) 
                    
                    table_settings = {
                        "horizontal_strategy": "lines",
                        "vertical_strategy": "lines",
                        "snap_tolerance": 1,             
                        "text_tolerance": 1,             
                        "join_tolerance": 1,             
                        "min_words_horizontal": 1, 
                        "min_words_vertical": 1 
                    }
                    debug_messages.append(f"  ä½¿ç”¨çš„ table_settings: {table_settings}")
                    
                    tables = cropped_page.extract_tables(table_settings)
                    
                    debug_messages.append(f"é é¢ {page_num + 1} æå–åˆ° {len(tables)} å€‹è¡¨æ ¼ã€‚")
                    
                    if not tables:
                        debug_messages.append(f"é é¢ {page_num + 1} æœªæå–åˆ°ä»»ä½•è¡¨æ ¼ã€‚")
                        continue

                    for table_idx, table in enumerate(tables):
                        debug_messages.append(f"--- è™•ç†é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} ---")
                        debug_messages.append(f"  åŸå§‹æå–çš„è¡¨æ ¼ (å‰5è¡Œ): {table[:5]}") 

                        if not table or len(table) < 1: # è‡³å°‘æœ‰ä¸€è¡Œ
                            debug_messages.append(f"  è¡¨æ ¼ {table_idx + 1} ç„¡æ•ˆ (è¡Œæ•¸ä¸è¶³æˆ–ç‚ºç©º)ã€‚")
                            continue

                        # éæ¿¾æ‰è¡¨æ ¼é–‹é ­çš„å®Œå…¨ç©ºè¡Œ
                        filtered_table = [row for row in table if any(c.strip() for c in row)]
                        if not filtered_table:
                            debug_messages.append(f"  éæ¿¾ç©ºè¡Œå¾Œè¡¨æ ¼ {table_idx + 1} ç‚ºç©ºï¼Œè·³éã€‚")
                            continue
                        
                        header_row_found = False
                        header = []
                        header_row_start_idx = -1 # åˆå§‹åŒ–ç‚º-1ï¼Œè¡¨ç¤ºæ•¸æ“šå¾ç¬¬0è¡Œé–‹å§‹

                        # é¦–å…ˆå˜—è©¦åœ¨éæ¿¾å¾Œçš„è¡¨æ ¼å‰5è¡Œå°‹æ‰¾æ˜ç¢ºçš„è¡¨é ­
                        potential_header_search_range = min(len(filtered_table), 5) 
                        for h_idx in range(potential_header_search_range):
                            h_row = filtered_table[h_idx]
                            cleaned_h_row_list = [normalize_text(col) for col in h_row]

                            is_potential_header = True
                            if len(cleaned_h_row_list) >= len(expected_columns_order):
                                for kw in ["å­¸å¹´åº¦", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"]: 
                                    if not any(kw in cell for cell in cleaned_h_row_list):
                                        is_potential_header = False
                                        break
                            else:
                                is_potential_header = False 
                            
                            if is_potential_header:
                                header = [normalize_text(col) for col in h_row] 
                                header_row_found = True
                                header_row_start_idx = h_idx 
                                break 
                        
                        if not header_row_found:
                            debug_messages.append(f"  æœªèƒ½è­˜åˆ¥å‡ºæ˜ç¢ºçš„è¡¨é ­ã€‚å˜—è©¦æª¢æŸ¥æ˜¯å¦ç‚ºæ•¸æ“šå»¶çºŒã€‚")
                            # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ˜ç¢ºçš„è¡¨é ­ï¼Œæª¢æŸ¥ç¬¬ä¸€æ¢éç©ºè¡Œæ˜¯å¦åƒæ•¸æ“šè¡Œ
                            if len(filtered_table[0]) >= len(expected_columns_order): # ç¢ºä¿è¡Œè¶³å¤ é•·
                                first_data_candidate_row = [normalize_text(col) for col in filtered_table[0]]
                                # æª¢æŸ¥ç¬¬ä¸€åˆ—æ˜¯å¦ç‚º3ä½æ•¸å­—çš„å­¸å¹´åº¦ï¼Œä¸”ç¬¬ä¸‰åˆ—ï¼ˆé¸èª²ä»£è™Ÿï¼‰éç©º
                                if first_data_candidate_row[0].isdigit() and \
                                   len(first_data_candidate_row[0]) == 3 and \
                                   first_data_candidate_row[2].strip() != '': # å‡è¨­é¸èª²ä»£è™Ÿåœ¨ç¬¬3åˆ—ï¼ˆç´¢å¼•2ï¼‰
                                    
                                    debug_messages.append(f"  ç¬¬ä¸€è¡Œ '{first_data_candidate_row[0]}' åƒå­¸å¹´åº¦ï¼Œåˆ¤æ–·ç‚ºæ•¸æ“šå»¶çºŒã€‚")
                                    header = expected_columns_order # å‡è¨­åˆ—é †åºèˆ‡é æœŸä¸€è‡´
                                    header_row_start_idx = -1 # è¡¨ç¤ºæ•¸æ“šå¾ filtered_table[0] é–‹å§‹
                                else:
                                    debug_messages.append(f"  ç¬¬ä¸€è¡Œä¸ç¬¦åˆæ•¸æ“šè¡Œæ ¼å¼ï¼Œè·³éæ­¤è¡¨æ ¼ã€‚")
                                    continue
                            else:
                                debug_messages.append(f"  ç¬¬ä¸€è¡Œå¤ªçŸ­ä¸ç¬¦åˆæ•¸æ“šè¡Œæ ¼å¼ï¼Œè·³éæ­¤è¡¨æ ¼ã€‚")
                                continue


                        debug_messages.append(f"  æœ€çµ‚è¡¨é ­: {header}")

                        col_to_index = {} 
                        index_to_col = {} 

                        for i, h_ext in enumerate(header):
                            if "å­¸å¹´åº¦" in h_ext: col_to_index["å­¸å¹´åº¦"] = i; index_to_col[i] = "å­¸å¹´åº¦"
                            elif "å­¸æœŸ" in h_ext: col_to_index["å­¸æœŸ"] = i; index_to_col[i] = "å­¸æœŸ"
                            elif "é¸èª²ä»£è™Ÿ" in h_ext: col_to_index["é¸èª²ä»£è™Ÿ"] = i; index_to_col[i] = "é¸èª²ä»£è™Ÿ"
                            elif "ç§‘ç›®åç¨±" in h_ext: col_to_index["ç§‘ç›®åç¨±"] = i; index_to_col[i] = "ç§‘ç›®åç¨±"
                            elif "å­¸åˆ†" in h_ext: col_to_index["å­¸åˆ†"] = i; index_to_col[i] = "å­¸åˆ†"
                            elif "GPA" in h_ext: col_to_index["GPA"] = i; index_to_col[i] = "GPA"
                        
                        critical_cols_found = all(col in col_to_index for col in ["å­¸å¹´åº¦", "ç§‘ç›®åç¨±", "å­¸åˆ†", "GPA"])
                        debug_messages.append(f"  é—œéµåˆ—ç´¢å¼•æ˜ å°„ç‹€æ…‹: {critical_cols_found}")
                        if not critical_cols_found: 
                            debug_messages.append("  ç¼ºå°‘é—œéµè¡¨é ­ï¼Œè·³éæ­¤è¡¨æ ¼ã€‚")
                            continue

                        # ç²å–é—œéµåˆ—çš„ç´¢å¼•
                        å­¸å¹´åº¦_idx = col_to_index.get("å­¸å¹´åº¦")
                        å­¸æœŸ_idx = col_to_index.get("å­¸æœŸ")
                        é¸èª²ä»£è™Ÿ_idx = col_to_index.get("é¸èª²ä»£è™Ÿ")
                        ç§‘ç›®åç¨±_idx = col_to_index.get("ç§‘ç›®åç¨±")
                        å­¸åˆ†_idx = col_to_index.get("å­¸åˆ†")
                        GPA_idx = col_to_index.get("GPA")

                        processed_rows = []
                        current_row_data_temp = None 
                        
                        # ç¢ºå®šå¾ filtered_table çš„å“ªä¸€è¡Œé–‹å§‹è™•ç†æ•¸æ“š
                        if header_row_start_idx == -1: # å¦‚æœæ˜¯éš±å¼è¡¨é ­ï¼Œå¾ç¬¬ä¸€è¡Œé–‹å§‹
                            data_rows_to_process = filtered_table[:]
                        else: # å¦‚æœæ‰¾åˆ°äº†æ˜ç¢ºè¡¨é ­ï¼Œå¾è¡¨é ­ä¸‹ä¸€è¡Œé–‹å§‹
                            data_rows_to_process = filtered_table[header_row_start_idx + 1:]

                        for row_num_in_table, row in enumerate(data_rows_to_process): 
                            cleaned_row = [normalize_text(c) for c in row]
                            
                            # ç¢ºä¿è¡Œè¶³å¤ é•·ï¼Œé¿å…ç´¢å¼•è¶Šç•Œ
                            # é€™è£¡ä½¿ç”¨ max(ç´¢å¼•) + 1ï¼Œç¢ºä¿èƒ½è¨ªå•æ‰€æœ‰éœ€è¦çš„åˆ—
                            if len(cleaned_row) < max(å­¸å¹´åº¦_idx, å­¸æœŸ_idx, é¸èª²ä»£è™Ÿ_idx, ç§‘ç›®åç¨±_idx, å­¸åˆ†_idx, GPA_idx) + 1:
                                debug_messages.append(f"    åŸå§‹è¡Œå¤ªçŸ­ï¼Œè·³é: {cleaned_row}")
                                continue

                            debug_messages.append(f"    --- è™•ç†åŸå§‹æ•¸æ“šè¡Œ (Data Rows) {row_num_in_table} ---")
                            debug_messages.append(f"    åŸå§‹æ•¸æ“šè¡Œå…§å®¹: {row}") 
                            debug_messages.append(f"    æ¸…æ´—å¾Œæ•¸æ“šè¡Œå…§å®¹: {cleaned_row}") 

                            is_new_grade_row = False
                            å­¸å¹´åº¦_val = cleaned_row[å­¸å¹´åº¦_idx]
                            é¸èª²ä»£è™Ÿ_val = cleaned_row[é¸èª²ä»£è™Ÿ_idx]
                            ç§‘ç›®åç¨±_val = cleaned_row[ç§‘ç›®åç¨±_idx]

                            # æ–°è¡Œåˆ¤æ–·ï¼šå­¸å¹´åº¦å¿…é ˆæ˜¯3ä½æ•¸å­—ï¼Œé¸èª²ä»£è™Ÿä¸èƒ½ç‚ºç©º
                            if å­¸å¹´åº¦_val.isdigit() and len(å­¸å¹´åº¦_val) == 3 and é¸èª²ä»£è™Ÿ_val.strip() != '':
                                is_new_grade_row = True
                                debug_messages.append(f"      åˆ¤æ–·: æ»¿è¶³æ–°çš„æˆç¸¾è¡Œæ¢ä»¶ (å­¸å¹´åº¦='{å­¸å¹´åº¦_val}', é¸èª²ä»£è™Ÿ='{é¸èª²ä»£è™Ÿ_val}')")
                            else:
                                debug_messages.append(f"      åˆ¤æ–·: ä¸ç¬¦åˆæ–°è¡Œæ¢ä»¶ (å­¸å¹´åº¦='{å­¸å¹´åº¦_val}', é¸èª²ä»£è™Ÿ='{é¸èª²ä»£è™Ÿ_val}')ã€‚")

                            if is_new_grade_row:
                                if current_row_data_temp: 
                                    reordered_row = [""] * len(expected_columns_order)
                                    for col_name, idx_in_header in col_to_index.items():
                                        if col_name in expected_columns_order:
                                            target_idx = expected_columns_order.index(col_name)
                                            if idx_in_header < len(current_row_data_temp): # ç¢ºä¿ç´¢å¼•ä¸è¶Šç•Œ
                                                reordered_row[target_idx] = current_row_data_temp[idx_in_header]
                                    processed_rows.append(reordered_row)
                                    debug_messages.append(f"      -> å‰ä¸€è¡Œå®Œæˆï¼Œé‡æ–°æ’åºä¸¦æ·»åŠ åˆ° processed_rows: {processed_rows[-1]}")
                                
                                current_row_data_temp = list(cleaned_row) 
                                debug_messages.append(f"      -> æ–°çš„æˆç¸¾è¡Œé–‹å§‹ç´¯ç©: {current_row_data_temp}")
                            elif current_row_data_temp: 
                                debug_messages.append(f"      åˆ¤æ–·: æª¢æŸ¥æ˜¯å¦ç‚ºç•¶å‰è¡ŒçºŒè¡Œ...")

                                # å‡è¨­çºŒè¡Œæ™‚ï¼Œå­¸å¹´åº¦å’Œé¸èª²ä»£è™Ÿéƒ½æ‡‰è©²æ˜¯ç©ºçš„
                                is_continuation_candidate = (å­¸å¹´åº¦_val.strip() == '' and é¸èª²ä»£è™Ÿ_val.strip() == '')

                                is_subject_continuation = False
                                if is_continuation_candidate and ç§‘ç›®åç¨±_val.strip() != '':
                                    is_subject_continuation = True
                                    debug_messages.append(f"        -> ç§‘ç›®åç¨±çºŒè¡Œï¼šå­¸å¹´åº¦/é¸èª²ä»£è™Ÿç‚ºç©ºï¼Œç§‘ç›®åç¨±æœ‰å…§å®¹ã€‚")
                                
                                is_gpa_continuation = False
                                GPA_val = cleaned_row[GPA_idx]
                                if is_continuation_candidate and GPA_val.strip() != '':
                                    is_gpa_continuation = True
                                    debug_messages.append(f"        -> GPA çºŒè¡Œï¼šå­¸å¹´åº¦/é¸èª²ä»£è™Ÿç‚ºç©ºï¼ŒGPAæœ‰å…§å®¹ã€‚")
                                
                                is_completely_empty_row = not any(c.strip() for c in cleaned_row)
                                if is_completely_empty_row:
                                    debug_messages.append(f"        -> æª¢æ¸¬åˆ°å®Œå…¨ç©ºç™½è¡Œã€‚")

                                if is_subject_continuation:
                                    current_row_data_temp[ç§‘ç›®åç¨±_idx] += " " + ç§‘ç›®åç¨±_val
                                    debug_messages.append(f"      -> ç§‘ç›®åç¨±çºŒè¡Œåˆä½µå¾Œ: {current_row_data_temp}")
                                elif is_gpa_continuation:
                                    current_row_data_temp[GPA_idx] += " " + GPA_val
                                    debug_messages.append(f"      -> GPA çºŒè¡Œåˆä½µå¾Œ: {current_row_data_temp}")
                                elif is_completely_empty_row:
                                    # å¦‚æœé‡åˆ°å®Œå…¨ç©ºç™½è¡Œï¼Œèªç‚ºå‰ä¸€æ¢è¨˜éŒ„çµæŸ
                                    if current_row_data_temp: 
                                        reordered_row = [""] * len(expected_columns_order)
                                        for col_name, idx_in_header in col_to_index.items():
                                            if col_name in expected_columns_order:
                                                target_idx = expected_columns_order.index(col_name)
                                                if idx_in_header < len(current_row_data_temp):
                                                    reordered_row[target_idx] = current_row_data_temp[idx_in_header]
                                        processed_rows.append(reordered_row)
                                        debug_messages.append(f"      -> æª¢æ¸¬åˆ°ç©ºç™½è¡Œï¼Œå‰ä¸€è¡Œå®Œæˆä¸¦æ·»åŠ åˆ° processed_rows: {processed_rows[-1]}")
                                    current_row_data_temp = None 
                                else: 
                                    # å¦‚æœä¸æ˜¯æ–°è¡Œï¼Œä¹Ÿä¸æ˜¯æ˜ç¢ºçš„çºŒè¡Œï¼Œä¹Ÿä¸æ˜¯ç©ºç™½è¡Œï¼Œå‰‡ç•¶å‰ç´¯ç©çš„è¡ŒçµæŸ
                                    debug_messages.append(f"      -> ä¸ç¬¦åˆä»»ä½•æ¨¡å¼ (æ–°è¡Œ/çºŒè¡Œ/ç©ºç™½è¡Œ)ï¼Œè¦–ç‚ºé›œè¨Šæˆ–éŒ¯èª¤ï¼ŒçµæŸç•¶å‰è¡Œã€‚")
                                    if current_row_data_temp: 
                                        reordered_row = [""] * len(expected_columns_order)
                                        for col_name, idx_in_header in col_to_index.items():
                                            if col_name in expected_columns_order:
                                                target_idx = expected_columns_order.index(col_name)
                                                if idx_in_header < len(current_row_data_temp):
                                                    reordered_row[target_idx] = current_row_data_temp[idx_in_header]
                                        processed_rows.append(reordered_row)
                                        debug_messages.append(f"      -> å°‡ç•¶å‰è¡Œæ·»åŠ åˆ° processed_rows: {processed_rows[-1]}")
                                    current_row_data_temp = None 
                            else: 
                                debug_messages.append(f"      -> current_row_data_temp ç‚ºç©ºï¼Œä¸”ç•¶å‰è¡Œä¸ç¬¦åˆæ–°è¡Œæ¢ä»¶ï¼Œè·³éã€‚")
                                pass 

                        # è™•ç†è¡¨æ ¼çš„æœ€å¾Œä¸€è¡Œ
                        if current_row_data_temp: 
                            reordered_row = [""] * len(expected_columns_order)
                            for col_name, idx_in_header in col_to_index.items():
                                if col_name in expected_columns_order:
                                    target_idx = expected_columns_order.index(col_name)
                                    if idx_in_header < len(current_row_data_temp):
                                        reordered_row[target_idx] = current_row_data_temp[idx_in_header]
                            processed_rows.append(reordered_row)
                            debug_messages.append(f"  æœ€å¾Œä¸€è¡Œå®Œæˆï¼Œé‡æ–°æ’åºä¸¦æ·»åŠ åˆ° processed_rows: {processed_rows[-1]}")

                        debug_messages.append(f"  è™•ç†å¾Œæœ‰æ•ˆè¡Œæ•¸: {len(processed_rows)}")
                        debug_messages.append(f"  è™•ç†å¾Œéƒ¨åˆ†æ•¸æ“š (å‰5è¡Œ): {processed_rows[:5]}")

                        if processed_rows:
                            df_table = pd.DataFrame(processed_rows, columns=expected_columns_order)
                            
                            for col in df_table.columns:
                                df_table[col] = df_table[col].astype(str).str.strip().replace('None', '').replace('nan', '')

                            all_grades_data.append(df_table)
                        else:
                            debug_messages.append(f"  æ­¤è¡¨æ ¼æœªèƒ½æå–åˆ°ä»»ä½•æœ‰æ•ˆæ•¸æ“šè¡Œã€‚")

                    debug_info_placeholder.text("\n".join(debug_messages)) 

            if not all_grades_data:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼æˆ–èª¿æ•´è¡¨æ ¼æå–è¨­å®šã€‚")
                full_grades_df = pd.DataFrame(columns=expected_columns_order)
                return

            full_grades_df = pd.concat(all_grades_data, ignore_index=True)

            # å†æ¬¡æ¸…ç†æ•´å€‹DataFrameï¼Œç¢ºä¿æ²’æœ‰å®Œå…¨ç©ºè¡Œï¼Œä¸¦ä¸”æ ¹æ“šå­¸å¹´åº¦ç¯©é¸
            full_grades_df.dropna(how='all', inplace=True)
            
            # ä½¿ç”¨æ›´åš´æ ¼çš„å­¸å¹´åº¦ç¯©é¸ï¼Œç¢ºä¿æ˜¯ä¸‰ä½æ•¸å­—
            initial_rows = len(full_grades_df)
            full_grades_df = full_grades_df[
                full_grades_df['å­¸å¹´åº¦'].astype(str).str.match(r'^\d{3}$')
            ]
            debug_messages.append(f"åŸå§‹æ•¸æ“šè¡Œæ•¸: {initial_rows}, ç¶“éå­¸å¹´åº¦ç¯©é¸å¾Œ: {len(full_grades_df)}")

            # éæ¿¾å‹ä½œæˆç¸¾ï¼Œç¢ºä¿ç§‘ç›®åç¨±åˆ—å­˜åœ¨
            if 'ç§‘ç›®åç¨±' in full_grades_df.columns:
                full_grades_df = full_grades_df[~full_grades_df['ç§‘ç›®åç¨±'].astype(str).str.contains('å‹ä½œæˆç¸¾', na=False)]
                debug_messages.append(f"éæ¿¾å‹ä½œæˆç¸¾å¾Œè¡Œæ•¸: {len(full_grades_df)}")
            
            # ç¢ºä¿ GPA åˆ—æ˜¯å­—ä¸²é¡å‹ä¸¦æ¸…ç†ç©ºç™½
            full_grades_df['GPA'] = full_grades_df['GPA'].astype(str).str.strip()


            if not full_grades_df.empty:
                total_credits, remaining_credits, passed_courses_df = analyze_student_grades(full_grades_df)

                st.subheader("æŸ¥è©¢çµæœ âœ…")
                st.metric("ç›®å‰ç¸½å­¸åˆ†", total_credits)
                st.metric("è·é›¢ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±128å­¸åˆ†)", remaining_credits)

                st.subheader("é€šéçš„èª²ç¨‹åˆ—è¡¨ ğŸ“–")
                st.dataframe(passed_courses_df[['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']])

                with st.expander("æŸ¥çœ‹åŸå§‹æå–çš„æ•¸æ“š (ç”¨æ–¼é™¤éŒ¯)"):
                    st.dataframe(full_grades_df)
            else:
                st.warning("æœªèƒ½å¾ PDF ä¸­æå–æœ‰æ•ˆçš„æˆç¸¾æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF æ ¼å¼ã€‚")

        except Exception as e:
            st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            st.info("è«‹ç¢ºèªæ‚¨çš„ PDF æ ¼å¼æ˜¯å¦ç‚ºæ¸…æ™°çš„è¡¨æ ¼ã€‚è‹¥å•é¡ŒæŒçºŒï¼Œå¯èƒ½æ˜¯ PDF çµæ§‹è¼ƒç‚ºè¤‡é›œï¼Œéœ€è¦èª¿æ•´ `pdfplumber` çš„è¡¨æ ¼æå–è¨­å®šã€‚")
            st.exception(e)
        finally: 
            debug_info_placeholder.text("\n".join(debug_messages))

if __name__ == "__main__":
    main()
